<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[李刚_产品经理助理]]></title>
    <url>%2F2018%2F04%2F03%2Finterview%2F</url>
    <content type="text"><![CDATA[联系方式 手机：15733207536 Email：luoyupiaoshang@gmail.com QQ：1763296564 个人信息 李刚/男/1995 统招本科/河北大学工商学院/土木工程 毕业时间: 2017/06 Github：https://github.com/lovemoganna 个人网站: https://luoyupiaoshang.club 期望职位：产品经理助理 期望薪资：6K 期望城市：北京 现在的情况和产品有关的东西 UML 流程图和Excel展示 UML类图/用例图 产品需求 &amp;&amp;DMEO展示 Visual Paradigm WPS/XMind8/ProcessOne/Git 之前自学了一部分java技术 java后端高并发和消息中间件 消息中间件:spring整合ActiveMQ 高并发的项目: 秒杀项目 个人展示个人网站. 目的 开发环境 相关技术 未来发展 记录自己用过的东西 砖瓦匠/centos7/githook Nodejs/Nginx 关联个人微信公众号,做消息推广 数据分析.简书这个产品,活跃了不少和我一样95后的用户.其中多数都是喜欢文学的大学生,也活跃着不少像我一样喜欢开发的人员. 我有一个爬虫项目,nodejs写的,爬取了简书里面的作者的首页和预览内容. 人工智能图像合成方面的认识 目的: 本着对新奇事物的探索,我在深度学习平台russellCloud做了下面这个项目.这个平台提供一个GPU来供机器训练模型. 项目链接: deepfakes 介绍: 将二者众多的图片进行模型训练,来合成具有二者共性的多张图片.我们挑选出一张最具有特点的展示. 作用对象: 特朗普 和 恶灵骑士 得出的结果: 一次完美的换脸术. 展示: 现在的发展: 该项技术已经延续使用在视频剪辑方面,可以做到真人换脸.几乎无缝对接. 电商项目我主要做了负责后端高并发的部分. 框架: SSM+centos7+tomcat+nginx+zookeeper+dubbo+maven+mysql7+solr+redis 技术点: SOA架构的搭建方式,Redis缓存优化+缓存同步,centos7下Nginx反向代理,Tomcat Session共享,Mysql增删改查及优化. 收获: 一个规范的项目构成:项目经理+产品经理+前端开发人员+后端开发人员+运维人员(linux/DB )+测试组. 发展: 衍生出我的秒杀项目 熟练工具和技能 办公工具: office 脑图/时序图/流程图: ProcessOne/XMind 统一建模语言: Visual markdown语言 sql: mysql linux: centos6/7 &amp;&amp; ubuntu 浏览器: firefox/chrome 熟悉的语言: java/nodejs/html/jsp 致谢感谢观看,期待有机会同您共事!]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>个人简历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql设计以及架构优化]]></title>
    <url>%2F2018%2F02%2F28%2Fmysql%E8%AE%BE%E8%AE%A1%E4%BB%A5%E5%8F%8A%E6%9E%B6%E6%9E%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[电商常用功能模块的数据库设计模块的划分: 注册会员–展示商品–加入购物车–生成订单 使用的工具和需要掌握的内容 使用MySQL5.7版本. Mysql的图形客户端程序,Mysqlworkbench. Linux下命令和Shell脚本的基础知识. 项目说明常见的购物流程: 1234用户登录---选购商品--加购物车--检查库存--提交订单 YES -- 在线支付 ---- 订单付款 YES -- 货到付款 ---- 订单付款 需要以下几个模块的设计 1234567用户模块: 完成用户注册和登录验证.商品模块: 前后台商品管理和浏览.订单模块: 订单及购物车的生成和管理.仓配模块: 仓库库存和物流管理功能. 数据库设计规范1.数据库结构设计 逻辑设计 —&gt; 物理设计 2.实际工作中 逻辑设计 + 物理设计 3.物理设计一般就是表名,字段名,字段类型的设计. 数据库规范概述1234561. 数据库命名规范2. 数据库基本设计规范3. 数据库索引命名和优化4. 数据库字段设计规范5. 数据库SQL开发规范6. 数据库操作行为规范 数据库命名规范所有数据库对象名称必须使用小写字母并用下划线分割.原因就是Mysql数据库对大小写敏感. 不同的数据库名 eg: DBName dbname 不同的表名 eg :Table table tabLe 所有数据库对象名称禁止使用Mysql保留关键字比如说你给列名起了个名字叫form 那么查询的时候就可能出现select id,username,from,age from tb_user;这种情况. 执行SQL的时候,mysql不清楚这2个form有什么区别. 要非解决这种问题哪,就用`from``来区分关键字. 数据库对象的命名要能做到见名识义,并且不能超过32个字符eg: 数据库命名示例: mc_userdb eg: 用户账号表: user_count 一般的临时表的命名规范: 像导入导出数据表,临时统计所使用的表,用完马上清理掉,最好. 但是大部分情况下都不允许,所以我们建立临时表时,必须要以tmp为前缀并以日期为后缀. eg : tmp_export_data_2018_01_28 备份表 备份表必须以bak为前缀并以日期为后缀. eg : bak_copy_data_2018_01_28 所有存储相同数据的列名和列类型必须一致 观察下面的的示例. 用户信息表1234567create table customer_inf( customer_inf_id int unsigned auto_increment primary key not null comment '自增', customer_id int unsigned not null comment 'customer login 表的自增', customer_name varchar(20) not null comment '用户真实姓名', identity_card_type tinyint not null default 1 comment '证件类型: 1 身份证, 2 微信网证', identify_card_no varchar(20) comment '证件号码' ); 订单表1234567create table order_master( order_id int unsigned not null auto_increment primary key comment '订单ID', order_sn bigint unsigned not null comment '订单编号 yyyymmddnnnnnnn', customer_id int unsigned not null comment '下单人ID', shipping_user varchar(10) not null comment '收货人姓名', province SMALLINT not null comment '收获人所在省' ); 我们可以观察到用户信息表中的customer_id字段和订单表中customer_id字段类型和大小相同:都是无符号的int类型. 这对于数据库的查询性能是非常重要的.一般都是关联列,对于查询的效率很有影响. 数据库命名规范总结12341. 所有数据库对象名称必须小写.2. 命名要见名识意,禁止使用Mysql的保留关键字.3. 临时表要以tmp_开头,备份表以bak_开头,并且以时间戳结尾.4. 所有存储相同数据的列名和列类型必须保持一致. 数据库基本设计规范现在可能还存在着Mysql5.5使用之前MyISAM(默认存储引擎)情况. 如今的Mysql5.7没有其他需求的话,默认是是使用Innodb存储引擎. 所有的表都要使用Innodb存储引擎原因就是Innodb存储引擎支持事务,行级锁,更好的恢复性,高并发下性能更好.与Oracle很相似. MyISAM在高并发的情况下,锁表是一种很常见的性能问题.Innodb存存储引擎解决了很多问题. 数据库和表的字符集统一使用UTF-8如果之存储中文字符的话,用GBK/GB2312字符集都可以. 统一的字符集可以避免由于字符集准换成的乱码. Mysql中的UTF8字符集汉字点3个字节,ASCII码占用1个字节. eg : 如果定义了varchar(255)的列使用UTF8存储中文字符,255个字符实际占用755个字节. 所有表和字段都要添加注释使用comment从句添加表这列的备注,这些我们基本都知道. 目的: 从一开始就进行数据字典的维护. 尽量控制单表数据量的大小,建议控制在500万行以内但是500万行数据量并不是Mysql数据库的限制 Mysql存储数据量的大小,取决于存储设置和文件系统,Mysql并没有对其进行了限制. 比如所: 32位操作系统单个文件不能超过2个G.所以32位操作系统限制了Mysql数据库的存储容量大小. 但是我们都使用64为的操作系统了,所以不必考虑存储容量的限制了. 可以使用历史数据归档,分库分表等手段来控制数据量大小. 这主要用在业务复杂的方面:比如订单表 谨慎的使用Mysql分区表分区表在物理上表现为多个文件,在逻辑上表现为一个表. 谨慎选择分区主键,跨分区查询效率可能更低. 建议采用物理分表的方式管理大数据. 尽量做到冷热数据分离,减少表的宽度除了注意表中的行,我们还要注意表中的宽度,Mysql对表中的数据行没有限制,但是一个表中所能包含的列却有限制. Mysql限制一个表中最多存放4096列,并且每一行的大小不能超过65535个字节. 减少磁盘IO,保证热数据的内存缓存命中率 利用更有效的利用缓存,避免读入无用的冷数据 为了保证表的宽度,要使用垂直拆分:经常一起使用的列放到一个表中,可以避免过多的冗关联操作,从另一方面可以提高查询的性能 禁止在表中建立预留字段一般是采用varchar类型,但是这种类型占用空间比较大. 预留字段的命名很难做到见名识义 预留字段无法确认存储的数据类型,所以无法选择合适的类型. 对预留字段类型的修改,会对表进行锁定. 禁止在数据库中存储图片,文件等二进制数据之前搭建了FastDFS服务器.可以解决这个问题. 禁止在线上做数据库压力测试要在专门的测试环境下测试.如果业务环境没上线,就不要再管理测试了. 禁止从开发环境,测试环境直接连接生产环境数据库数据库基本设计规范总结12341. 所有表必须使用Innodb存储引擎.2. 所有表及字段都要有备注信息,并使用UTF8字符集.3. 要尽量做到控制单表大小,并把冷热数据分离.4. 禁止使用预留字段及在表中存储大的二进制数据. 数据库索引规范索引对数据库的查询性能来说是非常重要的. 不要滥用索引限制每张表上的索引数量,单张表索引不超过5个. 索引并不是越多越好!索引可以提高效率同样也可以降低效率. 原因是索引可以提高查询的效率,但同样也会降低插入和更新的效率. 禁止给表中的每一列都建立单独的索引. Innodb是一种索引组织表.所谓的索引组织表就是,数据存储的逻辑顺序和索引的顺序是相同的.表的存储顺序只能有一种. Innodb是按照主键索引来组织表的. 固定的要求就是,每个innodb表必须有一个主键. 如果你没建立.Mysql就会选择第一个非空唯一索引作为主键. 如果没有非空唯一索引,Mysql就会自动生成一个占6个字节的主键.但性能不好. 表中主键的选择:不能使用更新频繁的列作为主键,不使用多列主键. 多列主键指的是联合索引作为主键. Innodb是索引组织表,如果使用上面的2个索引作为主键,不断频繁的改变顺序,不但会使服务器IO增加,同时会占用大量的CPU资源. 不要使用UUID,MD5,哈希,这种字符串数组的数据来作为主键. 这类数据无法保证数据的顺序更改. 拿UUID来说,我们无法保证下面插入的UUID的值是否大于前面的值,要是后插入的UUID的值比前面的小. 那么Innodb为了保证表的顺序性,要把这个小的UUID的值插入到前面. 这样就会造成大于这个新值的数据往后移动,这样就会造成大量的IO操作,还会占用大量的CPU资源.降低整体服务器的类型. 最好选中顺序自动增长的ID值,也就是数据库为我们提供的auto_increment 这种自增ID作为主键 在哪些上建立索引?1234561. 一般在SELECT,UPDATE,DELETE语句的WHERE从句的列建立索引.2. 包含在ORDER BY,GROUP BY,DISTINCT中的字段建立索引.3. 通常情况下,我们会选择建立联合索引,因为这样性能会更好.4. 多表JOIN的关联列上建立索引.如果Join的关联列上没有索引,在进行During操作的时候,性能会很差. 建立索引目的我们希望查询时通过索引来进行数据查找,从而减少磁盘的随机IO.增加查询的性能.所以我们的索引可以过滤出越少的数据,则我们需要从磁盘读入的数据越少. 如何选择索引列的顺序?我们是从左到右的顺序来使用的. 我们要把区分度最高的列放在联合索引的最左侧. 尽量把字段长度小的列放在联合索引的最左侧. 使用最频繁的列放在联合索引的左侧, 避免建立冗余索引和重复索引1.重复索引: 索引列完全重复. eg: primary key(id) index(id) unique index(id) 我们一旦指定了id作为主键,就相当于在id列上建立了一个非空的唯一索引. Mysql中的主键就是一个非空的唯一索引. 2.冗余索引: 部分索引列是冗余的. eg: index(a,b,c) index(a,b) index(a) 列存储 存储空间数据 create table user (id int unsigned auto_increment primary key,name varchar(32) not null,age int(2) not null,f varchar(32) not null);]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql设计</tag>
        <tag>架构优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-cluster搭建]]></title>
    <url>%2F2018%2F02%2F25%2FRedis%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[Redis集群搭建使用的包 Redis 集群的原理redis单机版的操作 Redis-cluster的架构 redis-cluster有一个投票:容错机制,用来确定是哪个节点挂了.少数服从多数. 比如下面这张图: 有5个节点,黄色的节点认为红色的节点挂了,只要剩下的3个节点有2个认为它挂了,那么红色的就认为挂了. 架构的细节 1.所有的redis节点彼此互联(PING-PONG机制),内部使用2进制协议优化传输速度和带宽. 2.节点的fail是通过集群中超过半数的节点监测失效时才生效. 3.客户端与redis节点直连,不需要中间proxy层,客户端不需要连接集群所有节点,连接集群中任何一个节点即可. 4.redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster负责维护node-slot–value redis集群中内置了16384个哈希槽,当需要在redis集群中放置一个key-value的时候,redis先对key使用crc16算法算出一个结果.然后把结果对16384取余,这样每个key都会对应一个编号在0-16383之间的哈希槽,redis会根据节点数量大致均等的将哈希槽映射到不同的节点. 极限情况下,允许有16384个节点. redis集群的搭建步骤1.一台虚拟机运行6个redis实例.端口从7001-7006. 2.复制redis实例,复制目录需要-r cp redis/bin redis-cluster/redis01 -r 进入cd redis-cluster/redis01中将持久化文件dump删除,不删除会对我们的集群造成影响. 接下来,修改bin目录下的redis.conf文件.主要修改端口号和打开注释. 修改端口号:port 7001 打开注释 接下来修改剩余的5个. 3.写脚本启动start-all.sh1234567891011121314151617cd redis01./redis-server redis.confcd ..cd redis02./redis-server redis.confcd ..cd redis03./redis-server redis.confcd ..cd redis04./redis-server redis.confcd ..cd redis05./redis-server redis.confcd ..cd redis06./redis-server redis.conf 无法启动,是因为需要授权的. chmod u+x start-all.sh 4.查看是否启动 5.进入redis源代码里面找一个文件 也就是在`/root/redis-4.0.8/src目录下去寻找.使用ll *.rb会找到redis-trib.rb`这个文件. 将这个文件复制到/usr/local/redis-cluster这个目录中. 现在的目录结构: 6.安装ruby环境yum install rubyyum install rubygems 输入你失败提示的那个的地址,去浏览器下载specs.4.8.gz这个文件,,输入gem install redis就能成功了. 7.ruby脚本 ./redis-trib.rb create --replicas 1 192.168.25.133:7001 192.168.25.133:7002 192.168.25.133:7003 192.168.25.133:7004 192.168.25.133:7005 192.168.25.133:7006 8.查看分配的主从服务器,以及槽的分配 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost redis-cluster]# ./redis-trib.rb create --replicas 1 192.168.25.133:7001 192.168.25.133:7002 192.168.25.133:7003 192.168.25.133:7004 192.168.25.133:7005 192.168.25.133:7006&gt;&gt;&gt; Creating cluster&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:192.168.25.133:7001192.168.25.133:7002192.168.25.133:7003Adding replica 192.168.25.133:7005 to 192.168.25.133:7001Adding replica 192.168.25.133:7006 to 192.168.25.133:7002Adding replica 192.168.25.133:7004 to 192.168.25.133:7003&gt;&gt;&gt; Trying to optimize slaves allocation for anti-affinity[WARNING] Some slaves are in the same host as their masterM: f525a4b2a3ff6cc32a36f276b17460910ac6334f 192.168.25.133:7001 slots:0-5460 (5461 slots) masterM: f865949d32a241285032a900ea0911859f83c44e 192.168.25.133:7002 slots:5461-10922 (5462 slots) masterM: db89b6f29ffa891ab166a39fb6101be99b763859 192.168.25.133:7003 slots:10923-16383 (5461 slots) masterS: b53df7de4aeb85751e64ec95743628a8387acf2c 192.168.25.133:7004 replicates db89b6f29ffa891ab166a39fb6101be99b763859S: af12ed12992d8c15057a356d299edac4a4b630fc 192.168.25.133:7005 replicates f525a4b2a3ff6cc32a36f276b17460910ac6334fS: 10189b284f51732b5a64aea3f9c8e7f545db9059 192.168.25.133:7006 replicates f865949d32a241285032a900ea0911859f83c44eCan I set the above configuration? (type 'yes' to accept): yes&gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join....&gt;&gt;&gt; Performing Cluster Check (using node 192.168.25.133:7001)M: f525a4b2a3ff6cc32a36f276b17460910ac6334f 192.168.25.133:7001 slots:0-5460 (5461 slots) master 1 additional replica(s)M: f865949d32a241285032a900ea0911859f83c44e 192.168.25.133:7002 slots:5461-10922 (5462 slots) master 1 additional replica(s)M: db89b6f29ffa891ab166a39fb6101be99b763859 192.168.25.133:7003 slots:10923-16383 (5461 slots) master 1 additional replica(s)S: af12ed12992d8c15057a356d299edac4a4b630fc 192.168.25.133:7005 slots: (0 slots) slave replicates f525a4b2a3ff6cc32a36f276b17460910ac6334fS: 10189b284f51732b5a64aea3f9c8e7f545db9059 192.168.25.133:7006 slots: (0 slots) slave replicates f865949d32a241285032a900ea0911859f83c44eS: b53df7de4aeb85751e64ec95743628a8387acf2c 192.168.25.133:7004 slots: (0 slots) slave replicates db89b6f29ffa891ab166a39fb6101be99b763859[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered.]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Redis-cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring与Redis整合]]></title>
    <url>%2F2018%2F02%2F24%2F%7Fspring%E5%92%8Credis%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[application-redix.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt;&lt;!-- 连接redis单机版 --&gt; &lt;!-- &lt;bean id="jedisClientPool" class="lups.org.common.jedis.impl.JedisClientPool"&gt; &lt;property name="jedisPool" ref="jedisPool"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id="jedisPool" class="redis.clients.jedis.JedisPool"&gt; &lt;constructor-arg name="host" value="192.168.25.133"/&gt; &lt;constructor-arg name="port" value="6379"/&gt; &lt;/bean&gt;--&gt; &lt;!-- 连接redis集群 --&gt; &lt;bean id="jedisClientCluster" class="lups.org.common.jedis.impl.JedisClientCluster"&gt; &lt;property name="jedisCluster" ref="jedisCluster"/&gt; &lt;/bean&gt; &lt;bean id="jedisCluster" class="redis.clients.jedis.JedisCluster"&gt; &lt;constructor-arg name="nodes"&gt; &lt;set&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="192.168.25.133"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="7001"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="192.168.25.133"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="7002"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="192.168.25.133"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="7003"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="192.168.25.133"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="7004"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="192.168.25.133"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="7005"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean class="redis.clients.jedis.HostAndPort"&gt; &lt;constructor-arg name="host" value="192.168.25.133"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name="port" value="7006"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/set&gt; &lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/beans&gt; 测试类12345678910111213141516171819public class JedisClientTest &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Test public void TestJedisClient()&#123; try &#123; //初始化Spring容器 ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext("classpath:spring/applicationContext-redis.xml"); //通过反射来获取bean对象 JedisClient jedisClient = context.getBean(JedisClientCluster.class); //来进行redis的操作 jedisClient.set("aa","1234"); String a = jedisClient.get("aa"); System.out.println(a); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125;&#125; 缓存的添加一般就在服务层里面添加. 1234567891011一般显示查询缓存如果缓存中有直接响应数据缓存中没有,查询数据库.返回结果之前,把结果添加到缓存就可以了.注意的一点就是不管是添加缓存和查询缓存,都不应该影响正常的逻辑.所以把`查询/添加缓存逻辑`放在try块里面. 缓存同步1234567更新完数据库,必须要更新缓存.也就是要一致.我们要求增改操作的时候,都应该同步缓存.所以在添加/更新的时候,删除缓存中对应的数据就可以实现自动更新了.这样就可以实现缓存同步了.如果采用的是hash类型,千万不要直接删除key,否则再次查询的时候,会对服务器造成很大的压力.修改那个field,就删那个field的缓存就可以了.`hdel key field1`.此时缓存,没有了,去查数据库,从而实现了缓存同步.]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Redis-cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis接口的编写]]></title>
    <url>%2F2018%2F02%2F24%2FRedis%E9%9B%86%E7%BE%A4%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[防火墙关闭,也可能对搭建有影响 使用redis-cli连接redis集群redis01/redis-cli -h 192.168.25.133 -p 7001 -c 输入一个key=a,value=123.经过crc16算法对key进行hash化出来一个值,再对16384取余,就可以得到一个值,用这个值匹配对应的槽就可以了. 这样就可以证明我搭建成功了.不变红就是没连接上. 测试单机版连接防火墙检查了都没连接上的办法. 只能设置密码了.在redis.conf中设置requirepass wsys,其中wsys就是你设置的密码. 测试代码1234567891011121314151617public class JedisTest &#123; private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Test public void jedisTest() throws Exception&#123; try &#123; Jedis jedis = new Jedis("192.168.25.133", 6379); jedis.auth("wsys"); String a = jedis.set("a", "123"); String a1 = jedis.get("a"); System.out.println(a1); jedis.close(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125;&#125; JedisPool测试代码1234567891011121314public void jedisPoolTest() throws Exception&#123; try &#123; //创建一个连接池对象,两个参数host,port JedisPool jedisPool = new JedisPool("192.168.25.133", 6379); Jedis jedis= jedisPool.getResource(); jedis.auth("wsys"); String a = jedis.get("a"); System.out.println("jedisPool中取: "+a); jedis.close(); jedisPool.close(); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; jedisCluster测试 如果出现java.lang.NumberFormatException这个错误,需要把jedis的maven依赖版本调高点,2.9.0就可以了12345678910111213141516171819202122@Test public void jedisClusterTest() throws Exception&#123; try &#123; //创建一个JedisCluster对象,有一个参数nodes是一个set类型,set中包含若干个HostAndPort对象. Set&lt;HostAndPort&gt; nodes =new HashSet&lt;&gt;(); nodes.add(new HostAndPort("192.168.25.133",7001)); nodes.add(new HostAndPort("192.168.25.133",7002)); nodes.add(new HostAndPort("192.168.25.133",7003)); nodes.add(new HostAndPort("192.168.25.133",7004)); nodes.add(new HostAndPort("192.168.25.133",7005)); nodes.add(new HostAndPort("192.168.25.133",7006)); JedisCluster jedisCluster = new JedisCluster(nodes); jedisCluster.set("b", "12"); String b = jedisCluster.get("b"); System.out.println("jedisCluster: "+b); jedisCluster.close(); //java.lang.NumberFormatException &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; &#125; 总结 121.单机版用jedispool来操作jedis.2.集群版直接使用jedisCluster就可以了. 编写jedisclient的接口以及单机版&amp;&amp;集群版的实现类1.jedisClient12345678910111213141516171819202122232425public interface JedisClient &#123; //字符串的操作 String set(String key,String value); String get(String key); //判断字符串的键值是否存在 Boolean exists(String key); //过期时间的设置 Long expire(String key,int seconds); //剩余过期时间 Long ttl(String key); //hash类型的操作 Long hset(String key,String field,String value); //增加1 Long incr(String key); //查询hash类型 String hget(String key,String field); //删除hash类型 Long hdel(String key,String... field); //判断hash类型是否存在 Boolean hexists(String key,String field); //查询所有hash的值 List&lt;String&gt; hvals(String key); //删除一个键值对 Long del(String key);&#125; 2.jedisClientPool123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117package lups.org.common.jedis.impl;import java.util.List;import lups.org.common.jedis.JedisClient;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;public class JedisClientPool implements JedisClient &#123; private JedisPool jedisPool; public JedisPool getJedisPool() &#123; return jedisPool; &#125; public void setJedisPool(JedisPool jedisPool) &#123; this.jedisPool = jedisPool; &#125; @Override public String set(String key, String value) &#123; Jedis jedis = jedisPool.getResource(); String result = jedis.set(key, value); jedis.close(); return result; &#125; @Override public String get(String key) &#123; Jedis jedis = jedisPool.getResource(); String result = jedis.get(key); jedis.close(); return result; &#125; @Override public Boolean exists(String key) &#123; Jedis jedis = jedisPool.getResource(); Boolean result = jedis.exists(key); jedis.close(); return result; &#125; @Override public Long expire(String key, int seconds) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.expire(key, seconds); jedis.close(); return result; &#125; @Override public Long ttl(String key) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.ttl(key); jedis.close(); return result; &#125; @Override public Long incr(String key) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.incr(key); jedis.close(); return result; &#125; @Override public Long hset(String key, String field, String value) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.hset(key, field, value); jedis.close(); return result; &#125; @Override public String hget(String key, String field) &#123; Jedis jedis = jedisPool.getResource(); String result = jedis.hget(key, field); jedis.close(); return result; &#125; @Override public Long hdel(String key, String... field) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.hdel(key, field); jedis.close(); return result; &#125; @Override public Boolean hexists(String key, String field) &#123; Jedis jedis = jedisPool.getResource(); Boolean result = jedis.hexists(key, field); jedis.close(); return result; &#125; @Override public List&lt;String&gt; hvals(String key) &#123; Jedis jedis = jedisPool.getResource(); List&lt;String&gt; result = jedis.hvals(key); jedis.close(); return result; &#125; @Override public Long del(String key) &#123; Jedis jedis = jedisPool.getResource(); Long result = jedis.del(key); jedis.close(); return result; &#125;&#125; 3.jedisClientCluster1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package lups.org.common.jedis.impl;import java.util.List;import lups.org.common.jedis.JedisClient;import redis.clients.jedis.JedisCluster;public class JedisClientCluster implements JedisClient &#123; private JedisCluster jedisCluster; public JedisCluster getJedisCluster() &#123; return jedisCluster; &#125; public void setJedisCluster(JedisCluster jedisCluster) &#123; this.jedisCluster = jedisCluster; &#125; @Override public String set(String key, String value) &#123; return jedisCluster.set(key, value); &#125; @Override public String get(String key) &#123; return jedisCluster.get(key); &#125; @Override public Boolean exists(String key) &#123; return jedisCluster.exists(key); &#125; @Override public Long expire(String key, int seconds) &#123; return jedisCluster.expire(key, seconds); &#125; @Override public Long ttl(String key) &#123; return jedisCluster.ttl(key); &#125; @Override public Long incr(String key) &#123; return jedisCluster.incr(key); &#125; @Override public Long hset(String key, String field, String value) &#123; return jedisCluster.hset(key, field, value); &#125; @Override public String hget(String key, String field) &#123; return jedisCluster.hget(key, field); &#125; @Override public Long hdel(String key, String... field) &#123; return jedisCluster.hdel(key, field); &#125; @Override public Boolean hexists(String key, String field) &#123; return jedisCluster.hexists(key, field); &#125; @Override public List&lt;String&gt; hvals(String key) &#123; return jedisCluster.hvals(key); &#125; @Override public Long del(String key) &#123; return jedisCluster.del(key); &#125;&#125;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Redis-cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基本操作]]></title>
    <url>%2F2018%2F02%2F24%2Fredis%2F</url>
    <content type="text"><![CDATA[基本知识判断redis服务的健康状态. 1234567存储key-value,把key计算为一个hash值,把它放在一个位置.取得时候,先计算是哪个位置,直接去那个位置去取,是直接存取这个值,而不是遍历.Redis之所以快,是因为所有数据都是保存在内存当中的. 5种数据类型key-value类型. stringhashlistsetsorted set 1.string类型1.写入键值对set str1 abc2.取得键值对get str13.显示所有的keykeys *4.增加一个键incr key15.删除操作del key46.加1的操作 7.减1的操作 Redis中所有的字段都是字符串,他们是先转换成整型,在加减1的. 我们观察下面的操作,就可以了.key2的键值是字符串,你给它加1,自然会出错,要是像下面这样做就对了 2.hash类型1.创建一个hashhset hash1 field1 12.查询一个hash的值hget hash1 field13.删除一个hashhdel hash1 field14.查询所有hash的field值hkeys hash1 5.查询所有的hash的value值hvals hash1 6.查询hash所有的key-value值hgetall hash1 redis的数据类型list的元素可以重复,有序.1.从左往右存储数据rpush a b c d e f2.从右往左储存数据lpush 1 2 3 4 5 6 3.查看数据范围lrange list1 0 -1 4.取出元素lpop list1rpop list1取出元素之后,就不能看到之前的全部了. set类型set 无序,且输入的数据不能重复1.添加元素sadd set1 a b c d a b2.删除元素srem set1 a3.查看元素smembers set1 4.seta与setb的比较 类似于左连接和右连接那种形式,剔除共有的部分 5.取交集sinter seta setb6.取并集sunion seta setb sorted set元素是有序的,耗费的性能会很高. 1.升序排列zrange zset1 0 -1 withscores 2.降序排列zrevrange zset1 0 -1 3.带分数倒序排序 设置key的过期时间expire key1 20 1.看看过期时间和倒计时 2.永久保存和不存在的标识 -1是永久保存的数据(持久化),-2是不存在的数据 redis的持久化1.重新设置过期时间 2.持久化数据persist key3,-1就代表数据持久化了. 3.redis的持久化.redis总的所有数据都是保存在内存当中的. 持久化方案有2种: 1.Rdb:快照形式.定期把内存中当前时刻的数据保存到磁盘.这是Redis默认支持的持久化方案. 2.aof形式:把所有对redis数据库操作的命令,增删改操作的命令,保存到文件当中,数据库恢复时把所有的命令执行一遍就可以了. redis.conf的配置里面有描述. 1.第一种: 15分钟之内有1个key发生变化,他就保存一个快照文件.5分钟之内有10个key发生变化,他就保存一个快照文件.1分钟之呢有1W个key发生变化,他就保存一个快照文件. 快照模式有丢失文件的可能性,但是我们一般就做缓存.没多大影响. 2.第二种把增删改操作用文件保存 默认是不开启的.对磁盘的IO比较频繁.]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Redis-cluster</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DB02-数据库字段设计规范]]></title>
    <url>%2F2018%2F02%2F22%2FDB02-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[复习1231.每个innodb表都要有一个主键2.限制表上索引的数量,避免建立重复和冗余索引3.注意合理选择符合索引键值的顺序 数据库字段设计规范字段类型的选择,会直接影响数据库的建立. 列的字段越大,建立索引时所需要的空间就会越大. 优先选择符合存储需要的最小数据类型.1.我们一般是将字符串转为数字类型存储. 下面的函数的转换:12345INET_ATON('255.255.255.255') = 4294967295把字符串的IP地址转换成整型.反之,把整型转换成字符串的IP地址INET_NTOA('4294967295') = 255.255.255.255 2.对于非负型的数据来说,要优先使用无符号整型来存储]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql服务器日志]]></title>
    <url>%2F2018%2F02%2F01%2Fmysql%E6%97%A5%E5%BF%97%E5%88%92%E5%88%86%2F</url>
    <content type="text"><![CDATA[Mysql的使用情景日志记录系统MySQL 数据库的插入和查询性能都非常的高效，如果设计地较好，在使用 MyISAM 存储引擎的时候，两者可以做到互不锁定，达到很高的并发性能。 所以，对需要大量的插入和查询日志记录的系统来说，MySQL 是非常不错的选择。 比如处理用户的登录日志，操作日志 等 ，都是非常适合的应用场景。 数据仓库系统随着现在数据仓库数据量的飞速增长，我们需要的存储空间越来越大。数据量的不断增长，使数据的统计分析变得越来越低效，也越来越困难。 解决方式如下: 123451. 采用昂贵的高性能主机以提高计算性能，用高端存储设备提高 I/O 性能，效果理想，但是成本非常高；2. 通过将数据复制到多台使用大容量硬盘的廉价 pc server上，以提高整体计算性能和 I/O 能力，效果尚可，存储空间有一定限制，成本低廉.3. 通过将数据水平拆分，使用多台廉价的 pc server 和本地磁盘来存放数据，每台机器上面都只有所有数据的一部分，解决了数据量的问题， 所有 pc server 一起并行计算，也解决了计算能力问题，通过中间代理程序调配各台机器的运算任务， 既可以解决计算性能问题又可以解决 I/O 性能问题，成本也很低廉. 这是基本解决方法.对于Mysql来讲,实现2,3步骤很容易,通过读写分离,主从复制就可以实现. 通过 MySQL 的简单复制功能，可以很好的将数据从一台主机复制到另外一台 ，不仅仅在局域网内可以复制，在广域网同样可以。优点在于Mysql是免费的. Mysql的架构组成Mysql的物理文件组成Mysql5.7服务器日志12345671. 选择常规查询和慢查询日志输出目的地2. 错误日志3. 一般查询日志4. 二进制日志(Binlog)5. manchaxun rizhi6. DDL 日志7. 服务器日志维护 MySQL服务器有几个日志可以帮助你找出正在发生的活动.日志类型: 错误日志 一般查询日志 二进制日志 中继日志 慢查询日志 DDL日志(元数据日志)-写入日志的信息: 在启动,运行或者停止mysqld时遇到的问题 建立了客户的客户关系和声明 改变数据的语句(也可用于复制) 从复制主服务器接收的数据更改 查询花费了超过 long_query_time几秒的时间执行 元数据操作由DDL语句执行 1234567891011121314151617181920212223默认情况下，除Windows上的错误日志之外，不会启用任何日志。DDL日志始终在需要时创建，并且没有用户可配置选项;默认情况下，服务器为数据目录中的所有启用日志写入文件。您可以通过刷新日志来强制服务器关闭并重新打开日志文件（或在某些情况下切换到新的日志文件）。发出FLUSH LOGS语句时发生日志刷新 ; 用a 或者参数执行 mysqladmin ; 或使用 或 选项执行 mysqldump。例如:flush-logsrefresh--flush-logs--master-data另外，二进制日志在其大小达到max_binlog_size系统变量的值时被刷新 。可以在运行时控制常规查询和慢查询日志.可以启动或者禁用日志记,或者更改日志文件名称.也可以告诉服务器编写通用查询和慢查询条目来记录表或者日志文件.日志维护操作(比如:旧日志文件到期)的信息有关保持日志安全的信息以上都可以查看下列链接. TODO: DDL日志 FLUSH语法 mysqladmin - 管理MySQL服务器的客户端 mysqldump–数据库备份程序 从服务器中继日志 服务器日志维护 密码和日志记录]]></content>
      <tags>
        <tag>Mysql</tag>
        <tag>ServiceLog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[选择常规查询和慢速查询日志的输出目的地]]></title>
    <url>%2F2018%2F01%2F27%2F%E9%80%89%E6%8B%A9%E5%B8%B8%E8%A7%84%E6%9F%A5%E8%AF%A2%E5%92%8C%E6%85%A2%E9%80%9F%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%E7%9A%84%E8%BE%93%E5%87%BA%E7%9B%AE%E7%9A%84%E5%9C%B0%2F</url>
    <content type="text"><![CDATA[前言如果启用了这些日志，则MySQL服务器可以灵活地控制输出目标到常规查询日志和慢速查询日志。 日志条目的可能目标是日志文件或 数据库中的general_log和 slow_log表mysql。 可以选择任一个或两个目的地。 服务器启动时的日志控制。该–log-output选项指定日志输出的目的地. 该选项本身不会启用日志。它的语法是 ： –log-output[=value,…] 如果–log-output给定值，则该值应该是一个或多个单词TABLE（记录到表）， FILE（记录到文件）或 NONE（不记录到表或文件）的以逗号分隔的列表。 NONE如果存在的话，优先于任何其他说明符。 如果–log-output省略，则默认日志记录目标为FILE。]]></content>
      <tags>
        <tag>Mysql</tag>
        <tag>ServiceLog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[集群环境中解决Session共享问题]]></title>
    <url>%2F2018%2F01%2F25%2F%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E4%B8%AD%E8%A7%A3%E5%86%B3Session%E5%85%B1%E4%BA%AB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[具体业务1.登录需要校验用户名和密码,然后把用户信息保存在session里面。最终返回用户登录成功。 2.用户访问用户中心，必须要登录。我们使用拦截器来实现。判断用户当前是否登录。 3.在拦截器里面判断有没有Session信息，再看session中有没有用户信息。如果有Session里面有用户信息，用户就登陆了。 但是要实现高并发，高可用。用需要前端搭建nginx服务器. session共享发生的位置1234567通过nginx负载均衡服务器，如果用户登录，如果用户登录成功了，就会把用户信息保存到当前的tomcat1的Session里面。用户成功后，刷新页面，他就会去访问用户中心。判断用户是否登录，恰巧轮到tomcat2来提供服务了。发现没有用户的登录信息。要求用户登录。接下来，又提示登录，登录成功后，session保存在Tomcat1里面，刷新页面，再次访问用户中心，又会访问Tomcat2.tomcat2里面没有存储用户信息的session，所以提示再次登录。 一般的解决方案12345配置tomcat，tomcat1会广播自己的节点信息，其他的tomcat节点接收到消息，会把那一个tomcat的session复制到其他的tomcat里面来。tomcat广播形式配合session共享，会有一个节点的上限。如果不听的往集群中加tomcat的时候，会形成内网的，网络固化，会占满内网的带宽，服务器的会变慢。所有节点共享session，需要解决高并发问题。 解决方案123有一个服务器，专门存储管理session信息。（Session里面都是key-value的形式，并且有过期时间的设置。）需要我们来模拟Session。redis有list的存储模型，有序，且是key-value的形式。 总结：1234561.配置tomcat集群，配置tomcatsession复制。节点不要超过5个。 2.可以使用session服务器，保存Session信息，使每个节点是无状态，需要模拟session。单点登录系统是使用Redis模拟Session，实现session的统一管理。 分布式事务的理解12345678910提交订单，订单提交，提醒库房系统发货。MQ，系统发消息。出异常，就说明事情没做完，导致数据不一致，还有手动应答，把消息处理完毕，正常结束了。给服务器一个回馈，我已经成功了。 此时，服务器吧这个消息删除掉。如果没有正常消费这个消息，服务器就会不停的重发，直到这个消息处理完，就能保证这个事不停的做。最终保证数据的一致性。我们使用ActiveMQ来实现事务的最终一致性。这个就可以解决分布式事务这样的问题。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Session共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ajax跨域问题]]></title>
    <url>%2F2018%2F01%2F24%2Fajax%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[模拟ajax跨域问题建立2个工程,一个客户端,一个服务端. 客户端代码 服务端的代码 虽然调用成功,但是却有问题 console栏报出错误: 分析发生ajax跨域的原因: 一开始我以为是服务器后台不允许前台调用,但实际上并不是这样. 它是由于下面的原因决定的:1234567891011121314151617181.浏览器限制这是出于浏览器安全的考虑,当他发现你的请求是跨域的时候,浏览器本身会做一些校验,如果检验不通过,就会报出跨域安全问题.服务器后台没有问题,而是浏览器校验出了问题.2.跨域发出的请求不是本域的,请求协议域名,端口,任何一个不一样,浏览器都视为跨域问题.我们后台的端口是8080,前台的端口是9901.域名即使一样也不可以.3.XHR(XMLHTTPRequest)请求也就是发送的不是XHR请求,就算是跨域,浏览器也不会报错.如果是json的请求,就不会报出这个错误,如果是xhr类型的请求,就会出现这样的错误.普通的ajax请求返回的是json对象.jsonp请求返回的是一个json脚本.![](http://upload-images.jianshu.io/upload_images/7505161-61cf20ca7baa8e64.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240) 解决思路123456781.浏览器限制:每个人都做改动,就是客户端的改动.2.XHR:只要发出的数据类型不是这个类型,我们就可以跨域,所以我们使用jsonp.3.跨域一.被调用方(),基于HHTP协议关于跨域方面的要求做出的修改,也就是说A域名调用B域名的时候,在B域名返回数据中加入一些字段允许A域名调用.浏览器通过校验,就不会发生浏览器校验问题,别的公司的,调用方(隐藏跨域:通过代理,浏览器发出的都是A域名的请求,把代理的URL都转到B域名里面,这样看起来就是同一个域名.) 1234567891.浏览器禁止检查:命令行禁止启动: --disable-web-security2.jsonp如何解决跨域jsonp是json的一种补充使用.使用jsonp后台也需要改动. jsonp类型展示:12345678910$.ajax(&#123; url : cartHostUrl+'/ajax/getproduct/', type : 'GET', dataType: 'jsonp', //返回json格式的数据 jsonp: 'callback', cache:true, success: function()&#123; result =json; &#125;&#125;); 后台修改:]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Session共享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebCrawler-网络爬虫01]]></title>
    <url>%2F2018%2F01%2F09%2FWebCrawler%2F</url>
    <content type="text"><![CDATA[大虫子 爬虫简介我们人做的事:访问一个网页,输入URL,按回车,该网站的服务器就会返回一个HTML文件浏览器解析返回的数据,展示在UI上. 爬虫做的事:爬虫模仿人的操作,给网站发送一个请求,网站会给爬虫程序返回一个HTML文件,爬虫程序在根据返回的数据进行抓取分析. 爬虫概论网络爬虫是一种自动化浏览网络的程序,或者叫网络机器人.爬虫被广泛用于互联网搜索引擎或其他类似网站，以获取或更新这些网站的内容和检索方式。它们可以自动采集所有其能够访问到的页面内容，以供搜索引擎做进一步处理（分检整理下载的页面），而使得用户能更快的检索到他们需要的信息。 白话:你手动打开窗口，输入数据等等操作用程序代替。用程序替你获取你想要的信息，这就是网络爬虫. 爬虫应用通常搜索引擎处理的对象是互联网网页。首先面临的问题是：如何能够设计出高效的下载系统，以将如此海量的网页数据传送到本地，在本地形成互联网网页的镜像备份。网络爬虫即起此作用，它是搜索引擎系统中很关键也很基础的构件。 爬虫：实际上就是通过相应的技术，抓取页面上特定的信息。 这种程序实际是利用html文档之间的链接关系，在Web上一个网页一个网页的爬取(crawl)， 将这些网页抓到系统来进行分析，并放入数据库中。]]></content>
      <tags>
        <tag>爬虫的原理</tag>
        <tag>爬虫架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链(Blockchain)]]></title>
    <url>%2F2018%2F01%2F08%2F%E5%8C%BA%E5%9D%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[起源 区块链技术起源于比特币,是比特币的底层技术. 区块链本身是一串使用密码学方法相关联产生的数据块, 每一个数据块中包含了一次比特币网络交易的信息,并由世界各地所有的比特币用户共同维护. 区块链的本质 区块链的本质是电子账簿. 通俗讲,区块链就是利用计算机程序在全网记录所有交易信息的公开大账本.人们只需要加入一个公开透明的数据库,通过点对点的记账,数据传输,认证或合约来达成信用共识,而不再借助任何中间方. 区块链的特点 区块链特点是受第三方控制的. 区块链中每个节点和矿工必须遵循同一记账交易规则,而这个规则是基于密码算法而不是信用. 同时每笔交易需要网络内其他用户的批准,所以不需要一套第三方中介结构或信任机构背锅. 区块链的安全性区块链的技术采取保障其安全性的算法是单向哈希算法. 区块链采取单向哈希算法,哈希(hash)算法是一种单向密码体制,即它是一个从明文到密文的不可逆的映射,只有加密过程,没有解密过程. 每当有加密交易产生时,网络中有强大运算能力的矿工(Miner)就开始利用算法解密验证交易,创造出新的区块来记录最新的交易. 像石榴算法,绿萝算法,企鹅算法都是常见的搜索引擎算法. 区块链的分类目前已知的区块链技术大致可分成三类: 公开区块链(public blockchain): 像比特币,公开区块链上的数据所有人都可以访问,所有人都可以发出交易等待被写入区块链. 协作区块链(federated blockchain): 德勤等会计所尝试的审计系统,参与区款连的节点是事先选择好的,节点间很可能是有很好的网络连接. 私有区域链(private blockchain): 参与的节点只有用户自己,数据的访问和使用有严格的权限管理. 区款连的运行 区块链这个公开透明的数据库包括了过去所有的交易记录,历史数据以及其他相关信息,这些信息安全地分布式存储在一串使用密码学方法产生的数据块中,即为一个区块,每个区块都包含了一个区块的索引,即区块的哈希值(hash),而从创始区块连接当前区块,就形成了区块链. 区块链自动地降低了支付成本. 15年12月重金投资区块链的初创公司 华尔街的金融公司正在投资区块链,抢滩布局.Visa,纳斯达克,花旗风投投资了一家旧金山区块链初创公司chain,设计融资金额达到3000万美元. 类比特币数据货币RSCoin 英国央行计划发布由中央机构控制的类比特币数据货币RSCoin. 这是一款完全基于央行的需求来设计的基于区块链技术的数字货币,该技术将依赖于一系列权威机构,如商业机构,防止货币重复消费. 目前,RSCoin由伦敦大学学院(UCL)研发,已进入了初步测试阶段. 区块链的结算应用 瑞穗银行声明中表示:”连续地生成包含交易信息的区块按照时间顺序链接成了区块链,编程不能被篡改的信息.而且,因为信息可以在多个公司之间共享,所以合作伙伴证实它可以缩短交易后的程序所需要的时间.” 区块链技术在试验过程中,也确实缩短了交易后程序的时间,达到接近即时结算的效果. 中国资本在区块链的作为 作为比特币及区块链的忠实拥护者.万向集团出资5000万美元成立了区块链基金,用于在全球范围内投资区块链商业应用相关的各类项目. 全球十大区块链投资中我国占据三席,分别为数贝投资,IDG,万向区块链基金. 测试代码高亮123456789101112public class test&#123; public void main(String [] ages) &#123; System.out.println("hello world!"); &#125;&#125;// 你好啊!/** 代码高亮测试 */]]></content>
      <categories>
        <category>区块链(Blockchain)</category>
      </categories>
      <tags>
        <tag>FT中文网</tag>
        <tag>区块链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀web层开发]]></title>
    <url>%2F2018%2F01%2F02%2F%E7%A7%92%E6%9D%80Web%E5%B1%82%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[主要内容 前端交互设计 Restful springmvc bootstrap+jquery 前端交互设计 产品 前端 后端 详情页流程逻辑 Restful接口设计什么是Restful123456REST是英文representational state transfer(表象性状态转变)或者表述性状态转移;Rest是web服务的一种架构风格;使用HTTP,URI,XML,JSON,HTML等广泛流行的标准和协议;轻量级,跨平台,跨语言的架构设计;它是一种设计风格,不是一种标准,是一种思想.Restful兴起于Rails,是一种优雅的URL表述方式,资源的状态和状态转移. Rest架构的风格Rest架构的主要原则1234567891011网络上的所有事物都被抽象为资源每个资源都有一个唯一的资源标识符同一个资源具有多种表现形式(xml,json等)对资源的各种操作不会改变资源标识符所有的操作都是无状态的符合REST原则的架构方式即可称为RESTful Restful的示例123456GET /Seckill/list 风格友好POST /Seckill/execute/&#123;seckillId&#125; 风格不友好 POST /Seckill/&#123;seckillId&#125;/execute 风格友好GET /seckill/delete/&#123;id&#125; 风格不友好GET /seckill/&#123;id&#125;/delete 风格友好 Restful规范1234GET --&gt;查询操作POST --&gt;添加/修改操作PUT --&gt;修改操作DELETE --&gt;删除操作 图示: HTTP状态码: springmvc中实现Restful服务123456SpringMVC实现restful服务:SpringMVC原生态的支持了REST风格的架构设计所涉及到的注解:--@RequestMapping--@PathVariable--@ResponseBody url的设计12341. /模块/资源/&#123;标示&#125;/集合1/...良好的表示如下: 2. /user/&#123;uid&#125;/friends --&gt;好友列表 3. /user/&#123;uid&#125;/followers --&gt;关注者列表 秒杀API的URL设计12345GET /seckill/list 秒杀列表GET /seckill/&#123;id&#125;/detail 详情页面GET /seckill/time/now 系统时间POST /seckill/&#123;id&#125;/exposer 暴露秒杀POST /seckill/&#123;id&#125;/&#123;md5&#125;/execution 执行秒杀 SpringMVC的运行流程我们始终围绕着Handler开发,如下: SpringMVC的运行流程123456789101112131415161718192021222324251.用户发送请求到DispatchServlet2.DispatchServlet根据请求路径查询具体的Handler3.HandlerMapping返回一个HandlerExcutionChain给DispatchServlet HandlerExcutionChain：Handler和Interceptor集合4.DispatchServlet调用HandlerAdapter适配器5.HandlerAdapter调用具体的Handler处理业务6.Handler处理结束返回一个具体的ModelAndView给适配器 ModelAndView:model--&gt;数据模型，view--&gt;视图名称7.适配器将ModelAndView给DispatchServlet8.DispatchServlet把视图名称给ViewResolver视图解析器9.ViewResolver返回一个具体的视图给DispatchServlet10.渲染视图11.展示给用户 图示: Http处理地址映射原理 注解映射示例1234567891011121314@RequestMapping注解:1. 支持标准的URL2. Ant风格URL(以?和** 等字符)3. 带(XXX)占位符的URLfor example:1. /user/*/creation匹配 /user/aaa/creation,/user/bbb/creation等URL2. /user/**/creation 匹配 /usr/creation, /user/aaa/bbb/creation等URL3. /user/&#123;userId&#125;匹配/user/123,/user/abc等URL4. /company/&#123;companyId&#125;/user/&#123;userId&#125;/detail匹配/company/123/user/456/detail等URL 请求方法细节的处理包括:1234561. 请求参数的绑定2. 请求方式限制3. 请求转发和重定向4. 数据模型赋值5. 返回JSON数据6. cookie访问 参数绑定的示例123456789101112@RequestMapping(value="/&#123;seckillId&#125;/detail",mnethod=RequestMethod.GET)public String detail(@PathVariable("seckillId")Long seckillId,Model model)&#123; if(seckillId == null)&#123; return "redirect:/seckill/list"; &#125; Seckill seckill=SeckillService.getById|(seckillId); if(seckill == null)&#123; return "forward:/seckill/list"; &#125; model.addAttribute("seckill",seckill); return "detail";//view&#125; 返回json数据的示例12345678910111213@RequestMapping(value="/&#123;seckillId&#125;/&#123;md5&#125;/execution",method=RequestMethod.POST,produces=&#123;"application/json;charset=UTF-8"&#125;)@ResponseBodypublic SeckillResult&lt;Exposer&gt; exposerSeckillURL(@PathVariable("id")long id)&#123; SeckillResult&lt;Exposer&gt; result; try&#123; Exposer exposer =... &#125; catch(Exception e)&#123; logger.error(e.getMessage(),e); result=new SeckillResult&lt;Exposer&gt;(false,e.getMessage()); &#125; return result;&#125; Cookie访问的示例@CookieValue(value=”killPhone”,required=false)long phone) 如果请求的RequestMapping里面没有包含killPhone的Cookie,SpringMVC框架就会报错,所以要设置成false.具体的判断要在程序里面判断. 123456789@RequestMapping(value="/&#123;seckillId&#125;/&#123;md5&#125;/execution",method=RequestMethod.POST)public SeckillResult&lt;SeckillExecution&gt; execute(@PathVariable("seckillId")long seckillId,@PathVariable("md5")String md5,@CookieValue(value="killPhone",required=false)long phone)&#123; if(phone ==null )&#123; return new SeckillResult&lt;SeckillExecution&gt;(false,"电话未注册"); &#125; SeckillExecution execution=seckillService.executeSeckillByProcedure(seckillId,md5,phone); SeckillResult&lt;SeckillExecution&gt; result=new SeckillResult&lt;SeckillExecution&gt;(true,execution); return result;&#125; web.xml的配置123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1" metadata-complete="true"&gt;&lt;!--配置DispactherServlet--&gt; &lt;servlet&gt; &lt;servlet-name&gt;seckill-dispacther&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--配置springmvc需要加载的配置文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/spring-*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;seckill-dispacther&lt;/servlet-name&gt; &lt;!--默认匹配所有的请求--&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;/web-app&gt; spring-web.xml的配置123456789101112131415161718192021222324252627282930&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/mvchttp://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--配置SpringMVC--&gt; &lt;!--1.开启SpringMVC注解模式--&gt; &lt;!--简化配置: 1. 自动注册DefaultAnnotationHandlerMapping,AnnotationMethodHandlerDdapter 2. 提供一系列:数据绑定,数字和日期.和Format @NumberFormat,@DataTimeFormat,xml,json默认读写支持 --&gt; &lt;mvc:annotation-driven/&gt; &lt;!--2.静态资源默认Servlet配置 1. 加入对静态资源的处理:js,gif,png 2. 允许使用&quot;/&quot;做整体映射 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--3.配置jsp,显示ViewResolver--&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot;/&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;/&gt; &lt;property name=&quot;suffix&quot; value=&quot;./jsp&quot;/&gt; &lt;/bean&gt; &lt;!--4.扫描web相关的bean--&gt; &lt;context:component-scan base-package=&quot;org.seckill.web&quot;/&gt;&lt;/beans&gt; 书写秒杀的ControllerSeckillController1url的格式: url:/模块/资源/&#123;id&#125;/细分 /seckill/&#123;id&#125;/list 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475@Controller@RequestMapping(&quot;/seckill&quot;)public class SeckillController &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private SeckillService seckillService; @RequestMapping(value = &quot;/list&quot;, method = RequestMethod.GET) public String getList(Model model) &#123; List&lt;Seckill&gt; list = seckillService.getAllSeckill(); model.addAttribute(&quot;list&quot;, list); //list.jsp + model = ModelAndView return &quot;list&quot;;//WEB-INF/jsp/&quot;list&quot;.jsp &#125; @RequestMapping(value = &quot;/&#123;seckillId&#125;/detail&quot;, method = RequestMethod.GET) public String getDetail(@PathVariable(&quot;seckillId&quot;) Long seckillId, Model model) &#123; if (seckillId == null) &#123; return &quot;redirect:/seckill/list&quot;; &#125; Seckill seckill = seckillService.getBySeckillId(seckillId); if (seckill == null) &#123; return &quot;forward:/seckill/list&quot;; &#125; model.addAttribute(&quot;seckill&quot;, seckill); return &quot;detail&quot;; &#125; //ajax json @RequestMapping(value = &quot;/&#123;seckillId&#125;/exposer&quot;, method = RequestMethod.POST, produces = &#123;&quot;application/json;charset=UTF-8&quot;&#125;) @ResponseBody public SeckillResult&lt;Exposer&gt; exposer(@PathVariable(&quot;seckillId&quot;) Long seckillId) &#123; try &#123; Exposer exposer = seckillService.exportSeckillUrl(seckillId); return new SeckillResult&lt;Exposer&gt;(true, exposer); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); return new SeckillResult&lt;Exposer&gt;(false, e.getMessage()); &#125; &#125; @RequestMapping(value = &quot;/&#123;seckillId&#125;/&#123;md5&#125;/execution&quot;, method = RequestMethod.POST, produces = &#123; &quot;application/json; charset=utf-8&quot;&#125;) @ResponseBody public SeckillResult&lt;SeckillExecution&gt; execute(@PathVariable(&quot;seckillId&quot;) Long seckillId, @PathVariable(&quot;md5&quot;) String md5, @CookieValue(value = &quot;killPhone&quot;, required = false) Long phone) &#123; // springmvc valid if (phone == null) &#123; return new SeckillResult&lt;&gt;(false, &quot;未注册&quot;); &#125; try &#123; // 存储过程调用 SeckillExecution execution = seckillService.executeSeckill(seckillId, phone, md5); return new SeckillResult&lt;SeckillExecution&gt;(true, execution); &#125; catch (RepatKillException e) &#123; SeckillExecution execution = new SeckillExecution(seckillId, SeckillStatEnum.REPEAT_KILL); return new SeckillResult&lt;SeckillExecution&gt;(true, execution); &#125; catch (SeckillClosedException e) &#123; SeckillExecution execution = new SeckillExecution(seckillId, SeckillStatEnum.END); return new SeckillResult&lt;SeckillExecution&gt;(true, execution); &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); SeckillExecution execution = new SeckillExecution(seckillId, SeckillStatEnum.INNER_ERROR); return new SeckillResult&lt;SeckillExecution&gt;(true, execution); &#125; &#125; @RequestMapping(value = &quot;/time/now&quot;, method = RequestMethod.GET) @ResponseBody public SeckillResult&lt;Long&gt; time() &#123; Date now = new Date(); return new SeckillResult&lt;Long&gt;(true, now.getTime()); &#125;&#125; 一些插件的CDNCDN查询地址1234567jquery-cookiehttps://cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.jsjquery-countdownhttps://cdn.bootcss.com/jquery-countdown/2.0.2/jquery.countdown-ar.js 切记1234必须使用这种方法书写&lt;script src=&quot;xxx&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;如果采用下面的写法,浏览器不会加载资源&lt;script src=&quot;xxx&quot; type=&quot;text/javascript&quot;/&gt; 总结 Bootstrap和JS在github地址有.我才开始用,需要了解一部分.感觉逻辑什么的还挺好用的. DTO传输数据 注解映射驱动]]></content>
      <categories>
        <category>Seckill</category>
      </categories>
      <tags>
        <tag>SSM</tag>
        <tag>Web</tag>
        <tag>Bootstrap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀Service层开发]]></title>
    <url>%2F2018%2F01%2F02%2F%E7%A7%92%E6%9D%80service%E5%B1%82%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[思考DAO层做的事创建数据库,编写接口,书写mapper.xml(SQL), 配置mybatis-config.xml,整合spring-dao.xml. 总的来说就是接口设计和SQL编写. 代码和SQL进行分离,方便Review. DAO拼接等逻辑在SERVICE层完成. DAO层也成为数据访问层,也就是对mysql等远程系统的操作. service层包分类dto –数据传输层,关于web和service的数据传递. entity –业务实体的存放. exception –秒杀结束,秒杀存货不足. enum –枚举类 service层接口的设计123456789101112131415161718192021222324252627282930313233343536373839/** * 业务接口:站在&quot;使用者&quot;角度设计接口 * 三个方面:方法定义粒度,参数,返回类型(return 类型/异常) */public interface SeckillService &#123; /** * 展示所有秒杀记录 * * @return */ List&lt;Seckill&gt; getAllSeckill(); /** * @param seckillId * @return 展示单个秒杀记录 */ Seckill getBySeckillId(long seckillId); /** * 行为接口 * 秒杀开启时输出秒杀接口地址, * 否则输出系统时间和秒杀时间. * @param seckillId * @return Exposer */ Exposer exportSeckillUrl(long seckillId); /** * 执行秒杀操作,需要根据商品Id和用户名来执行操作, * 同时对用户的url来源渠道做一次验证.即和之前秒杀开启前的MD5值作比较. * * @param seckillId * @param userPhone * @param md5 * @Return SeckillException */ SeckillExecution executeSeckill(long seckillId, long userPhone, String md5) throws SeckillException, SeckillClosedException, RepatKillException;&#125; 数据传输数据的封装(dto)Exposer-暴露秒杀信息的的封装类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/** * 暴露秒杀地址DTO */public class Exposer &#123; //是否开启秒杀 public boolean exposed; //MD5加密 private String md5; //商品ID private long seckillId; //系统当前时间(毫秒),方便用户浏览器控制服务器的时间. private Date now; //秒杀开始时间 private Date start; //秒杀结束时间 private Date end; /** * 不同的构造方法方便对象的初始化. * 秒杀成功用到的构造方法 * @param exposed * @param md5 * @param seckillId */ public Exposer(boolean exposed, String md5, long seckillId) &#123; this.exposed = exposed; this.md5 = md5; this.seckillId = seckillId; &#125; /** * 不符合条件,用到的构造方法 * @param exposed * @param seckillId * @param now * @param start * @param end */ public Exposer(boolean exposed,long seckillId,Date now, Date start, Date end) &#123; this.exposed=exposed; this.seckillId=seckillId; this.now = now; this.start = start; this.end = end; &#125; /** * 秒杀开始之前,需要对秒杀地址隐藏,加密. * @param exposed * @param seckillId */ public Exposer(boolean exposed, long seckillId) &#123; this.exposed = exposed; this.seckillId = seckillId; &#125; public boolean isExposed() &#123; return exposed; &#125; public Exposer setExposed(boolean exposed) &#123; this.exposed = exposed; return this; &#125; public String getMd5() &#123; return md5; &#125; public Exposer setMd5(String md5) &#123; this.md5 = md5; return this; &#125; public long getSeckillId() &#123; return seckillId; &#125; public Exposer setSeckillId(long seckillId) &#123; this.seckillId = seckillId; return this; &#125; public Date getNow() &#123; return now; &#125; public Exposer setNow(Date now) &#123; this.now = now; return this; &#125; public Date getStart() &#123; return start; &#125; public Exposer setStart(Date start) &#123; this.start = start; return this; &#125; public Date getEnd() &#123; return end; &#125; public Exposer setEnd(Date end) &#123; this.end = end; return this; &#125;&#125; SeckillExecution-秒杀执行结果的封装类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 秒杀执行结果 */public class SeckillExecution &#123; private long seckillId; //秒杀执行结果状态 private int state; //状态表示 private String stateInfo; //秒杀成功对象 private SuccessKilled successKilled; public SeckillExecution(long seckillId, SeckillStatEnum statEnum) &#123; this.seckillId = seckillId; this.state = statEnum.getState(); this.stateInfo = statEnum.getStateInfo(); &#125; public SeckillExecution(long seckillId, SeckillStatEnum statEnum, SuccessKilled successKilled) &#123; this.seckillId = seckillId; this.state = statEnum.getState(); this.stateInfo = statEnum.getStateInfo(); this.successKilled = successKilled; &#125; public long getSeckillId() &#123; return seckillId; &#125; public SeckillExecution setSeckillId(long seckillId) &#123; this.seckillId = seckillId; return this; &#125; public int getState() &#123; return state; &#125; public SeckillExecution setState(int state) &#123; this.state = state; return this; &#125; public String getStateInfo() &#123; return stateInfo; &#125; public SeckillExecution setStateInfo(String stateInfo) &#123; this.stateInfo = stateInfo; return this; &#125; public SuccessKilled getSuccessKilled() &#123; return successKilled; &#125; public SeckillExecution setSuccessKilled(SuccessKilled successKilled) &#123; this.successKilled = successKilled; return this; &#125;&#125; 秒杀接口的实现–Impl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130@Servicepublic class SeckillServiceImpl implements SeckillService &#123; /** * 使用slf4j的日志 */ private Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private SecKillDao secKillDao; @Autowired private SuccessKilledDao successKilledDao; /** * 与MD5结合的混淆的字符串. */ private final String hx = &quot;aaskg8has$%^&amp;@i1564I^$&amp;*@$!&quot;; @Override public List&lt;Seckill&gt; getAllSeckill() &#123; return secKillDao.queryAll(0, 4); &#125; @Override public Seckill getBySeckillId(long seckillId) &#123; return secKillDao.queryById(seckillId); &#125; /** * 判断秒杀时间是否开始了 * @param seckillId * @return */ @Override public Exposer exportSeckillUrl(long seckillId) &#123; Seckill seckill = secKillDao.queryById(seckillId); //系统当前时间 Date nowTime = new Date(); Date startTime = seckill.getStartTime(); Date endTime = seckill.getEndTime(); //1.如果seckill为null,不暴露地址.调用Exposer里面的初始化方法就可以了. if (seckill == null) &#123; return new Exposer(false, seckillId); &#125; //2.如果秒杀时间不符合,也不能进行秒杀. if (nowTime.getTime() &lt; startTime.getTime() || nowTime.getTime() &gt; endTime.getTime()) &#123; return new Exposer(false, seckillId, nowTime, startTime, endTime); &#125; //3.md5转换特定字符串的过程,是不可逆的. String md5 = getMd5(seckillId); return new Exposer(true, md5, seckillId); &#125; /** * 生成MD5字符串 * @param seckillId * @return */ private String getMd5(long seckillId) &#123; String base = seckillId + &quot;/&quot; + hx; String md5 = DigestUtils.md5DigestAsHex(base.getBytes()); return md5; &#125; /** * 执行秒杀的实现,主要校验MD5来实现秒杀 * @param seckillId * @param userPhone * @param md5 * @return * @throws SeckillException * @throws SeckillClosedException * @throws RepatKillException */ @Override public SeckillExecution executeSeckill(long seckillId, long userPhone, String md5) throws SeckillException, SeckillClosedException, RepatKillException &#123; //1.md5匹配不上,系统出现异常 if (md5 == null || !md5.equals(getMd5(seckillId))) &#123; throw new SeckillException(&quot;Seckill data rewite! 你可能使用了重复秒杀的插件 !=QAQ=!&quot;); &#125; /** * 2. md5匹配成功, * 执行秒杀逻辑: * --减库存 * --写明细 */ Date killTime = new Date(); try &#123; //减库存 int updateCount = secKillDao.reduceNumber(seckillId, killTime); //更新数&lt;0,说明减库存失败,没有更新到记录 if (updateCount &lt; 0) &#123; //秒杀过期 throw new SeckillClosedException(&quot;Seckill is closed!&quot;); &#125; //写明细 int insertState = successKilledDao.insertSuccessKilled(seckillId, userPhone); //唯一的验证标准就是验证 秒杀商品的ID和用户手机号. //之前秒杀成功,state=1.再次秒杀同一seckillId的商品,他就会秒杀不成功了,因为我们设置的是insert ignore,插入就会忽略,insertState返回的就是0. if (insertState &lt;= 0) &#123; //重复秒杀 throw new RepatKillException(&quot;Seckill repeted!&quot;); &#125; else &#123; //秒杀成功 SuccessKilled successKilled = successKilledDao.querySuccessKilledWithSeckill(seckillId, userPhone); return new SeckillExecution(seckillId,SeckillStatEnum.SUCCESS, successKilled); //TODO &#125; &#125; //这些异常的抛出有次序.我们要友好一些,要知道抛出的是哪个部分的异常. //重复秒杀的异常 catch (RepatKillException e1) &#123; throw e1; &#125; //秒杀时间过期的异常 catch (SeckillClosedException e2) &#123; throw e2; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); //所有编译期异常都要转换为运行期异常 throw new SeckillException(&quot;seckill inner error:&quot; + e.getMessage()); &#125; &#125;&#125; 数据字典的形成根据条件判断需要抛出的stateInfo提示信息,直接在里面写,可用性很差,所以我们采用枚举类的方式来规范statInfo的分配. 枚举类SeckillStatEnum12345678910111213141516171819202122232425262728293031323334353637/** * 使用枚举类表述常量数据字典 */public enum SeckillStatEnum &#123; SUCCESS(1,&quot;秒杀成功!&quot;), END(0,&quot;秒杀结束!&quot;), REPEAT_KILL(-1,&quot;重复秒杀!&quot;), INNER_ERROR(-2,&quot;系统异常!&quot;), DATA_REWRITE(-3,&quot;数据篡改!&quot;); private int state; private String stateInfo; SeckillStatEnum(int state, String stateInfo) &#123; this.state = state; this.stateInfo = stateInfo; &#125; public int getState() &#123; return state; &#125; public String getStateInfo() &#123; return stateInfo; &#125; //此静态方法迭代所有的类型 public static SeckillStatEnum stateOf(int index) &#123; for (SeckillStatEnum state : values()) &#123; //values()用来拿到所有类型 if (state.getState() == index) &#123; return state; &#125; &#125; return null; &#125;&#125; 基于以前的构造方法改造成含有枚举的表示方法. 秒杀成功用到的构造方法:改造前123456public SeckillExecution(long seckillId, int state, String stateInfo, SuccessKilled successKilled) &#123; this.seckillId = seckillId; this.state = state; this.stateInfo = stateInfo; this.successKilled = successKilled; &#125; 改造后123456789101112public SeckillExecution(long seckillId, SeckillStatEnum statEnum) &#123; this.seckillId = seckillId; this.state = statEnum.getState(); this.stateInfo = statEnum.getStateInfo(); &#125; public SeckillExecution(long seckillId, SeckillStatEnum statEnum, SuccessKilled successKilled) &#123; this.seckillId = seckillId; this.state = statEnum.getState(); this.stateInfo = statEnum.getStateInfo(); this.successKilled = successKilled; &#125; 异常的处理–Exception秒杀异常12345678910111213/** * 后两个异常都属于秒杀异常,所以继承此类即可. */public class SeckillException extends RuntimeException &#123; public SeckillException(String message) &#123; super(message); &#125; public SeckillException(String message, Throwable cause) &#123; super(message, cause); &#125;&#125; 重复秒杀异常12345678910111213/** * 重复秒杀异常(运行期异常) * java的异常一般分为运行期异常和编译期异常 * spring声明式事务只接收运行期异常事务回滚策略.抛出非声明式异常,spring不会对其进行事务回滚. */public class RepatKillException extends SeckillException&#123; public RepatKillException(String message) &#123; super(message); &#125; public RepatKillException(String message, Throwable cause) &#123; super(message, cause); &#125;&#125; 秒杀关闭异常123456789101112131415161718192021package org.seckill.exception;/** * @author: ligang * date: 2018/2/7 * time: 15:39 * 秒杀时间关闭异常 */public class SeckillClosedException extends SeckillException &#123; /** * 运行期异常的继承,但是他们都属于秒杀异常 * @param message */ public SeckillClosedException(String message) &#123; super(message); &#125; public SeckillClosedException(String message, Throwable cause) &#123; super(message, cause); &#125;&#125; 使用Spring托管SERVICE依赖理论SpringIOC的概念IOC-依赖注入 SpringIOC的过程会创建一个对象工厂,还会进行依赖管理,最终给一个一致的访问接口. SuccessKillSERVICE完整的实例如下: 使用IOC的好处: 对象创建统一托管 规范的声明周期管理 灵活的依赖注入 一致的获取对象(默认是单例) SpringIOC的注入方式和场景 三种方式实现如下 我们的IOC使用: 123XML配置package-scan(包扫描)Annotation注解 springIOC的注解用法 先进行包扫描 在spring-service.xml里面输入12&lt;!--扫描Service包下所有使用注解的类型--&gt; &lt;context:component-scan base-package=&quot;org.seckill.service&quot;/&gt; 注解部分 @Component 如果你不知道该写@Service/@Controller的时候,@Component就是一个比较笼统的Spring容器在一个组件实例. @Service @Controller dao里面的所有内容都会通过mapper.xml文件初始化放进Spring容器中,然后spring容器中回去Dao的实例,注入到相关的ervice下面 @Autowired(自动注入,就不用自己new实现类了) / @Resource / @Inject 注入方式 spring的声明式事务声明式事务就是不关心事务的开启或者提交.而是交给第三方框架来实现的.解脱事务代码. 1.执行事务的步骤12345开启事务修改SQL-1(更新/增加/删除)修改SQL-2修改SQL-3提交或者回滚 2.声明式事务的使用方式123ProxyFactoryBean + XML ---- 早期的使用方式(2.0)tx:advice+aop命名空间 ---- 一次配置永久生效(使用最多的方式,不太关心事务是如何操作的)注解@Transaction ----- 注解控制(推荐使用,对我们有利) 3.事务方法嵌套 声明式事务独有的概念123传播行为 --- spring默认是`propagation_required`,意思就是说当有一个新的事务加入中来,会直接加入到已经存在的事务,如果有事务存在就会直接加入到原有的事务当中,如果没有就会创建一个新的事务 4.什么时候回滚事务121. 抛出运行期异常(RuntimeException)可以执行回滚,非运行期异常可能不会全部回滚.2. 小心不当的try-catch,要是你使用try-catch包括一个有异常的程序,spring就会感知不到它会出现异常. 声明式事务的配置: 123456789101112&lt;!--2.配置事务管理器,我们使用的是jdbc的事务管理器--&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;!--注入数据库连接池--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;!--3.配置基于声明式注解的声明式事务 当你输入tx:annotation-driven的时候,它会自动的把相关的schema加上 默认使用注解来管理事务行为 --&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; @Transaction的使用 12345使用注解控制事务方法的优点: 1. 开发团队达成一致的约定,明确标注事务方法的编程风格 2. 保证事务方法的执行时间尽可能短,不要穿插其他的网络操作,比如:RPC/HTTP请求.或者剥离到事务方法外部:就是把它们写到方法的上一层. 3. 不是所有的方法都使用事务,如:只有一条修改操作,只读操作不需要事务控制.(mysql的行级锁有涉及到) service测试slf4j接口的实现logback官网配置文件 日志logback.xml的配置 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!--打印到控制台,默认级别是debug,时间,线程和日志的格式--&gt;&lt;configuration debug=&quot;true&quot;&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!-- encoders are by default assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder --&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=&quot;debug&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; 测试类:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;&quot;classpath:spring/spring-dao.xml&quot;,&quot;classpath:spring/spring-service.xml&quot;&#125;)public class SeckillServiceTest &#123; //使用日志 private final Logger logger = LoggerFactory.getLogger(this.getClass()); @Autowired private SeckillService seckillService; @Test public void getAllSeckill() throws Exception &#123; List&lt;Seckill&gt; list = seckillService.getAllSeckill(); logger.info(&quot;list =&#123;&#125;,&quot;,list); &#125; @Test public void getBySeckillId() throws Exception &#123; Seckill seckill = seckillService.getBySeckillId(1000L); logger.info(&quot;list =&#123;&#125;,&quot;,seckill); &#125; @Test public void exportSeckillUrl() throws Exception &#123; Exposer exposer = seckillService.exportSeckillUrl(1000L); logger.info(&quot;exposer =&#123;&#125;,&quot;,exposer); /** * exposer =Exposer&#123;exposed=true, md5=&apos;d592364bb958482949d97e04131f4b2e&apos;, seckillId=1000, now=null, start=null, end=null&#125;, */ &#125; @Test public void executeSeckill() throws Exception &#123; long id =1000L; long phone= 1245564659; String md5=&quot;d592364bb958482949d97e04131f4b2e&quot;; try &#123; SeckillExecution seckillExecution = seckillService.executeSeckill(id, phone, md5); logger.info(&quot;seckillExecution:&quot; + seckillExecution); &#125; catch(RepatKillException e)&#123; logger.error(e.getMessage()); &#125; catch (SeckillClosedException e)&#123; logger.error(e.getMessage()); &#125; /** * 再一次执行秒杀会出现运行期异常. * org.seckill.exception.RepatKillException: Seckill repeted! */ &#125; @Test public void testSeckillLogic() throws Exception&#123; long id =1000L; Exposer exposer = seckillService.exportSeckillUrl(id); logger.info(&quot;exposer =&#123;&#125;,&quot;,exposer); if(exposer.isExposed())&#123; //开始执行秒杀 long phone= 1245564359; String md5 = exposer.getMd5(); try &#123; SeckillExecution seckillExecution = seckillService.executeSeckill(id, phone, md5); logger.info(&quot;seckillExecution:&quot; + seckillExecution); &#125; catch(RepatKillException e)&#123; logger.error(e.getMessage()); &#125; catch (SeckillClosedException e)&#123; logger.error(e.getMessage()); &#125; &#125; else&#123; logger.warn(&quot;exposer=&#123;&#125;&quot;,exposer); &#125; &#125;//id=1001 的测试 seckillExecution:SeckillExecution&#123;seckillId=1001, state=1, stateInfo=&apos;秒杀成功!&apos;, successKilled=SuccessKilled&#123;seckillId=1001, userPhone=1245564359, state=0, createTime=Tue Feb 20 13:19:46 CST 2018&#125;&#125;//id=1000 的测试 21:22:24.838 [main] WARN o.secKill.service.SeckillServiceTest - exposer=Exposer&#123;exposed=false, md5=&apos;null&apos;, seckillId=1000, now=Tue Feb 20 21:22:24 CST 2018, start=Tue Feb 20 12:41:15 CST 2018, end=Tue Feb 20 12:41:15 CST 2018&#125;&#125;]]></content>
      <categories>
        <category>Seckill</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>SSM</tag>
        <tag>Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀高并发优化]]></title>
    <url>%2F2018%2F01%2F02%2F%E7%A7%92%E6%9D%80%E9%AB%98%E5%B9%B6%E5%8F%91%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[高并发发生的位置图示: 红色: 可能出现高并发. 绿色: 忽略不计 详情页的分析秒杀时间要到的时候,用户会自然而然的刷新秒杀页面. CDN的理解12341. CDN(内部分发网络)加速用户获取数据的系统2. 部署在里用户最近的网络节点上3. 命中CDN不需要访问后端服务器4. 互联网公司有自己搭建或者租用 系统时间优不优化?运行一次内存(Cacheline)大约10ns(可忽略不计) 我们单独获取系统时间,在Controller里面做了一个接口. 秒杀地址接口分析1231. 无法使用CDN缓存2. 适合服务器端缓存:Redis等3. 一致性维护成本低 秒杀地址接口优化存在的问题:1231. 无法使用CDN缓存(用的别人的)2. 后端缓存困难:库存问题3. 一行数据竞争:热点商品 解决方式: 其他方案分析 成本分析 mysqlUpdate测试 mysqlUpdate压力测试:同一个商品1S钟可以被卖4W次但是我们并不使用mysql来解决高并发的问题,一般认为mysql比较低效. java控制事务行为的分析以一条更新语句为例: 当所有人都去购买同一个商品的时候,都执行update操作,这样会造成用户阻塞,当排队排在最前的用户commit的时候,后面的用户才能执行update,会存在串行化的问题. 只有上一条更新操作commit的时候,下一条update SQL语句,获得行锁,才能执行更新操作. 行级锁是在Commit之后释放. 高并发的难点所在 行级锁在Commit提交之后释放,要想办法减少行级锁持有的时间. 但是大部分的MySQL数据库都是云服务,部署在异地机房,就有有传播延迟,实际约20ms. 所以延迟问题也会造成行锁释放需要的时间更加长. 比如下图: 判断Update更新库存成功有两个条件:– update自身运行没出错– 客户端确认Update影响记录数 – 优化方法: 把客户端逻辑放到Mysql服务端.避免网络延迟和GC影响. 将客户端逻辑放到Mysql服务端的方法:123456789101112131415161718192021222324251. 定制Mysql方案:update/*+[auto_commit]*/,需要修改mysql的源码2. 使用存储过程:整个事务在Mysql端完成.```` ### 总结* 前端控制暴露接口,按钮防止重复.* 动静态数据分离:CDN缓存,后端缓存.* 事务竞争优化:减少事务锁时间.## Redis的使用```androiddatabinding使用redis优化地址暴露接口makemake install -- 需要GCC的环境redis-server集群环境下的查看监控日志:redis-sentinel sentinel.conf加入pom.xml依赖&lt;!--Redis客户端的支持--&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.7.2&lt;/version&gt; &lt;/dependency&gt; Redis后端缓存优化我们知道在暴露接口的实现发过程中,我们是使用主键查询的方式来工作的,这样访问速度很快.但是频繁的访问数据库,给我们的服务器造成了很大的压力. 我们希望Redis来做缓存,来降低访问数据库的压力. 优化编码优化的是秒杀暴露接口,就是通过Id去查询商品的那个方法.12 传输的就是二进制的数据,所以需要将对象序列化. 一般在实体上implements serializable,这是jdk自带的序列话机制. JVM 性能比对. 123采用自定义序列化(protostuff)把我们的对象转换为二进制的数组(字节数组)存到Redis当中. protostuff序列化的依赖1234567891011&lt;!--ProtoStuff的序列化依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt; &lt;version&gt;1.0.8&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt; &lt;version&gt;1.0.8&lt;/version&gt; &lt;/dependency&gt; 添加Redis服务1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192/** * 缓存优化 * get from cache * if null * getdb * else * put cache * locgoin */public class RedisDao &#123; private JedisPool jedisPool; private Logger logger = LoggerFactory.getLogger(this.getClass()); /** * 传入地址&amp;&amp;端口 * * @param ip * @param port */ public RedisDao(String ip, int port) &#123; jedisPool = new JedisPool(ip, port); &#125; /** * 通过类的字节码对象创建, * 通过类的反射可以拿到类有什么属性,哪些方法. * RunTimeSchema就是基于类的属性去做一个模式. * 创建对象的时候,会根据模式赋予相应的值. */ private RuntimeSchema&lt;Seckill&gt; schema = RuntimeSchema.createFrom(Seckill.class); /** * 取出Seckill * * @param seckillId * @return */ public Seckill getSeckill(long seckillId) &#123; //Redis缓存的逻辑:先拿到对象,判断对象是否存在,将其反序列化成对象. try &#123; Jedis jedis = jedisPool.getResource(); try &#123; //前缀+值的模式 String key = "seckill:" + seckillId; //但并没有实现内部序列化操作 //get--&gt;byte[]--&gt;反序列化--&gt;Object[Seckill] byte[] bytes = jedis.get(key.getBytes()); if (bytes != null) &#123; //就将这个字节数组利用protostuff序列化 //创建一个空对象 Seckill seckill = schema.newMessage(); //按照schema把数据传输到空对象里面去 ProtostuffIOUtil.mergeFrom(bytes,seckill,schema); //seckill被反序列化,空间压缩到原生jdk处理的十分之一,压缩速度快,节省了CPU. return seckill; &#125; &#125; finally &#123; jedis.close(); &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return null; &#125; /** * 往里面防止Seckill对象 * * @param seckill * @return */ public String putSeckill(Seckill seckill) &#123; //set Object[Seckill] --&gt; 序列化--&gt;byte[] Jedis jedis = jedisPool.getResource(); try &#123; try &#123; String key="seckill:"+seckill.getseckillId(); //将其转为字节数组,里面内置了一个缓存器,如果当前对象特别大,会有一个缓冲的过程. byte[] bytes = ProtostuffIOUtil.toByteArray(seckill, schema, LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE)); //经测试,这个字节数组的大小为51 //超时缓存 int timeout =60 * 60; String result = jedis.setex(key.getBytes(), timeout, bytes); return result; &#125; finally &#123; jedis.close(); &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(), e); &#125; return null; &#125;&#125; 测试类12345678910111213141516171819202122232425@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;&quot;classpath:spring/spring-dao.xml&quot;&#125;)public class BaseTest &#123; private long id = 1001; @Autowired private RedisDao redisDao; @Autowired private SecKillDao secKillDao; @Test public void testRedisDao() &#123; Seckill seckill = redisDao.getSeckill(id); if (seckill == null) &#123; seckill = secKillDao.queryById(id); if (seckill != null) &#123; String result = redisDao.putSeckill(seckill); System.out.println(&quot;存入是否成功:&quot; + result); seckill = redisDao.getSeckill(id); System.out.println(&quot;取出的SeckillShop是:&quot; + seckill); &#125; &#125; &#125;&#125; 并发优化事务的发生: 目的就是要缩短update 减库存的时候使用行级锁,到commit事务的时候释放行级锁的时间.1234567我们把insert语句放在update语句的前面,因为他会做一个判断.insert ignore 插入成功,返回1,代表插入一行.插入失败,返回0.根据返回值来确定是否执行Update,update就是减少库存,返回1执行成功,返回0执行失败.主要目的就是降低mysql-rowLock的持有时间. 找到SeckillService 改造SeckillServiceImpl中的代码: 将先执行update操作&amp;&amp;insert明细 改造成 insert操作在前然后update在后的样子 这样做的好处是缩短了获得行级锁的时间.12345678910update insert update insert 2个事务前面先占用行级锁,然后再插入明细 后面等待行级锁,再执行插入操作,这样等待行级锁的时间会更长.insert update insert update 前面插入完毕后,执行update才占用行级锁 后面先插入,然后等待行级锁.也就是两个事务同时insert的情况下,没有锁竞争,执行速度会快. 改造代码如下:1234567891011121314151617181920//写明细 int insertState = successKilledDao.insertSuccessKilled(seckillId, userPhone); //唯一的验证标准就是验证 秒杀商品的ID和用户手机号. //之前秒杀成功,state=1.再次秒杀同一seckillId的商品,他就会秒杀不成功了,因为我们设置的是insert ignore,插入就会忽略,insertState返回的就是0. if (insertState &lt;= 0) &#123; //重复秒杀 throw new RepatKillException(&quot;Seckill repeted!&quot;); &#125; else &#123; //减库存,热点商品竞争发生在这个地方 int updateCount = secKillDao.reduceNumber(seckillId, killTime); //更新数&lt;0,说明减库存失败,没有更新到记录 if (updateCount &lt;= 0) &#123; //没有更新到记录,秒杀结束,rollback throw new SeckillClosedException(&quot;Seckill is closed!&quot;); &#125; else &#123; //秒杀成功,commit SuccessKilled successKilled = successKilledDao.querySuccessKilledWithSeckill(seckillId, userPhone); return new SeckillExecution(seckillId, SeckillStatEnum.SUCCESS, successKilled); &#125; &#125; 事务SQL在Mysql客户端执行.存储过程做优化. 目的:降低行级锁到commit的持续时间,同时让mysql获得更高的QPS. 编写mysql的存储过程 123456789101112131415161718192021222324252627282930313233343536373839404142DELIMITER $$ --console 默认的分隔符是; 现在将 ; 转换为 $$,这样看着舒服 --定义存储过程 --参数:in 输入参数; out 输入参数 --row_count():返回上一条修改类型sql的影响行数 --row_count :0;未修改数据; &gt;0;表示修改的行数;&lt;0:sql错误或者未执行sql CREATE PROCEDURE `seckill`.`execute_seckill` (in v_seckill_id bigint,in v_phone bigint, in v_kill_time timestamp,out r_result int) BEGIN DECLARE insert_count int default 0; START TRANSACTION; insert ignore into success_killed (seckill_id,user_phone,create_time) values (v_seckill_id,v_phone,v_kill_time); select row_count() into insert_count; IF (insert_count = 0) THEN ROLLBACK; set r_result = -1; ELSEIF (insert_count &lt; 0) THEN ROLLBACK; set r_result = -2; ELSE update seckill set number = number -1 where seckill_id = v_seckill_id and start_time &lt; v_kill_time and end_time &gt; v_kill_time and number &gt; 0; select row_count() into insert_count; IF (insert_count = 0) THEN ROLLBACK; set r_result = 0; ELSEIF (insert_count &lt; 0) THEN ROLLBACK; set r_result = -2; ELSE COMMIT; set r_result = 1; END IF; END IF; END; $$ 执行存储的过程 1234567先把分隔符改回来DELIMITER ;1.定义一个常量-- 执行存储过程call execute_seckill(1003,13784832739,now(),@r_result);-- 获取结果select @r_result; 可以看到结果是result=1,执行秒杀成功. 我们可以查看库存和明细表. 具体实现mysql的存储过程秒杀商品编写service层接口12345678/** * 主要是完成mysql的存储过程 * @param seckillId * @param userPhone * @param md5 * @return */ SeckillExecution executeSeckillProcedure(long seckillId, long userPhone, String md5); 编写Dao层接口12345/** * 使用存储过程执行秒杀 * @param paramMap */ void killByProcedure(Map&lt;String,Object&gt; paramMap); mapper中的写法123456789&lt;!--mybati调用存储过程--&gt; &lt;select id=&quot;killByProcedure&quot; statementType=&quot;CALLABLE&quot;&gt; call execute_seckill( #&#123;seckillId,jdbcType=BIGINT,mode=IN&#125;, #&#123;phone,jdbcType=BIGINT,mode=IN&#125;, #&#123;killTime,jdbcType=TIMESTAMP,mode=IN&#125;, #&#123;result,jdbcType=INTEGER,mode=OUT&#125; ) &lt;/select&gt; 引入依赖Commons-collections123456&lt;!-- https://mvnrepository.com/artifact/commons-collections/commons-collections --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt; &lt;/dependency&gt; 编写Service层接口123456789101112131415161718192021222324252627282930public SeckillExecution executeSeckillProcedure(long seckillId, long userPhone, String md5) &#123; //校验MD5 if(md5 == null || !md5.equals(getMd5(seckillId)) )&#123; return new SeckillExecution(seckillId,SeckillStatEnum.DATA_REWRITE); &#125; Date killTime = new Date(); HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;seckillId&quot;,seckillId); map.put(&quot;phone&quot;,userPhone); map.put(&quot;killTime&quot;,killTime); map.put(&quot;result&quot;,null); //执行存储过程,result被赋值 try &#123; secKillDao.killByProcedure(map); //获取Result Integer result = MapUtils.getInteger(map, &quot;result&quot;, -2); if(result == 1 )&#123; SuccessKilled successKilled = successKilledDao.querySuccessKilledWithSeckill(seckillId, userPhone); return new SeckillExecution(seckillId,SeckillStatEnum.SUCCESS,successKilled); &#125;else&#123; //根据Result去拿我们的秒杀状态. return new SeckillExecution(seckillId,SeckillStatEnum.stateOf(result)); &#125; &#125; catch (Exception e) &#123; logger.error(e.getMessage(),e); return new SeckillExecution(seckillId,SeckillStatEnum.INNER_ERROR); &#125; &#125; 测试类1234567891011121314151617/** * 测试mysql存储过程 */@Testpublic void executeSeckillByProcedure()&#123; long id =1003; long phone= 1358963569; Exposer exposer = seckillService.exportSeckillUrl(id); if(exposer.isExposed())&#123; //开始执行秒杀 String md5 = exposer.getMd5(); if(md5!= null)&#123; SeckillExecution seckillExecution = seckillService.executeSeckillProcedure(id, phone, md5); logger.info(seckillExecution.getStateInfo()); &#125; &#125; &#125; 替换Controller就把SeckillController中的秒杀方法改为executeSeckillByProcedure即可. 展示详情表列表 重复秒杀 秒杀成功 秒杀成功的json数据–execution展示.这是用存储过程来执行秒杀的.]]></content>
      <categories>
        <category>Seckill</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>RowsLock</tag>
        <tag>高并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库的基本操作]]></title>
    <url>%2F2018%2F01%2F01%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[RDBMS术语 数据库: 数据库是一些关联表的集合。 数据表: 表是数据的矩阵。在一个数据库中的表看起来像一个简单的电子表格. 列: 一列(数据元素) 包含了相同的数据, 例如邮政编码的数据。 行：一行（=元组，或记录）是一组相关的数据，例如一条用户订阅的数据。 冗余：存储两倍数据，冗余降低了性能，但提高了数据的安全性. 主键：主键是唯一的。一个数据表中只能包含一个主键。你可以使用主键来查询数据。 外键：外键用于关联两个表。 复合键：复合键（组合键）将多个列作为一个索引键，一般用于复合索引. 索引：使用索引可快速访问数据库表中的特定信息。索引是对数据库表中一列或多列的值进行排序的一种结构。类似于书籍的目录。 参照完整性: 参照的完整性要求关系中不允许引用不存在的实体。与实体完整性是关系模型必须满足的完整性约束条件，目的是保证数据的一致性。 mysql的数据类型目前我使用过的数据类型有 int varchar timestamp bigint smallint dater time year tinyint double 下面是标准数据库的类型 类型 大小 范围(有符号) 范围(无符号) 用途 TINYINT 1字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 FLOAT 4 字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度浮点数值 DOUBLE 8 字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度浮点数值 DECIMAL 对DECIMAL(M,D) ，如果M&gt;D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 时间类型 类型 大小 范围 格式 用途 DATE 3 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3 ‘-838:59:59’/‘838:59:59’ HH:MM:SS 时间值或持续时间 YEAR 1 1901/2155 YYYY 年份值 DATETIME 8 1000-01-01 00:00:00/9999-12-31 23:59:59 YYYY-MM-DD HH:MM:SS 混合日期和时间值 TIMESTAMP 4 1970-01-01 00:00:00/2038,结束时间是第 2147483647 秒，北京时间 2038-1-19 11:14:07，格林尼治时间 2038年1月19日 凌晨 03:14:07 YYYYMMDD HHMMSS 混合日期和时间值，时间戳 字符串类型 类型 大小 用途 CHAR 0-255字节 定长字符串 VARCHAR 0-65535 字节 变长字符串 TINYBLOB 0-255字节 不超过 255 个字符的二进制字符串 TINYTEXT 0-255字节 短文本字符串 BLOB 0-65 535字节 二进制形式的长文本数据 TEXT 0-65 535字节 长文本数据 MEDIUMBLOB 0-16777215字节 二进制形式的中等长度文本数据 MEDIUMTEXT 0-16777215字节 中等长度文本数据 LONGBLOB 0-4294967295字节 二进制形式的极大文本数据 LONGTEXT 0-4294967295字节 极大文本数据 1234567891011CHAR和VARCHAR类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。BINARY和VARBINARY类类似于CHAR和VARCHAR，不同的是它们包含二进制字符串而不要非二进制字符串。也就是说，它们包含字节字符串而不是字符字符串。这说明它们没有字符集，并且排序和比较基于列值字节的数值值。BLOB是一个二进制大对象，可以容纳可变数量的数据。有4种BLOB类型：TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB。它们只是可容纳值的最大长度不同。有4种TEXT类型：TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT。这些对应4种BLOB类型，有相同的最大长度和存储需求。 创建数据库create database student; 使用此数据库use student; 创建数据库表123456789create table student_inf( `student_id` int not null auto_increment comment '学生ID', `student_name` VARCHAR(21) not null comment "学生姓名", `student_age` int not null comment "学生年龄", `student_birthday` DATE not null comment "出生日期", `create_time` timestamp not null default current_timestamp comment "创建时间", primary key(student_id), key idx_create_time(create_time) )ENGINE=Innodb auto_increment = 1000 DEFAULT charset = utf8 comment ='学生信息表'; 我们可以查看表的结构: 删除数据表drop table table_name; 查看表的字段 查看索引show index from stundet_inf;show keys from student_inf; 这两种方式都可以,查出来是2条索引. 索引类型创建索引时,可以规定索引能否包含重复值,如果不包含,则索引应该创建为Primary key或者unique类型的索引. 对于单列惟一性索引，这保证单列不包含重复的值。 对于多列惟一性索引，保证多个值的组合不重复。 创建索引实际上就是,在表中哪列上添加索引 alter table student_inf add index idx_student_age(student_age); 此时我们可以查看一下索引有没有增加: 删除索引我们其实并不需要idx_stundet_age这个索引.索引多了会拖慢查询速度.影响CPU的处理性能. 所以删除:drop index idx_student_age on student_inf 此时再查询,就会发现还剩2个索引. 或者alter table student_inf drop index idx_student_age.这样也可以. 删除主键的操作不长使用,alter table student_inf drop primary key 因为一个表只可能有一个PRIMARY KEY索引，因此不需要指定索引名。 如果没有创建PRIMARY KEY索引，但表具有一个或多个UNIQUE索引，则MySQL将删除第一个UNIQUE索引。 如果从表中删除了某列，则索引会受到影响。 对于多列组合的索引，如果删除其中的某列，则该列也会从索引中删除。 如果删除组成索引的所有列，则整个索引将被删除。 插入语句 我们根据表的结构来进行insert 操作. 1insert into student_inf(student_id,student_name,student_age,student_birthday,create_time) values (null,'小明',12,'1995-05-02','2018-03-03 10:56:00'); update语句我们不小心犯错误了,把月份写成25月了. 所以采用下面的语句进行更新. 1update student_inf set student_birthday = '1995-02-02' where student_id =1000 ; 此时再看一下查询语句: 值得注意的是我们在生产环境中,不要使用select *来操作,这是查询表中所有的数据,会造成慢查询的问题. 删除语句delete from student_inf where student_id = 1000; 模糊查询 ##查看查询计划 我们可以看到查询用到了idx_create_time这个索引. Union操作符MySQL UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。 多个 SELECT 语句会删除重复的数据。 我们先来创建两个表 website表12345678910create table website( `website_id` int not null auto_increment comment '站点ID', `website_name` varchar(21) not null comment '站点名称', `website_url` varchar(100) not null comment '站点地址', `website_alexa` smallint not null comment '点击度排名', `website_country` VARCHAR(10) not null comment '站点服务维护所在国家', `create_time` timestamp not null default current_timestamp comment '创建时间', primary key(`website_id`), key idx_create_time(create_time) comment '创建间索引' )ENGINE=Innodb default charset =utf8; apps表123456789create table apps( `apps_id` int not null auto_increment comment '站点ID', `apps_name` varchar(21) not null comment '站点名称', `apps_url` varchar(100) not null comment '站点地址', `apps_country` VARCHAR(10) not null comment '站点服务维护所在国家', `create_time` timestamp not null default current_timestamp comment '创建时间', primary key(`apps_id`), key idx_create_time(create_time) comment '创建间索引' )ENGINE=Innodb default charset =utf8; 插入数据 1.插入website的数据12345insert into website(website_id,website_name,website_url,website_alexa,website_country,create_time) values(null,'Google','https://www.google.cm/',1,'USA',null);insert into website(website_id,website_name,website_url,website_alexa,website_country,create_time) values(null,'淘宝','https://www.taobao.cm/',13,'CN',null);再编几个吧 2.插入apps表的数据1insert into apps(apps_id,apps_name,apps_url,apps_country,create_time) values (null,'QQ APP','http://im.qq.com','CN',null); 3.使用union或者’union all’关键字来进行两个表之间的查询数据. 4.开始查询 union关键字的使用: union all 关键字的使用: 排序的使用(order by)下面的例子都是按照create_time来进行排序查询的. 倒序查询 正序查询 Mysql的分组(group by)查询GROUP BY 语句根据一个或多个列对结果集进行分组。 这个时候,我们来试试脚本运行的方法吧,换个样子肯定很舒服. 脚本如下,我们命名为schema.sql 123456789101112131415161718192021222324252627-- 选择你的目标数据库use mysqldemo;-- 开始执行下面的代码SET NAMES utf8;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for `employee_tbl`-- ----------------------------DROP TABLE IF EXISTS `employee_tbl`;CREATE TABLE `employee_tbl` ( `id` int(11) NOT NULL, `name` char(10) NOT NULL DEFAULT '', `date` datetime NOT NULL, `singin` tinyint(4) NOT NULL DEFAULT '0' COMMENT '登录次数', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- ------------------------------ Records of `employee_tbl`-- ----------------------------BEGIN;INSERT INTO `employee_tbl` VALUES ('1', '小明', '2016-04-22 15:25:33', '1'), ('2', '小王', '2016-04-20 15:25:47', '3'), ('3', '小丽', '2016-04-19 15:26:02', '2'), ('4', '小王', '2016-04-07 15:26:14', '4'), ('5', '小明', '2016-04-11 15:26:40', '4'), ('6', '小明', '2016-04-04 15:26:54', '2');COMMIT;SET FOREIGN_KEY_CHECKS = 1; 我们使用一下图形化工具MysqlWorkBench吧. 步骤:1.我们首先要创建一个新的schema. 2.导入数据 3.点击按钮,我们创建成功. 在脚本上好歹也要写上自己的目标数据库吧. 参考地址如何使用mysqlworkbench导入mysql脚本 分组测试1.查询数据 2.执行分组 我们将以上的数据表按照名字进行分组,在统计每个人登录的次数. select name, SUM(singin) as singin_count from employee_tbl group by name with rollup 这个with rollup的作用就是可以实现在分组统计数据基础上再进行相同的统计（SUM,AVG,COUNT…）.就相当于加上了最终的总数计算, 我们再试试count()函数,并使用 GROUP BY 语句 将数据表按名字进行分组，并统计每个人有多少条记录： null表示所有人登录的总次数,用null来表示太难看看,所以我们用coalesce语法来设计一下: select coalesce(a,b,c) 参数说明： 如果a==null,则选择b；如果b==null,则选择c； 如果a!=null,则选择a；如果a b c 都为null ，则返回为null（没意义）。 下面我们进行null的改写. mysql连接的使用一说连接,我们就要告别单表查询的时代了. Mysql的Join在两个或者多个表中查询数据. 可以在SELECT,UPDATE,DELETE语句中使用mysql的JOIN来联合多表查询. JOIN按照功能大致分为3类: 1231. inner join(内连接,或者等值连接):获取两个表中字段匹配关系的记录.2. Left join(左连接):获取左表所有记录,即使右表没有对应匹配的记录.3. Right join(右连接):与Left Join相反,用于获取右表所有记录,即使左表没有与之相匹配的数据. 既然需要关联两个表,我们就再设计一个student_sto12345678910create table student_scores( `student_id` int not null auto_increment comment '学生ID', `answer_person_name` VARCHAR(21) not null comment "答题人姓名", `math_scores` int not null comment "数学成绩", `language_scores` int not null comment "语文成绩", `physcial_score` int not null comment '物理成绩', `create_time` timestamp not null default current_timestamp comment "创建时间", primary key(student_id,answer_person_name), key idx_create_time(create_time) )ENGINE=Innodb auto_increment = 1000 DEFAULT charset = utf8 comment ='学生成绩表'; 这里我们用到了联合索引,且是用在了主键上.需要我们明白下面的意思: 123主键是唯一的。联合主键其实就是主键。只是联合主键是用2个或2个以上的字段组成主键。用这个主键包含的字段作为主键，这个组合在数据表中是唯一，且加了主键索引。 插入数据1insert into student_scores(student_id,answer_person_name,math_scores,language_scores,physcial_score,create_time)values(null,"小红",18,36,87,null); 1.和student_inf这张表做一个联合查询.我们先做’inner join’的实验. 12select s1.student_id,s1.student_name,s2.math_scores,s2.language_scores from student_inf s1 inner join student_scores s2 on s1.student_name = s2.answer_person_name;` 测试结果如下: 2.我们再做’left join’的实验. 1select s1.student_id,s1.student_name,s2.math_scores,s2.language_scores from student_inf s1 left join student_scores s2 on s1.student_name = s2.answer_person_name; 3.right join的测试 既然到这里,我们再深入一些,3表查询.也试一试吧.要不多没意思啊.又不是考试,但是我们要做到位.玩玩嘛. 再来一个表student_spending12345678910create table stundet_spending( student_id int not null auto_increment comment '学生ID', spending_person_name varchar(32) not null comment '消费者姓名', buy_book_spending int not null comment '买书钱', telephone_costs int not null comment '电话费', living_supplies_costs int not null comment '生活用品花费', create_time timestamp not null default current_timestamp comment '创建时间', primary key(student_id,spending_person_name), key idx_create_time(create_time))ENGINE=Innodb auto_increment = 1000 DEFAULT charset = utf8 comment ='学生花销表'; 插入数据 1insert into student_spending(student_id,spending_person_name,buy_book_spending,telephone_costs,living_supplies_costs,create_time) values(null,'小红',12,20,50,null); 我们来关联这3个表:1select s1.student_name,s1.student_age,s2.physcial_score,s3.buy_book_spending,s3.create_time from student_inf s1 inner join student_scores s2 on s1.student_name =s2.answer_person_name inner join student_spending s3 on s2.answer_person_name=s3.spending_person_name where s1.student_age = 18; mysql null 值处理MySQL 使用 SQL SELECT 命令及 WHERE 子句来读取数据表中的数据,但是当提供的查询条件字段为 NULL 时，该命令可能就无法正常工作。 为了处理这种情况，MySQL提供了三大运算符: IS NULL: 当列的值是 NULL,此运算符返回 true。 IS NOT NULL: 当列的值不为 NULL, 运算符返回 true。 &lt;=&gt;: 比较操作符（不同于=运算符），当比较的的两个值为 NULL 时返回 true。 关于 NULL 的条件比较运算是比较特殊的。你不能使用 = NULL 或 != NULL 在列中查找 NULL 值 。 在 MySQL 中，NULL 值与任何其它值的比较（即使是 NULL）永远返回 false，即 NULL = NULL 返回false 。 MySQL 中处理 NULL 使用 IS NULL 和 IS NOT NULL 运算符。 好吧,我们做个试验: 建表: 12345create table runoob_test_tbl ( runoob_author varchar(40) NOT NULL, runoob_count INT ); 插入数据 1234INSERT INTO runoob_test_tbl (runoob_author, runoob_count) values ('RUNOOB', 20);INSERT INTO runoob_test_tbl (runoob_author, runoob_count) values ('菜鸟教程', NULL);INSERT INTO runoob_test_tbl (runoob_author, runoob_count) values ('Google', NULL);INSERT INTO runoob_test_tbl (runoob_author, runoob_count) values ('FK', 20); 查询 1SELECT * from runoob_test_tbl; 测试 1234mysql&gt; SELECT * FROM runoob_test_tbl WHERE runoob_count = NULL;Empty set (0.00 sec)mysql&gt; SELECT * FROM runoob_test_tbl WHERE runoob_count != NULL;Empty set (0.01 sec) 正确的测试 12SELECT * FROM runoob_test_tbl WHERE runoob_count IS NULL;SELECT * from runoob_test_tbl WHERE runoob_count IS NOT NULL; mysql中,= 和 != 运算符是不起作用的; mysql的正则表达式MySQL中使用 REGEXP 操作符来进行正则表达式匹配。 1.查找runoob_author字段中以’st’为开头的所有数据：2.查找runoob_author字段以’OB’结尾的所有数据:3.查找runoob_author字段中所有内容包含O的所有数据: 4.查找runoob_author字段中以元音字符开头或以’OB’字符串结尾的所有数据： 正则表达式地址 Mysql的事务MySQL 事务主要用于处理操作量大，复杂度高的数据。 比如说，在人员管理系统中，你删除一个人员，你即需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这样，这些数据库操作语句就构成一个事务！ 在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务。 事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。 事务用来管理 insert,update,delete 语句 事务必须满足ACID这4个条件分别为: 原子性（Atomicity，或称不可分割性）. 一致性（Consistency）. 隔离性（Isolation，又称独立性）. 持久性（Durability）. 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 注意在 MySQL 命令行的默认设置下，事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务务须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交。 事务控制语句 BEGIN或START TRANSACTION；显式地开启一个事务； COMMIT；也可以使用COMMIT WORK，不过二者是等价的。COMMIT会提交事务，并使已对数据库进行的所有修改称为永久性的； ROLLBACK；有可以使用ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改； SAVEPOINT identifier；SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT； RELEASE SAVEPOINT identifier；删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常； ROLLBACK TO identifier；把事务回滚到标记点； SET TRANSACTION；用来设置事务的隔离级别。InnoDB存储引擎提供事务的隔离级别有READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。 Mysql事务处理主要有两种方法有2种方法1.用BEGIN,ROLLBACK,COMMIT来实现 BEGIN开始一个事务 ROLLBACK事务回滚 COMMIT事务确认 2.直接用SET来改变Mysql的自动提交模式 SET AUTOCOMMIT=0 禁止自动提交 SET AUTOCOMMIT=1 开启自动提交 事务测试1.一个完整的事务如下: 2.我们来看看rollback情况. 再开始一个事务,特别之处是它没有提交.并被回滚了. 所以自然没有插进数据. 3.查看mysql的隔离级别 select @@tx_isolation 可见mysql的隔离级别默认是可重复读. Alter命令当我们需要修改数据表名或者修改数据表字段时，就需要使用到MySQL ALTER命令。 我们先查看标的结构: 以下,2中查看方法是一致的. 删除,添加,或修改表字段.1.使用alter命令及drop字句删除表的i字段. alter table testalter_tbl drop i; 看一看更加全面的表结构.编码默认是gbk 2.增加一列 3.指定新增字段的位置. 执行下面的语句来测试,看看字段的位置有没有变化. 1234ALTER TABLE testalter_tbl DROP i;ALTER TABLE testalter_tbl ADD i INT FIRST;ALTER TABLE testalter_tbl DROP i;ALTER TABLE testalter_tbl ADD i INT AFTER c; 前两条SQL的执行结果: 后两条SQL的执行结果. 修改字段类型及名称. 改字段的类型 modify字段的使用. alter table testalter_tbl modify i bigint; 改字段的名称 字段名和类型全都改 5.解决对null值和默认值的影响 6.修改字段默认值 alter table testalter_tbl alter i set default 1000; 7.使用alter命令及drop字段来删除字段的默认值 8.修改数据表类型 alter table testalter_tbl engine = myisam; 9.修改表名ALTER TABLE testalter_tbl RENAME TO alter_tbl; 10.查看表的类型. show table status like &#39;testalter_tbl&#39;\G; 索引MySQL索引的建立对于MySQL的高效运行是很重要的，索引可以大大提高MySQL的检索速度。 打个比方，如果合理的设计且使用索引的MySQL是一辆兰博基尼的话，那么没有设计和使用索引的MySQL就是一个人力三轮车。 索引分单列索引和组合索引。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。 创建索引时，你需要确保该索引是应用在 SQL 查询语句的条件(一般作为 WHERE 子句的条件)。 实际上，索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录。 上面都在说使用索引的好处，但过多的使用索引将会造成滥用。因此索引也会有它的缺点：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件。 建立索引会占用磁盘空间的索引文件。 普通索引创建索引这是最基本的索引，它没有任何限制。它有以下几种创建方式： CREATE INDEX indexName ON mytable(username(length)); 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 修改表结构(添加索引)ALTER table tableName ADD INDEX indexName(columnName) 创建表的时候直接指定123456789CREATE TABLE mytable(ID INT NOT NULL,username VARCHAR(16) NOT NULL,INDEX [indexName] (username(length))); 删除索引的语法DROP INDEX [indexName] ON mytable; 唯一索引它与前面的普通索引类似，不同的就是：索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式： 创建索引CREATE UNIQUE INDEX indexName ON mytable(username(length)) 修改表结构ALTER table mytable ADD UNIQUE [indexName] (username(length)) 创建表的时候直接指定123456789CREATE TABLE mytable(ID INT NOT NULL,username VARCHAR(16) NOT NULL,UNIQUE [indexName] (username(length))); 使用ALTER 命令添加和删除索引有四种方式来添加数据表的索引： ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。 ALTER TABLE tbl_name ADD UNIQUE index_name (column_list): 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。 ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。 ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list): 该语句指定了索引为 FULLTEXT ，用于全文索引。 以下实例为在表中添加索引。 mysql&gt; ALTER TABLE testalter_tbl ADD INDEX (c); 你还可以在 ALTER 命令中使用 DROP 子句来删除索引。尝试以下实例删除索引: mysql&gt; ALTER TABLE testalter_tbl DROP INDEX c; 使用 ALTER 命令添加和删除主键主键只能作用于一个列上，添加主键索引时，你需要确保该主键默认不为空（NOT NULL）。实例如下：12mysql&gt; ALTER TABLE testalter_tbl MODIFY i INT NOT NULL;mysql&gt; ALTER TABLE testalter_tbl ADD PRIMARY KEY (i); 你也可以使用 ALTER 命令删除主键： mysql&gt; ALTER TABLE testalter_tbl DROP PRIMARY KEY; 删除主键时只需指定PRIMARY KEY，但在删除索引时，你必须知道索引名。 显示索引信息你可以使用 SHOW INDEX 命令来列出表中的相关的索引信息。可以通过添加 \G 来格式化输出信息。 尝试以下实例: mysql&gt; SHOW INDEX FROM table_name; \G 临时表MySQL 临时表在我们需要保存一些临时数据时是非常有用的。临时表只在当前连接可见，当关闭连接时，Mysql会自动删除表并释放所有空间。 临时表在MySQL 3.23版本中添加，如果你的MySQL版本低于 3.23版本就无法使用MySQL的临时表。不过现在一般很少有再使用这么低版本的MySQL数据库服务了。 MySQL临时表只在当前连接可见，如果你使用PHP脚本来创建MySQL临时表，那每当PHP脚本执行完成后，该临时表也会自动销毁。 如果你使用了其他MySQL客户端程序连接MySQL数据库服务器来创建临时表，那么只有在关闭客户端程序时才会销毁临时表，当然你也可以手动销毁。 1234567891011121314151617181920mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; ('cucumber', 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec) 当你使用 SHOW TABLES命令显示数据表列表时，你将无法看到 SalesSummary表。 如果你退出当前MySQL会话，再使用 SELECT命令来读取原先创建的临时表数据，那你会发现数据库中没有该表的存在，因为在你退出时该临时表已经被销毁了。 删除临时表默认情况下，当你断开与数据库的连接后，临时表就会自动被销毁。当然你也可以在当前MySQL会话使用 DROP TABLE 命令来手动删除临时表。1234567891011121314151617181920212223mysql&gt; CREATE TEMPORARY TABLE SalesSummary ( -&gt; product_name VARCHAR(50) NOT NULL -&gt; , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 -&gt; , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 -&gt; , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql&gt; INSERT INTO SalesSummary -&gt; (product_name, total_sales, avg_unit_price, total_units_sold) -&gt; VALUES -&gt; ('cucumber', 100.25, 90, 2);mysql&gt; SELECT * FROM SalesSummary;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec)mysql&gt; DROP TABLE SalesSummary;mysql&gt; SELECT * FROM SalesSummary;ERROR 1146: Table 'RUNOOB.SalesSummary' doesn't exist 复制表如果我们需要完全的复制MySQL的数据表，包括表的结构，索引，默认值等。 如果仅仅使用CREATE TABLE … SELECT 命令，是无法实现的。 本章节将为大家介绍如何完整的复制MySQL数据表，步骤如下： 使用 SHOW CREATE TABLE 命令获取创建数据表(CREATE TABLE) 语句，该语句包含了原数据表的结构，索引等。 复制以下命令显示的SQL语句，修改数据表名，并执行SQL语句，通过以上命令 将完全的复制数据表结构。 如果你想复制表的内容，你就可以使用 INSERT INTO … SELECT 语句来实现。 实例尝试以下实例来复制表 runoob_tbl 。12345678910111213141516171819202122232425262728293031323334353637383940414243444546步骤一：获取数据表的完整结构。mysql&gt; SHOW CREATE TABLE runoob_tbl \G;*************************** 1. row *************************** Table: runoob_tblCreate Table: CREATE TABLE `runoob_tbl` ( `runoob_id` int(11) NOT NULL auto_increment, `runoob_title` varchar(100) NOT NULL default '', `runoob_author` varchar(40) NOT NULL default '', `submission_date` date default NULL, PRIMARY KEY (`runoob_id`), UNIQUE KEY `AUTHOR_INDEX` (`runoob_author`)) ENGINE=InnoDB1 row in set (0.00 sec)ERROR:No query specified步骤二：修改SQL语句的数据表名，并执行SQL语句。mysql&gt; CREATE TABLE `clone_tbl` ( -&gt; `runoob_id` int(11) NOT NULL auto_increment, -&gt; `runoob_title` varchar(100) NOT NULL default '', -&gt; `runoob_author` varchar(40) NOT NULL default '', -&gt; `submission_date` date default NULL, -&gt; PRIMARY KEY (`runoob_id`), -&gt; UNIQUE KEY `AUTHOR_INDEX` (`runoob_author`)-&gt; ) ENGINE=InnoDB;Query OK, 0 rows affected (1.80 sec)步骤三：执行完第二步骤后，你将在数据库中创建新的克隆表 clone_tbl。 如果你想拷贝数据表的数据你可以使用 INSERT INTO... SELECT 语句来实现。mysql&gt; INSERT INTO clone_tbl (runoob_id, -&gt; runoob_title, -&gt; runoob_author, -&gt; submission_date) -&gt; SELECT runoob_id,runoob_title, -&gt; runoob_author,submission_date -&gt; FROM runoob_tbl;Query OK, 3 rows affected (0.07 sec)Records: 3 Duplicates: 0 Warnings: 0执行以上步骤后，你将完整的复制表，包括表结构及表数据。 mysql的元数据你可能想知道MySQL以下三种信息： 查询结果信息： SELECT, UPDATE 或 DELETE语句影响的记录数。 数据库和数据表的信息： 包含了数据库及数据表的结构信息。 MySQL服务器信息： 包含了数据库服务器的当前状态，版本号等。在MySQL的命令提示符中，我们可以很容易的获取以上服务器信息。 但如果使用Perl或PHP等脚本语言，你就需要调用特定的接口函数来获取。 接下来我们会详细介绍。 获取查询语句影响的记录数PERL 实例在 DBI 脚本中， 语句影响的记录数通过函数 do( ) 或 execute( )返回：1234567891011# 方法 1# 使用do( ) 执行 $querymy $count = $dbh-&gt;do ($query);# 如果发生错误会输出 0printf "%d 条数据被影响\n", (defined ($count) ? $count : 0);# 方法 2# 使用prepare( ) 及 execute( ) 执行 $querymy $sth = $dbh-&gt;prepare ($query);my $count = $sth-&gt;execute ( );printf "%d 条数据被影响\n", (defined ($count) ? $count : 0); 数据库和数据表列表你可以很容易的在MySQL服务器中获取数据库和数据表列表。 如果你没有足够的权限，结果将返回 null。 你也可以使用 SHOW TABLES 或 SHOW DATABASES 语句来获取数据库和数据表列表。 REAL实例12345# 获取当前数据库中所有可用的表。my @tables = $dbh-&gt;tables ( );foreach $table (@tables )&#123; print "表名 $table\n";&#125; 获取服务器元数据以下命令语句可以在 MySQL 的命令提示符使用，也可以在脚本中 使用，如PHP脚本。 mysql的序列MySQL序列是一组整数：1, 2, 3, …，由于一张数据表只能有一个字段自增主键， 如果你想实现其他字段也实现自动增加，就可以使用MySQL序列来实现。 本章我们将介绍如何使用MySQL的序列。 使用AUTO_INCREMENTMySQL中最简单使用序列的方法就是使用 MySQL AUTO_INCREMENT 来定义列。 实例 以下实例中创建了数据表insect， insect中id无需指定值可实现自动增长。 123456789101112131415161718192021222324mysql&gt; CREATE TABLE insect -&gt; ( -&gt; id INT UNSIGNED NOT NULL AUTO_INCREMENT, -&gt; PRIMARY KEY (id), -&gt; name VARCHAR(30) NOT NULL, # type of insect -&gt; date DATE NOT NULL, # date collected -&gt; origin VARCHAR(30) NOT NULL # where collected);Query OK, 0 rows affected (0.02 sec)mysql&gt; INSERT INTO insect (id,name,date,origin) VALUES -&gt; (NULL,'housefly','2001-09-10','kitchen'), -&gt; (NULL,'millipede','2001-09-10','driveway'), -&gt; (NULL,'grasshopper','2001-09-10','front yard');Query OK, 3 rows affected (0.02 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; SELECT * FROM insect ORDER BY id;+----+-------------+------------+------------+| id | name | date | origin |+----+-------------+------------+------------+| 1 | housefly | 2001-09-10 | kitchen || 2 | millipede | 2001-09-10 | driveway || 3 | grasshopper | 2001-09-10 | front yard |+----+-------------+------------+------------+3 rows in set (0.00 sec) 获取AUTO_INCREMENT值在MySQL的客户端中你可以使用 SQL中的LAST_INSERT_ID( ) 函数来获取最后的插入表中的自增列的值。 在PHP或PERL脚本中也提供了相应的函数来获取最后的插入表中的自增列的值。 PERL实例使用 mysql_insertid 属性来获取 AUTO_INCREMENT 的值。 实例如下：123$dbh-&gt;do ("INSERT INTO insect (name,date,origin)VALUES('moth','2001-09-14','windowsill')");my $seq = $dbh-&gt;&#123;mysql_insertid&#125;; 重置序列如果你删除了数据表中的多条记录，并希望对剩下数据的AUTO_INCREMENT列进行重新排列，那么你可以通过删除自增的列，然后重新添加来实现。 不过该操作要非常小心，如果在删除的同时又有新记录添加，有可能会出现数据混乱 操作如下所示：1234mysql&gt; ALTER TABLE insect DROP id;mysql&gt; ALTER TABLE insect -&gt; ADD id INT UNSIGNED NOT NULL AUTO_INCREMENT FIRST, -&gt; ADD PRIMARY KEY (id); 设置序列的开始值一般情况下序列的开始值为1，但如果你需要指定一个开始值100，那我们可以通过以下语句来实现：12345678mysql&gt; CREATE TABLE insect -&gt; ( -&gt; id INT UNSIGNED NOT NULL AUTO_INCREMENT, -&gt; PRIMARY KEY (id), -&gt; name VARCHAR(30) NOT NULL, -&gt; date DATE NOT NULL, -&gt; origin VARCHAR(30) NOT NULL)engine=innodb auto_increment=100 charset=utf8; 或者你也可以在表创建成功后，通过以下语句来实现： mysql&gt; ALTER TABLE t AUTO_INCREMENT = 100; MySQL 处理重复数据有些 MySQL 数据表中可能存在重复的记录，有些情况我们允许重复数据的存在，但有时候我们也需要删除这些重复的数据。 本章节我们将为大家介绍如何防止数据表出现重复数据及如何删除数据表中的重复数据。 防止表中出现重复数据你可以在MySQL数据表中设置指定的字段为 PRIMARY KEY（主键） 或者 UNIQUE（唯一） 索引来保证数据的唯一性。 让我们尝试一个实例：下表中无索引及主键，所以该表允许出现多条重复记录。123456CREATE TABLE person_tbl( first_name CHAR(20), last_name CHAR(20), sex CHAR(10)); 如果你想设置表中字段first_name，last_name数据不能重复，你可以设置双主键模式来设置数据的唯一性， 如果你设置了双主键，那么那个键的默认值不能为NULL，可设置为NOT NULL。 如下所示：1234567CREATE TABLE person_tbl( first_name CHAR(20) NOT NULL, last_name CHAR(20) NOT NULL, sex CHAR(10), PRIMARY KEY (last_name, first_name)); 如果我们设置了唯一索引，那么在插入重复数据时，SQL语句将无法执行成功,并抛出错。 INSERT IGNORE INTO与INSERT INTO的区别就是INSERT IGNORE会忽略数据库中已经存在的数据，如果数据库没有数据，就插入新的数据，如果有数据的话就跳过这条数据。这样就可以保留数据库中已经存在数据，达到在间隙中插入数据的目的 以下实例使用了INSERT IGNORE INTO，执行后不会出错，也不会向数据表中插入重复数据：123456mysql&gt; INSERT IGNORE INTO person_tbl (last_name, first_name) -&gt; VALUES( 'Jay', 'Thomas');Query OK, 1 row affected (0.00 sec)mysql&gt; INSERT IGNORE INTO person_tbl (last_name, first_name) -&gt; VALUES( 'Jay', 'Thomas');Query OK, 0 rows affected (0.00 sec) INSERT IGNORE INTO当插入数据时，在设置了记录的唯一性后，如果插入重复数据，将不返回错误，只以警告形式返回。 而REPLACE INTO into如果存在primary 或 unique相同的记录，则先删除掉。再插入新记录 另一种设置数据的唯一性方法是添加一个UNIQUE索引，如下所示：1234567CREATE TABLE person_tbl( first_name CHAR(20) NOT NULL, last_name CHAR(20) NOT NULL, sex CHAR(10) UNIQUE (last_name, first_name)); 统计重复数据以下我们将统计表中 first_name 和 last_name的重复记录数：1234mysql&gt; SELECT COUNT(*) as repetitions, last_name, first_name -&gt; FROM person_tbl -&gt; GROUP BY last_name, first_name -&gt; HAVING repetitions &gt; 1; 以上查询语句将返回 person_tbl 表中重复的记录数。 一般情况下，查询重复的值，请执行以下操作： 确定哪一列包含的值可能会重复。 在列选择列表使用COUNT(*)列出的那些列。 在GROUP BY子句中列出的列。 HAVING子句设置重复数大于1。 ###过滤重复数据 如果你需要读取不重复的数据可以在 SELECT 语句中使用 DISTINCT 关键字来过滤重复数据。12mysql&gt; SELECT DISTINCT last_name, first_name -&gt; FROM person_tbl; 你也可以使用 GROUP BY 来读取数据表中不重复的数据：123mysql&gt; SELECT last_name, first_name -&gt; FROM person_tbl -&gt; GROUP BY (last_name, first_name); 删除重复数据如果你想删除数据表中的重复数据，你可以使用以下的SQL语句： 12345mysql&gt; CREATE TABLE tmp SELECT last_name, first_name, sex -&gt; FROM person_tbl; -&gt; GROUP BY (last_name, first_name, sex);mysql&gt; DROP TABLE person_tbl;mysql&gt; ALTER TABLE tmp RENAME TO person_tbl; 当然你也可以在数据表中添加 INDEX（索引） 和 PRIMAY KEY（主键）这种简单的方法来删除表中的重复记录。 方法如下：12mysql&gt; ALTER IGNORE TABLE person_tbl -&gt; ADD PRIMARY KEY (last_name, first_name); MySQL 及 SQL 注入如果您通过网页获取用户输入的数据并将其插入一个MySQL数据库，那么就有可能发生SQL注入安全的问题。 本章节将为大家介绍如何防止SQL注入，并通过脚本来过滤SQL中注入的字符。 所谓SQL注入，就是通过把SQL命令插入到Web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。 我们永远不要信任用户的输入，我们必须认定用户输入的数据都是不安全的，我们都需要对用户输入的数据进行过滤处理。 以下实例中，输入的用户名必须为字母、数字及下划线的组合，且用户名长度为 8 到 20 个字符之间：123456789if (preg_match("/^\w&#123;8,20&#125;$/", $_GET['username'], $matches))&#123; $result = mysqli_query($conn, "SELECT * FROM users WHERE username=$matches[0]");&#125; else&#123; echo "username 输入异常";&#125; 让我们看下在没有过滤特殊字符时，出现的SQL情况： 123// 设定$name 中插入了我们不需要的SQL语句$name = "Qadir'; DELETE FROM users;"; mysqli_query($conn, "SELECT * FROM users WHERE name='&#123;$name&#125;'"); 以上的注入语句中，我们没有对 $name 的变量进行过滤，$name 中插入了我们不需要的SQL语句，将删除 users 表中的所有数据。 在PHP中的 mysqli_query() 是不允许执行多个 SQL 语句的，但是在 SQLite 和 PostgreSQL 是可以同时执行多条SQL语句的，所以我们对这些用户的数据需要进行严格的验证。 防止SQL注入，我们需要注意以下几个要点：1234561.永远不要信任用户的输入。对用户的输入进行校验，可以通过正则表达式，或限制长度；对单引号和 双"-"进行转换等。2.永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用存储过程进行数据查询存取。3.永远不要使用管理员权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。4.不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。5.应用的异常信息应该给出尽可能少的提示，最好使用自定义的错误信息对原始错误信息进行包装6.sql注入的检测方法一般采取辅助软件或网站平台来检测，软件一般采用sql注入检测工具jsky，网站平台就有亿思网站安全平台检测工具。MDCSOFT SCAN等。采用MDCSOFT-IPS可以有效的防御SQL注入，XSS攻击等。 防止SQL注入在脚本语言，如Perl和PHP你可以对用户输入的数据进行转义从而来防止SQL注入。 PHP的MySQL扩展提供了mysqli_real_escape_string()函数来转义特殊的输入字符。123456if (get_magic_quotes_gpc())&#123; $name = stripslashes($name);&#125;$name = mysqli_real_escape_string($conn, $name); mysqli_query($conn, "SELECT * FROM users WHERE name='&#123;$name&#125;'"); Like语句中的注入like查询时，如果用户输入的值有&quot;_&quot;和&quot;%&quot;，则会出现这种情况：用户本来只是想查询&quot;abcd_&quot;，查询结果中却有&quot;abcd_&quot;、&quot;abcde&quot;、&quot;abcdf&quot;等等；用户要查询&quot;30%&quot;（注：百分之三十）时也会出现问题。 在PHP脚本中我们可以使用addcslashes()函数来处理以上情况，如下实例：1234$sub = addcslashes(mysqli_real_escape_string($conn, "%something_"), "%_");// $sub == \%something\_ mysqli_query($conn, "SELECT * FROM messages WHERE subject LIKE '&#123;$sub&#125;%'");addcslashes() 函数在指定的字符前添加反斜杠。 语法格式: addcslashes(string,characters)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>增删改查</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀概述]]></title>
    <url>%2F2018%2F01%2F01%2F%E7%A7%92%E6%9D%80%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[涉及的内容:1.Mysql 表设计SQL技巧事务和行级锁 2.Mybatis dao层的设计和开发 mybatis的合理使用 mybatis与Spring整合 3.Spring Spring IOC整合Service 声明式事务运用 4.SpringMVC Restful接口设计和使用 框架运作流程 Controller开发技巧 5.前端 交互设计 Bootstrap JQuery,Ajax 6.高并发 优化,及优化思路. 创建maven项目mvn命令创建项目创建项目更加详细的链接 12345678910111213141516mvn archetype:generate -DarchetypeCatalog=internal -DgroupId=org.seckill -DartifactId=secKill -DarchetypeArtifactId=maven-archetype-webapp``` 值得注意的是,webapp下面的web.xml过时了不能使用,我们可以拿tomcat8里面的webapp/examples下面的web.xml的表头来操作:```androiddatabinding&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1" metadata-complete="true"&gt;&lt;/web-app&gt; pom.xml的配置1234567891.junit3使用的是编程式的测试,junit4使用的是声明式(注解)的测试2.java中常用的日志:slf4j,log4j,logback,common-logging sfl4j:是规范/接口 日志实现:log4j,logback,common-logging 使用:slf4j + logback3.数据库的相关组件4.mybatis的相关组件5.spring相关组件 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.seckill&lt;/groupId&gt; &lt;artifactId&gt;secKill&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;secKill Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;!--0.使用junit4,采用声明注解方式测试--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--1.日志选用slf4j和logback--&gt; &lt;!--日志使用slf4j--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt; &lt;/dependency&gt; &lt;!--实现了logback核心的功能--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--实现slf4j接口并整合--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--2.数据库相关的依赖--&gt; &lt;!--数据库驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;version&gt;5.1.35&lt;/version&gt; &lt;/dependency&gt; &lt;!--数据库连接池c3p0--&gt; &lt;dependency&gt; &lt;groupId&gt;c3p0&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--3.dao框架:mybatis依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--mybatis自身实现的spring整合依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--4.Service Web相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;jstl&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--5.Spring依赖--&gt; &lt;!--5.1.spring核心依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--5.2 spring的IOC--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--5.3 spring的包扫描.IOC拓展用到的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--5.4 spring Dao层的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--5.5 spring Transaction的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--5.6 spring Web的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--5.6 spring Test的相关依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.1.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;secKill&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; 秒杀业务的分析 可知,秒杀业务的核心是对库存的处理. 用户针对库存业务分析: 什么是购买行为? 记录秒杀成功信息 如果没有事务存在,可能会出现:1234561. 减库存没有购买明细,2. 记录了明细没有减库存,3. 超卖/少卖 故障责任… 数据落地: mysql VS nosql nosql对事务的支持不尽如意,但是对高性能,高可用支持非常棒. 事务机制仍然是目前最可靠的落地方案.mysql内置的事务机制很可靠. 5.秒杀业务的难点 难点在与竞争. 反映在mysql中是事务和行级锁. 我们做的事务流程: 1234567Start transaction Update 库存数量(竞争发生在这一块)Insert购买明细Commit 可见当所有人秒杀一件商品时,执行同一个SQL语句,由于采用的是行级锁,所以每次只能执行一条SQL语句. 现在看来,秒杀的难点就是如何高效的处理竞争了. 秒杀功能1231. 秒杀接口暴露2. 执行秒杀3. 相关查询 代码开发 123451. DAO设计编码 包括数据库的表设计,DAO的接口,mybatis如何去实现DAO.2.Service设计编码 Spring管理Service,声明式事务去标注方法是事务操作,简化事务控制3.Web设计编码]]></content>
      <categories>
        <category>Seckill</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown语法]]></title>
    <url>%2F2018%2F01%2F01%2FMarkdown%2F</url>
    <content type="text"><![CDATA[表格模板12345| Tables | Are | Cool || ------------- |:-------------:| -----:|| col 3 is | right-aligned | $1600 || col 2 is | centered | $12 || zebra stripes | are neat | $1 |]]></content>
      <categories>
        <category>Seckill</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[秒杀Dao层开发]]></title>
    <url>%2F2018%2F01%2F01%2F%E7%A7%92%E6%9D%80Dao%E5%B1%82%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[数据库设计编码数据库设计工作:123456789101112131415161718191.创建数据库seckill2.使用数据库seckill3.创建秒杀数据库存表: 3.1.存储引擎的选用. 3.2.具体字段的编辑. 3.3.索引的创建.4.初始化数据(插入几组数据)5.创建用户明细表秒杀成功明细表里面的主键不使用自增的主键,而是采用联合主键同一个用户只可能对同一个库存内的商品做秒杀,所以设计为PRIMARY_KEY(seckill_id,user_phone), 详情如下:!!! 千万注意:表的字段,比如:seckill_id里面是tab上面的那个符号,不要弄错了.我使的是5.7版本,还有就是创建时间戳的时候,需要给它设置一个默认值 创建秒杀数据库123456789101112CREATE TABLE seckill( `seckill_id` BIGINT NOT NULL AUTO_INCREMENT COMMENT &apos;商品库存id&apos;, `name` VARCHAR(120) NOT NULL COMMENT &apos;商品名称&apos;, `number` int NOT NULL COMMENT &apos;库存数量&apos;, `start_time` TIMESTAMP not null ON UPDATE CURRENT_TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT &apos;秒杀开始时间&apos;, `end_time` TIMESTAMP not null ON UPDATE CURRENT_TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT &apos;秒杀结束时间&apos;, `create_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &apos;创建时间&apos;, PRIMARY KEY (seckill_id), key idx_start_time(start_time), key idx_end_time(end_time), key idx_create_time(create_time))ENGINE=InnoDB AUTO_INCREMENT=1000 DEFAULT CHARSET=utf8 COMMENT =&apos;秒杀库存表&apos;; 查看表的详细计划:show create table seckill\G; 插入几组数据123456INSERT INTO seckill(name,number,start_time,end_time)VALUES(&apos;1000元秒杀iPad6&apos;,100,&apos;2018-1-31 16:31:00&apos;,&apos;2018-2-16 16:31:00&apos;),(&apos;500元秒杀iPad7&apos;,200,&apos;2018-1-31 16:31:00&apos;,&apos;2018-2-16 16:31:00&apos;),(&apos;300元秒杀小米4&apos;,300,&apos;2018-1-31 16:31:00&apos;,&apos;2018-2-16 16:31:00&apos;),(&apos;200元秒杀红米note&apos;,400,&apos;2018-1-31 16:31:00&apos;,&apos;2018-2-16 16:31:00&apos;); 创建用户明细表12345678create table success_killed( `seckill_id` bigint NOT NULL COMMENT &apos;秒杀商品Id&apos;, `user_phone` bigint NOT NULL COMMENT &apos;用户手机号&apos;, `state` tinyint NOT NULL DEFAULT -1 COMMENT &apos;状态标识:-1:无效,0:成功,1:已付款,2:已发货&apos;, `create_time` TIMESTAMP NOT NULL DEFAULT current_timestamp COMMENT &apos;创建时间&apos;, PRIMARY KEY (seckill_id,user_phone),/*联合索引*/ key idx_create_time(create_time))ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT =&apos;秒杀成功明细表&apos;; 现在发现IDEA里面用show CREATE TABLE success_killed;不用加上\G; 一般其他的控制台要加上\G;即:show CREATE TABLE success_killed\G; DAO相关接口编码DAO层接口的设计总的看来,我们的接口需要减少库存和增加明细的操作. 但是还要更加细致 其中,要注意的是,SuccessSeckilled是一个复合实体,里面有一个实体是Seckill,属于多对一的关系. 也就是同样的商品秒杀成功的话,可能有多个明细. SeckillDao接口的设计 根据商品ID和秒杀时间减少库存 根据商品Id秒杀商品 根据偏移量查询秒杀商品列表 1234567891011121314151617181920212223242526public interface SeckillDao &#123; /** * 减库存 * @param secKillId * @param killTime * @return 如果影响行数&gt;1,表示更新的记录行数(如果返回0,说明这条语句没有更新成功.) */ int reduceNumber(long secKillId, Date killTime); /** * 根据Id秒杀商品 * @param seckillId * @return */ Seckill queryById(long seckillId); /** * 根据偏移量查询秒杀商品列表 * @param limit 取多少条记录 * @param offet 偏移量 * @return 商品列表 * 会用到一个SQL的链接,因为是符合查询(查询秒杀明细(查询秒杀商品)) */ List&lt;Seckill&gt; queryAll(int offet,int limit);&#125; SuccessKilledDao接口的设计 插入用户秒杀明细 查询携带秒杀商品的明细 123456789101112131415161718192021/** * 1.插入用户购买明细,可过滤重复(之前设置的是联合主键,所以可以帮我们过滤重复) * 2.根据id查询Successkilled并携带Seckill实体 * */public interface SuccessKilledDao &#123; /** * 插入用户购买明细 * @param secKillId * @param userPhone * @return 插入的行数,就是秒杀成功的记录 */ int insertSuccessKilled(long secKillId,long userPhone); /** * 根据id查询Successkilled并携带Seckill实体 * @param secKillId * @return */ SuccessKilled querySuccessKilledWithSeckill(long secKillId);&#125; 基于MyBatis实现DAOmybatis与hibernate其实都是针对对象关系的映射框架. 把数据库中的东西映射到对象 反过来就把对象中的东西映射到数据库当中 图示: mybatis的特点参数+SQL=Entity/List SQL写在的位置 XML提供SQL(推荐) 2, 注解提供SQL 实现DAO接口: Mapper自动实现DAO接口(推荐) 我知道有一种是通过MyEclipse实现接口的方式,用起来挺爽的.但是不利于我们对设计接口的理解. 关注点:SQL如何编写,如何去设计DAO接口.节省了很多需要维护的程序.所有的实现都是mybatis自动完成. API编程的方式实现DAO接口 你可能会遗漏一些东西…影响工作效率 mybatis实现DAO编程mybatis官方文档地址Mybatis官方链接 驼峰命名转换:不用关心列名到属性名的转换了. 配置文件如下: mybatis-config.xml123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;!--1.配置全局属性--&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!--使用JDBC的getGenerateKeys 获取数据库自增主键值,默认是false--&gt; &lt;setting name=&quot;useGeneratekeys&quot; value=&quot;true&quot;/&gt; &lt;!--使用列别名替换别名,默认是true select name as title from table 列名name取得的列别名是title,mybatis会自动识别 --&gt; &lt;setting name=&quot;useColumnLable&quot; value=&quot;true&quot;/&gt; &lt;!--开启驼峰命名转换:Table(create_time)转为 Entity(createtime)--&gt; &lt;setting name=&quot;mapUnderscoreToCamelCase&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt;&lt;/configuration&gt; 配置文件mapper.xml 的书写12345678910111213141516171819202122232425261.引入方法内部的参数就跟HQL里里面的? 有类似之处#&#123;xxx&#125; xxx是方法里面的参数2.mybatis配置的xml文件内部不能识别的符号的改写方法&gt;=配置文件中不允许有&gt;=符号的出现,允许下面这种写法:&lt;![CDATA[ &lt;= ]]&gt;为了防止冲突,就是告诉 &lt;= 不是xml的语法3.resultType--实体类名 parameterType-参数类型多个参数并不用加上parameterType4.解决主键冲突的话,可能出现错误:需要在insert into 中间加上ignore,即:insert ignore into 这样重复插入的话,就会插入不成功.返回插入的数=05.解决mybatis把结果映射到表中同时映射表内部的实体问题可以利用内连接(inner join)来解决这个问题.select *from s s1inner join e e1 on s1.id = e1.idwhere s1.id =#&#123;Id&#125; Mapper下的两个映射文件: SeckillDao.xml12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;org.seckill.dao.SecKillDao&quot;&gt; &lt;!--目的:为DAO接口方法提供SQL语句配置--&gt; &lt;!--id就是方法名,看你的方法要执行什么操作了--&gt; &lt;update id=&quot;reduceNumber&quot;&gt; &lt;!--具体的SQL--&gt; UPDATE seckill SET number = number-1 WHERE seckill_id=#&#123;seckillId&#125; AND start_time &lt;![CDATA[ &lt;= ]]&gt; #&#123;killTime&#125; AND end_time &gt;= #&#123;killTime&#125; AND number &gt; 0; &lt;/update&gt; &lt;select id=&quot;queryById&quot; resultType=&quot;Seckill&quot; parameterType=&quot;long&quot;&gt; SELECT * FROM seckill WHERE seckill_id=#&#123;seckillId&#125; &lt;/select&gt; &lt;select id=&quot;queryAll&quot; resultType=&quot;Seckill&quot;&gt; SELECT * FROM seckill ORDER BY create_time DESC limit #&#123;offset&#125;,#&#123;limit&#125; &lt;/select&gt;&lt;/mapper&gt; SuccessKilledDao.xml12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;org.seckill.dao.SuccessKilledDao&quot;&gt; &lt;insert id=&quot;insertSuccessKilled&quot;&gt; &lt;!--如果主键冲突,报错--&gt; insert ignore into success_killed (seckill_id, user_phone,state) values (#&#123;seckillId&#125;,#&#123;userPhone&#125;,0); &lt;/insert&gt; &lt;select id=&quot;querySuccessKilledWithSeckill&quot; resultType=&quot;SuccessKilled&quot;&gt; &lt;!--根据id查询Successkilled并携带Seckill实体--&gt; &lt;!--如何告诉MyBatis把结果映射到SuccessKilled同时映射SecKill属性--&gt; &lt;!--最重要的原因就是:可以自由的控制SQL--&gt; SELECT sk.seckill_id, sk.user_phone, sk.create_time, sk.state, s.seckill_id &quot;seckill.seckill_id&quot;, s.name &quot;seckill.name&quot;, s.number &quot;seckill.number&quot;, s.start_time &quot;seckill.start_time&quot;, s.end_time &quot;seckill.end_time&quot;, s.create_time &quot;seckill.create_time&quot; FROM success_killed sk INNER JOIN seckill s ON sk.seckill_id=s.seckill_id WHERE sk.seckill_id=#&#123;seckillId&#125; and sk.user_phone=#&#123;userPhone&#125;; &lt;/select&gt;&lt;/mapper&gt; Mybatis整合Spring理论目标12345678910111213141516171819202122232425262728293031323334353637381.更少的编码 只写接口,不写实现类 接口本身就能说明很多事情 比如:Seckill queryById(long secKillID); 1.参数 --long 2.结果集 --SecKill 3.行为: query 根据上面的就可以写SQL,配置mapper.xml就可以了.2.更少的配置 1.别名 就比如:从resultType=&quot;Scekill&quot;来说吧,本来他应该写更长的名字才对,即resultType=&quot;org.seckill.dao.SecKillDao&quot; 但是可以简写的原因就是,mybatis帮我们实现了包扫描,即Package Scan 2.配置扫描 1. &lt;mapper resource=&quot;mapper/SeckillDao.xml&quot;/&gt; &lt;mapper resource=&quot;mapper/SuccessKilledDao.xml&quot;/&gt; ...... 当有很多这样的配置文件的话,我们会很费劲的添加,但mybatis有一个自动扫描配置文件的功能. 2.dao实现 一般就是&lt;bean id = &quot;xxxDao&quot; class =&quot;xxx.xxx.dao&quot;/&gt;的形式配置交给Spring容器管理. 要是有很多这样的配置文件的时候,我们就需要些很多这样的配置. mybatis可以自动实现DAO接口,统一叫Mapper,效率非常高, 但是不利于初学者的学习.我之前做的电商项目就是DAO用mybatis自动生成的文件. 因为出来一堆mapper,就是dao,和一堆映射文件xxxmapper.xml. 自动注入spring容器.3.足够的灵活性 1.自由定制SQL语句 2.自由传递传参 3.结果集自动赋值自由的传递参数,自由的返回实体的类型 XML提供SQL,DAO接口Mapper. 这种方式很好 mybatis整合spring编码spring整合mybatis官方文档Spring4.1.7官方版本 取它的容器头部.1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;...&quot; class=&quot;...&quot;&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt; &lt;bean id=&quot;...&quot; class=&quot;...&quot;&gt; &lt;!-- collaborators and configuration for this bean go here --&gt; &lt;/bean&gt;&lt;!-- more bean definitions go here --&gt;&lt;/beans&gt; 连接池的配置, c3p0连接池的配置:comboolPoolDataSource除了驱动类,URL,user,password之外.还有一些私有配置 maxPoolSize,每一个数据库中池子的最大数:,默认是15.minPoolSize,默认是3. autoCommitOnClose 连接池的Connection调用Close的时候,本质上是把连接对象放到池子当中,放到池子的过程当中,c3p0连接池要做一些清理工作. 当close连接的时候,不要commit checkoutTimeOut当maxPoolSize连接满的时候,等待连接的间隔时间,c3p0默认是0,无线等待. acquireRetryAttempts获取连接失败重试次数 &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt;后边的那个value值就是sqlSessionFactory的名字. 当MapperScannerConfigure启动的时候,可能会出现jdbc.properties里面的东西还没有被加载,不能拿到SQLSessionFactory里面的参数. 当用到mybatis的时候,才会去找对应的SqlSessionFactory. spring-dao.xml配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!--配置整合mybatis过程--&gt; &lt;!--1:配置数据库相关参数 properties的属性: $&#123;url&#125; --&gt; &lt;context:property-placeholder location=&quot;classpath:jdbc.properties&quot;/&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;&gt; &lt;!--配置连接池属性--&gt; &lt;property name=&quot;driverClass&quot; value=&quot;$&#123;jdbc.driver&#125;&quot;/&gt; &lt;property name=&quot;jdbcUrl&quot; value=&quot;$&#123;jdbc.url&#125;&quot;/&gt; &lt;property name=&quot;user&quot; value=&quot;$&#123;jdbc.username&#125;&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;jdbc.password&#125;&quot;/&gt; &lt;!--2:c3p0连接池的私有属性--&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;30&quot;/&gt; &lt;property name=&quot;minPoolSize&quot; value=&quot;10&quot;/&gt; &lt;!--关闭连接后不自动commit--&gt; &lt;property name=&quot;autoCommitOnClose&quot; value=&quot;false&quot;/&gt; &lt;!--获取连接超时时间--&gt; &lt;!--property name=&quot;checkoutTimeout&quot; value=&quot;8000&quot;/--&gt; &lt;!--当获取连接失败重试次数--&gt; &lt;property name=&quot;acquireRetryAttempts&quot; value=&quot;2&quot;/&gt; &lt;/bean&gt; &lt;!--3.配置SQLSessionFactory对象--&gt; &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;!--注入数据库连接池--&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;!--配置mybatis全局配置文件:mybatis-config.xml--&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:mybatis-config.xml&quot;/&gt; &lt;!--扫描Entity包 使用别名 org.seckill.entity.Seckill同一的转换为Seckill使用 有多个包的时候,可以分开写: value=&quot;org.seckill.entity;org.seckill.entity2&quot; --&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;org.seckill.entity&quot;/&gt; &lt;!--扫描SQL配置文件:mapper需要的xml文件--&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:mapper/*.xml&quot;/&gt; &lt;/bean&gt; &lt;!--4.配置扫描DAO接口包,动态实现Dao接口,并注入到Spring容器中. 可以看出这个类专门是扫描mapper的,而在mybatis中mapper就相当于dao --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!--注入SQLSessionFactory--&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;/&gt; &lt;!--给出需要扫描Dao接口包--&gt; &lt;property name=&quot;basePackage&quot; value=&quot;org.seckill.dao&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt; 单元测试spring 与junit整合 ctrl+shift+t创建单元测试类 RunWith(SpringJunit4ClassRunner.class)//junit启动时加载springIOC容器. @Resource不管用,改用@Autowired QueryAll方法测试遇到下面的绑定参数异常 1org.apache.ibatis.binding.BindingException: Parameter &apos;offset&apos; not found. Available parameters are [0, 1, param1, param2] 需要加上@Param(“实际形参”)1List&lt;Seckill&gt; queryAll(@Param(&quot;offset&quot;) int offset, @Param(&quot;limit&quot;) int limit); SeckillDaoTest测试:12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 配置Spring和junit整合,junit启动时加载springIOC容器 * spring-test,junit */@RunWith(SpringJUnit4ClassRunner.class)//告诉junitspring配置文件的位置@ContextConfiguration(&#123;&quot;classpath:spring/spring-dao.xml&quot;&#125;)public class SecKillDaoTest &#123; //注入Dao @Autowired private SecKillDao secKillDao; /** * Preparing: SELECT seckill.seckill_id,seckill.name,seckill.number,seckill.start_time,seckill.end_time,seckill.create_time * FROM seckill * WHERE seckill.seckill_id = ?; * @throws Exception */ @Test public void queryById() throws Exception &#123; long id=1000L; Seckill seckill = secKillDao.queryById(id); System.out.println(seckill); &#125; @Test public void reduceNumber() throws Exception &#123; Date killTime=new Date(); int updateNumber= secKillDao.reduceNumber(1000L, killTime); System.out.println(&quot;updateNumber=&quot;+updateNumber); &#125; /** * * @throws Exception */ @Test public void queryAll() throws Exception &#123; List&lt;Seckill&gt; seckills = secKillDao.queryAll(2, 100); for (Seckill seckill : seckills) &#123; System.out.println(seckill); &#125; &#125;&#125; SuccessKilledTest测试:12345678910111213141516171819202122232425262728293031@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;&quot;classpath:spring/spring-dao.xml&quot;&#125;)public class SuccessKilledDaoTest &#123; @Autowired private SuccessKilledDao successKilledDao; @Test public void insertSuccessKilled() throws Exception &#123; long id=1000L; long phone=13784832725L; int updateSuccessedKilled = successKilledDao.insertSuccessKilled(id, phone); System.out.println(updateSuccessedKilled); &#125; /** * Preparing: * SELECT sk.seckill_id, sk.create_time, sk.state, sk.user_phone, s.seckill_id &quot;seckill.seckill_id&quot;, s.name &quot;seckill_name&quot;, s.number &quot;seckill_number&quot;, s.start_time &quot;seckill_start_time&quot;, s.end_time &quot;seckill_end_time&quot;, s.create_time &quot;seckill_create_time&quot; * FROM success_killed sk * INNER JOIN seckill s ON sk.seckill_id = s.seckill_id * WHERE sk.seckill_id = ? AND sk.user_phone = ?; * @throws Exception */ @Test public void querySuccessKilledWithSeckill() throws Exception &#123; long id=1001L; long phone=15733207536L; SuccessKilled successKilled = successKilledDao.querySuccessKilledWithSeckill(id,phone); System.out.println(successKilled); System.out.println(successKilled.getSeckill()); &#125;&#125;]]></content>
      <categories>
        <category>Seckill</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>SSM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springData-03]]></title>
    <url>%2F2017%2F12%2F01%2FSpringData-03%2F</url>
    <content type="text"><![CDATA[CrudRepository接口的使用CrudRepository接口分为下面的方法:123456789save(entity)findOne(id)findAll()delete(entity)deleteAll()save (entites)exists(id)delete(id)delete(entities) save方法使用测试: code1234567891011121314151617自定义的接口public interface EmployeeCrudRepository extends CrudRepository&lt;Employee,Integer&gt; &#123;&#125;EmployeeCrudService类@Servicepublic class EmployeeCrudService &#123; @Autowired private EmployeeCrudRepository employeeCrudRepository; @Transactional(rollbackOn = Exception.class) public void save(List&lt;Employee&gt; employees)&#123; employeeCrudRepository.save(employees); &#125;&#125; TestCode 123456789101112@Test public void test2() &#123; List&lt;Employee&gt; employees = new ArrayList&lt;&gt;(); Employee e = null; for (int i = 0; i &lt; 100; i++) &#123; e = new Employee(); e.setName(&quot;name&quot; + i); e.setAge(100 - i); employees.add(e); &#125; employee.save(employees); &#125; PagingAndSortingRepository接口使用 该接口包含分页和排序的功能 带排序的查询:findAll(Sort sort) 带排序的分页查询:findAll(Pageable pageable) 源码: 12345678@NoRepositoryBeanpublic interface PagingAndSortingRepository&lt;T, ID extends Serializable&gt; extends CrudRepository&lt;T, ID&gt; &#123; Iterable&lt;T&gt; findAll(Sort sort);//返回所有的实体 Page&lt;T&gt; findAll(Pageable pageable);//返回所有的page对象&#125;Pageable这个接口的实现类有PageRequest,里面有设置页数以及每页显示多少条的方法.PageRequest(Integer page,Integer size); 写一个接口 测试类12345678910111213141516171819202122232425262728 @Test public void test()&#123; //page:当前页数,它是按照索引(index=0.....)来算的 size:每页显示的条数 PageRequest pageable = new PageRequest(0,5); Page&lt;Employee&gt; page = employeePagingAndSortingRepository.findAll(pageable); System.out.println(page.getTotalPages());//一共有多少页 System.out.println(page.getTotalElements());//总记录数 System.out.println(page.getContent());//显示当前页的数据内容 System.out.println(page.getNumber()+1);//当前是第1页,不过它是从第0页算起的. System.out.println(page.getSize());//每页的页数 System.out.println(page.getSort()); System.out.println(page.getNumberOfElements()); /** * 20 100 [com.springdata.domain.Employee@5707f613, com.springdata.domain.Employee@68b11545, com.springdata.domain.Employee@7d0100ea, com.springdata.domain.Employee@357bc488, com.springdata.domain.Employee@4ea17147] 0 5 null 5 */ 其中page.getContent()我们得到的是一组哈希码数组.所以需要我们生成实体类的ToString()方法得到的结果是:[Employee&#123;id=1, name=&apos;name0&apos;, age=100&#125;, Employee&#123;id=2, name=&apos;name1&apos;, age=99&#125;, Employee&#123;id=3, name=&apos;name2&apos;, age=98&#125;, Employee&#123;id=4, name=&apos;name3&apos;, age=97&#125;, Employee&#123;id=5, name=&apos;name4&apos;, age=96&#125;] 下面进行排序的测试: 123456789101112每页显示5列数据,按照id降序排列@Test public void testSort()&#123; //按照id字段降序排列 Sort.Order order = new Sort.Order(Sort.Direction.DESC, &quot;id&quot;); Sort sort = new Sort(order); PageRequest pageRequest = new PageRequest(0,5,sort); Page&lt;Employee&gt; page = employeePagingAndSortingRepository.findAll(pageRequest); System.out.println(page.getContent()); //[Employee&#123;id=100, name=&apos;name99&apos;, age=1&#125;, Employee&#123;id=99, name=&apos;name98&apos;, age=2&#125;, Employee&#123;id=98, name=&apos;name97&apos;, age=3&#125;, Employee&#123;id=97, name=&apos;name96&apos;, age=4&#125;, Employee&#123;id=96, name=&apos;name95&apos;, age=5&#125;] &#125; JpaRepository接口的使用包括如下方法: 1234567public interface JpaRepository&lt;T, ID extends Serializable&gt; extends PagingAndSortingRepository&lt;T, ID&gt; &#123;&#125;1.findAll查询所有实体2.save(entity)增加实体3.findAll(Sort sort)支持排序4.flush5.deleteInBatch(entities)删除实体 自定义接口 12public interface EmployeeJpaRepository extends JpaRepository&lt;Employee,Integer&gt;&#123;&#125; 测试用例: 1234567891011121314151617@Test public void test()&#123; //查询ID为99的Employee内容 Employee one = employeeJpaRepository.findOne(99); System.out.println(one); //检查id=?的内容是否存在 System.out.println(employeeJpaRepository.exists(2)); System.out.println(employeeJpaRepository.exists(122)); Sort.Order id = new Sort.Order(Sort.Direction.DESC, &quot;id&quot;); Sort orders = new Sort(id); List&lt;Employee&gt; list = employeeJpaRepository.findAll(orders); for (Employee employee : list) &#123; System.out.println(employee); &#125; System.out.println(employeeJpaRepository.count()); &#125; JpaSpecificationExecutor接口Specification封装了JPA Criteria查询条件. Specification接口 123public interface Specification&lt;T&gt; &#123; Predicate toPredicate(Root&lt;T&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb);&#125; Specification的实现类 自定义接口: 123456/** * 继承多个接口,使其功能性更加强大 */public interface EmployeeJpaSpecificationExecutor extends JpaSpecificationExecutor&lt;Employee&gt;,JpaRepository&lt;Employee,Integer&gt;&#123;&#125; 测试用例:12]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springdata</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springData-02]]></title>
    <url>%2F2017%2F12%2F01%2FSpringData-02%2F</url>
    <content type="text"><![CDATA[maven依赖123456789101112&lt;!--SpringData--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-jpa&lt;/artifactId&gt; &lt;version&gt;1.8.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-entitymanager&lt;/artifactId&gt; &lt;version&gt;4.3.6.Final&lt;/version&gt; &lt;/dependency&gt; 书写beans.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:p=&quot;http://www.springframework.org/schema/p&quot; xmlns:cache=&quot;http://www.springframework.org/schema/cache&quot; xmlns:jpa=&quot;http://www.springframework.org/schema/data/jpa&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.1.xsd http://www.springframework.org/schema/cache http://www.springframework.org/schema/cache/spring-cache-3.1.xsd http://www.springframework.org/schema/data/jpa http://www.springframework.org/schema/data/jpa/spring-jpa.xsd&quot;&gt; &lt;!--1.配置数据源--&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://192.168.25.131:3306/spring_data&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; &lt;!--2.配置EntityManagerFactory--&gt; &lt;bean id=&quot;entityManagerFactory&quot; class=&quot;org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;jpaVendorAdapter&quot; value=&quot;org.springframework.orm.jpa.vendor.HibernateJpaVendorAdapter&quot;/&gt; &lt;!--配置扫描包--&gt; &lt;property name=&quot;packagesToScan&quot; value=&quot;com.springdata&quot;/&gt; &lt;!--jpa的一些属性--&gt; &lt;property name=&quot;jpaProperties&quot;&gt; &lt;props&gt; &lt;!--ejb语言的策略--&gt; &lt;prop key=&quot;hibernate.ejb.naming_strategy&quot;&gt;org.hibernate.cfg.ImprovedNamingStrategy&lt;/prop&gt; &lt;!--数据库的方言采用的是mysqlInnoDB存储引擎--&gt; &lt;prop key=&quot;hibernate.dialect&quot;&gt;org.hibernate.dialect.MySQL5InnoDBDialect&lt;/prop&gt; &lt;!--执行显示SQL--&gt; &lt;prop key=&quot;hibernate.show_sql&quot;&gt;true&lt;/prop&gt; &lt;!--自动格式化SQL--&gt; &lt;prop key=&quot;hibernate.format_sql&quot;&gt;true&lt;/prop&gt; &lt;!--根据实体自动创建表--&gt; &lt;prop key=&quot;hibernate.hbm2ddl.auto&quot;&gt;update&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 书写实体类12345需要三个注解:1.在类上使用@Entity,声明这个类是实体类2.在get方法上用@ID标识该属性为主键 @GeneratedValue产生策略是自增 实体类: 123456789101112131415161718192021222324252627282930313233@Entitypublic class Employee &#123; private Integer id; private String name; private Integer age; @GeneratedValue @Id public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; @Column(length = 20) public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 自动建表的实现12345修改表中某一字段的长度drop table employee;在实体类上的那个修改的成员变量的get方法上加上@Column(length=20)就可以改变它的长度了.一般字符串类型的长度默认是255. 测试类:123456789@Before public void testBefore() &#123; context = new ClassPathXmlApplicationContext(&quot;beans-new.xml&quot;); System.out.println(&quot;先获得配置文件&quot;); &#125; @Test public void testSpringDataJpa()&#123; System.out.println(&quot;我要自动建表了-------------&quot;); &#125; beans-new.xml其他配置1234567891011&lt;!--3.配置事务管理器--&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.orm.jpa.JpaTransactionManager&quot;&gt; &lt;property name=&quot;entityManagerFactory&quot; ref=&quot;entityManagerFactory&quot;/&gt; &lt;/bean&gt; &lt;!--4.配置支持注解的事务--&gt; &lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot;/&gt; &lt;!--5.配置SpringData--&gt; &lt;jpa:repositories base-package=&quot;com.springdata&quot; entity-manager-factory-ref=&quot;entityManagerFactory&quot;/&gt; &lt;context:component-scan base-package=&quot;com.springdata&quot;/&gt; 测试上面的那些配置实现类:12345678public interface EmployeeRepository extends Repository&lt;Employee, Integer&gt; &#123; /** * Respository里面的那两个参数就是:1.实体类 2.主键的ID(类型) * @param name * @return */ public Employee findByName(String name);&#125; 测试类: 123456789101112131415161718192021222324252627282930public class SpringDataTest &#123; private ClassPathXmlApplicationContext context; private EmployeeRepository employeeRepository; /** 先装载配置 */ @Before public void Setup()&#123; context = new ClassPathXmlApplicationContext(&quot;beans-new.xml&quot;); employeeRepository = context.getBean(EmployeeRepository.class); System.out.println(&quot;setup&quot;); &#125; /** 执行测试 */ @Test public void testFindbyName()&#123; Employee employee = employeeRepository.findByName(&quot;xiaoming&quot;); System.out.println(&quot;ID:&quot;+employee.getId()+&quot;姓名:&quot;+employee.getName()+&quot;年龄:&quot;+employee.getAge()); &#125; /** 销毁 */ @After public void tearDown()&#123; context=null; System.out.println(&quot;tearDown&quot;); &#125;&#125; 分析: 1234567891011121314151617181920Hibernate: select employee0_.id as id1_0_, employee0_.age as age2_0_, employee0_.name as name3_0_ from employee employee0_ where employee0_.name=? 上面是测试执行产生的SQL语句可以看出它查询的时候,查询了3个字段,并且给employee起来个别名employee0_ 并且是根据name字段来查询的.因为我们的配置设置了执行产生的SQL语句了.即: &lt;!--执行显示SQL--&gt;&lt;prop key=&quot;hibernate.show_sql&quot;&gt;true&lt;/prop&gt;&lt;!--自动格式化SQL--&gt;&lt;prop key=&quot;hibernate.format_sql&quot;&gt;true&lt;/prop&gt; 但是值得注意的是: 123查询的时候的方法的名字,不能随心所欲的起了.比如你要把findByName()方法改成test()方法,他就执行不成功了.所以,代码必须按照要按照一定的规则来设置. 关于Repository核心接口的认识CrudRepository:就是执行save/insert/delete操作. PagingAndSortingRepository:分页和排序:每页的显示和按照关键字的排序 jpaRepository:jpa的一些东西 jpaSpecificationExecutor:一些其他的东西 Repository接口源码: 123456package org.springframework.data.repository;import java.io.Serializable;public interface Repository&lt;T, ID extends Serializable&gt; &#123;&#125; 标记接口123可以看出里面就一个空接口,没提供任何方法.那Repository就是一个标记接口T就是你的目标实体类,ID就是那个实体类当中的ID(主键)的类型 类似的,我们可以看一下Serializable接口的形式: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109public interface Serializable &#123;&#125;他没有任何方法,同样的Serializable也是一个标记接口.```` #### 自定义接口使用的过程```androiddatabinding 之前使用的那个接口. public interface EmployeeRepository extends Repository&lt;Employee, Integer&gt;&#123; employeeRepository.findByName(String name); &#125; ```他在测试类中的使用:```androiddatabindingcontext = new ClassPathXmlApplicationContext(&quot;beans-new.xml&quot;);EmployeeRepository employeeRepository = context.getBean(EmployeeRepository.class);Employee employee = employeeRepository.findByName(&quot;xiaoming&quot;);```我们可以打印出来看一下这个employeeRepository```androiddatabindingorg.springframework.data.jpa.repository.support.SimpleJpaRepository@2bfaba70显示这个就说明你定义的那个接口EmployeeRepository已经被Spring容器所管理,可以被使用了.```#### 如果自定义接口没有继承官方提供的Repository&lt;T,ID&gt;接口,会出现错误```androiddatabinding就是下面这个错误org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type &apos;com.springdata.repository.EmployeeRepository&apos; available此类型的Bean无效,说明自定义的接口没有被Spring容器管理.此时我们可以使用@RepositoryDefinition(domainClass,idclass)注解的源码如下:@Documented@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE&#125;)@Inheritedpublic @interface RepositoryDefinition &#123; Class&lt;?&gt; domainClass(); Class&lt;? extends Serializable&gt; idClass();&#125;```所以我们可以下列的设置:```@RepositoryDefinition(domainClass = Employee.class,idClass = Integer.class)public interface EmployeeRepository &#123; /** * extends Repository&lt;Employee, Integer&gt; * Respository里面的那两个参数就是:1.实体类 2.主键的ID(类型) * @param name * @return */ public Employee findByName(String name);&#125;```### Repository的子接口CrudRepository:继承Repository,实现了CRUD的相关方法![](http://upload-images.jianshu.io/upload_images/7505161-0b283ab8f5c168b0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](http://upload-images.jianshu.io/upload_images/7505161-c1f6c80553a1313c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)jpaRepository:继承了PagingAndsortingRepository,实现了JPA规范的相关方法.![](http://upload-images.jianshu.io/upload_images/7505161-87bdc782bde6550d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)PagingAndSortingRepository:继承CrudRepository,实现了分页排序的相关的方法.![](http://upload-images.jianshu.io/upload_images/7505161-820c87ab0c846938.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)分为两个方法:1.可以根据具体的字段来排序2.第二个是分页的类![](http://upload-images.jianshu.io/upload_images/7505161-1149625b935d0742.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)### Repository中查询方法定义规则和使用 1. 了解SpringData中查询方法名称的定义规则 2. 使用SpringData完成复杂查询方法的命名 ![](http://upload-images.jianshu.io/upload_images/7505161-12d94ed91d010f92.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](http://upload-images.jianshu.io/upload_images/7505161-87f22b1868632f24.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)分析:```关键字 具体方法 翻译成的SQL语句如果不按上弄规则来写,会出现异常.```下面插入数据,进行测试 insert into employee(name,age) values(“test1”,20)insert into employee(name,age) ]values(“test2”,21)insert into employee(name,age) values(“test3”,22)insert into employee(name,age) values(“test4”,23)insert into employee(name,age) values(“test5”,20)insert into employee(name,age) values(“test6”,21)insert into employee(name,age) values(“test7”,22)insert into employee(name,age) values(“test8”,23)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849**按照特定命名的方法规则来进行查询**EmployeeRepository接口````androiddatabinding@RepositoryDefinition(domainClass = Employee.class,idClass = Integer.class)public interface EmployeeRepository &#123; /** * extends Repository&lt;Employee, Integer&gt; * Respository里面的那两个参数就是:1.实体类 2.主键的ID(类型) * @param name * @return */ public Employee findByName(String name); /** * where name like ?% and age &lt;? * name以XXx开始 &amp;&amp; age&lt;xxx * @param name * @param age * @return 符合条件的employee列表 */ public List&lt;Employee&gt; findByNameStartingWithAndAgeLessThan(String name, Integer age); /** * where name like %? and age &lt;? * name以XXX结束&amp;&amp; age&lt;xxx * @param name * @param age * @return */ public List&lt;Employee&gt; findByNameEndingWithAndAgeLessThan(String name, Integer age); /** * where name in(?,?......)or age &lt; ? * name在某个集合范围之内,或者age&lt;xxx * @param name * @param age * @return */ public List&lt;Employee&gt; findByNameInOrAgeLessThan(List&lt;String&gt; name,Integer age); /** * where name in(?,?......)and age &lt; ? * name在某个集合范围之内,并且age&lt;xxx * @param name * @param age * @return */ public List&lt;Employee&gt; findByNameInAndAgeLessThan(List&lt;String&gt; name,Integer age); 测试类 12345678910111213141516171819202122232425262728@Test public void test1()&#123; /* System.out.println(employeeRepository); employee = employeeRepository.findByName(&quot;xiaoming&quot;);*/ /*List&lt;Employee&gt; list = employeeRepository.findByNameEndingWithAndAgeLessThan(&quot;ong&quot;, 30);*/ List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;test1&quot;); list.add(&quot;test2&quot;); list.add(&quot;test3&quot;); list.add(&quot;test4&quot;); List&lt;Employee&gt; employees = employeeRepository.findByNameInOrAgeLessThan(list, 22); for (Employee employee : employees) &#123; System.out.println(&quot;ID是&quot;+employee.getId()+&quot; 姓名是:&quot;+employee.getName()+&quot; 年龄是&quot;+employee.getAge()); &#125; &#125; @Test public void test2()&#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;test1&quot;); list.add(&quot;test2&quot;); list.add(&quot;test3&quot;); list.add(&quot;test4&quot;); List&lt;Employee&gt; employees = employeeRepository.findByNameInAndAgeLessThan(list, 22); for (Employee employee : employees) &#123; System.out.println(&quot;ID是&quot;+employee.getId()+&quot; 姓名是:&quot;+employee.getName()+&quot; 年龄是&quot;+employee.getAge()); &#125; &#125; Query注解的使用1.在Repository方法中使用,不需要遵循查询方法命名规则. 需要将@Query定义在Repository中的方法之上即可. 命名参数及索引参数的使用. 本地查询 实现Code: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * select t1 from Employee t1 * 里面的Employee是类名 * @return */ @Query(&quot;select o from Employee o where id=(select max(id) from Employee t)&quot;) public Employee getEmployeeByMaxId(); /** * ?是占位符 * @param name * @param age * @return */ @Query(&quot;select o from Employee o where o.name=?1 and o.age=?2&quot;) public List&lt;Employee&gt; queryParams(String name,Integer age); /** * :name * 与@Param(&quot;name&quot;) * :后面的内容要和@Param()里面的内容一致. * @param name * @param age * @return */ @Query(&quot;select o from Employee o where o.name=:name and o.age=:age&quot;) public List&lt;Employee&gt; queryParams2(@Param(&quot;name&quot;) String name,@Param(&quot;age&quot;) Integer age); /** * 模糊查询:除了关键字不一致,其他都一样 * @param name * @return */ @Query(&quot;select o from Employee o where o.name like %?1%&quot;) public List&lt;Employee&gt; queryByLike(String name); /** * 用 :name 取代 ?1,但是需要在参数前面加上@Param(&quot;name&quot;) * @param name * @return */ @Query(&quot;select o from Employee o where o.name like %:name%&quot;) public List&lt;Employee&gt; queryByLike2(@Param(&quot;name&quot;) String name); /** * 本地查询的实现 * @return */ @Query(nativeQuery = false,value = &quot;select count(1) from Employee&quot;) public Long getCount(); 测试Code: 123456789101112131415161718192021222324252627282930313233343536@Test public void test3()&#123; Employee employee = employeeRepository.getEmployeeByMAxId(); System.out.println(&quot;ID是&quot;+employee.getId()+&quot; 姓名是:&quot;+employee.getName()+&quot; 年龄是&quot;+employee.getAge()); &#125; @Test public void test4()&#123; List&lt;Employee&gt; list = employeeRepository.queryParams(&quot;xiaoming&quot;, 10); for (Employee employee : list) &#123; System.out.println(&quot;ID是&quot;+employee.getId()+&quot; 姓名是:&quot;+employee.getName()+&quot; 年龄是&quot;+employee.getAge()); &#125; &#125; @Test public void test5()&#123; List&lt;Employee&gt; list = employeeRepository.queryParams2(&quot;xiaoming&quot;, 10); for (Employee employee : list) &#123; System.out.println(&quot;ID是&quot;+employee.getId()+&quot; 姓名是:&quot;+employee.getName()+&quot; 年龄是&quot;+employee.getAge()); &#125; &#125; @Test public void test6()&#123; List&lt;Employee&gt; list = employeeRepository.queryByLike2(&quot;test&quot;); for (Employee employee : list) &#123; System.out.println(&quot;ID是&quot;+employee.getId()+&quot; 姓名是:&quot;+employee.getName()+&quot; 年龄是&quot;+employee.getAge()); &#125; &#125; /** * 本地查询的测试 */ @Test public void test7()&#123; Long count = employeeRepository.getCount(); System.out.println(count); &#125; 更新及删除操作整合事务的使用@Modifying注解使用:加上表示允许修改值@Modifying结合@Query注解执行更新操作.@Transaction在事务中的使用 但是事务一般是在Service层中发生的.一个Service里面可能有多个Dao的调用,必须保证多个dao在同一个事务里面,比如说银行存钱,取钱的操作.事务一定要保证准确. 更新操作&amp;&amp;删除操作:12345678910111213141516/** * 再次注意Employee是类名,不是表名. * @param name * @param id */ @Modifying @Query(&quot;update Employee o set o.name = :name where o.id =:id&quot;) public void updateNameById(@Param(&quot;name&quot;) String name,@Param(&quot;id&quot;) Integer id); /** * 删除操作 * @param id */ @Modifying @Query(&quot;delete from Employee o where id = :id&quot;) public void deleteById(@Param(&quot;id&quot;)Integer id); 由于事务(@Transactional)是在Service层完成的,所以我们需要书写一个EmployeeService类: 1234567891011121314151617@Servicepublic class EmployeeService &#123; @Autowired private EmployeeRepository employeeRepository; @Transactional(rollbackOn = Exception.class) public void update(String name,Integer id)&#123; employeeRepository.updateNameById(name,id); &#125; @Transactional(rollbackOn = Exception.class) public void delete(Integer id)&#123; employeeRepository.deleteById(id); &#125;&#125; 测试方法: 12345678@Test public void test() &#123; employeeService.update(&quot;wangxiaoer&quot;, 1); &#125; @Test public void test2() &#123; employeeService.delete(6); &#125;]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springdata</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springData-01]]></title>
    <url>%2F2017%2F12%2F01%2FapringData-01%2F</url>
    <content type="text"><![CDATA[传统方式访问数据库JDBC 1. Connection 2. ResultSet 3. Statement 4. TestCase SpringJDBCTemplate 弊端分析 创建maven项目1.导入依赖-pom.xml junit&amp;&amp;mysqlDriver 12345678910111213&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.38&lt;/version&gt; &lt;/dependency&gt; 数据表的准备关系型的数据库mysql 123456789101112131415161718192021222324251. 创建一个数据库ceate database spring_data;2.切换到当前使用的数据库use spring_data 3.创建一张表create table student( id int not null auto_increment, name varchar(20) not null, age int not null, primary key(id));4.查看表的结构 desc student;5.往表中插入数据insert into student(id,name,age) values(null,&quot;xiaoming&quot;,10);insert into student(id,name,age) values(null,&quot;xiaohong&quot;,12);insert into student(id,name,age) values(null,&quot;xiaodong&quot;,18);insert into student(id,name,age) values(null,&quot;xiaolong&quot;,20); 开发JDBCUtil工具类 获取Connection,关闭Connection,Statement,ResultSet. 配置的属性放在配置文件里面,然后通过Properties.load(inputStream);就可以调用了. 释放Connect,ResultSet,Statement资源. 具体实现 配置文件db.properties 1234jdbc.url=jdbc:mysql://192.168.25.131:3306/spring_datajdbc.user=rootjdbc.password=rootjdbc.driverClass=com.mysql.jdbc.Driver 2.实现类JdbcUtils123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 1.获取Connection * 2.释放资源 */public class JdbcUtil &#123; /** * 获取Connection * @return 所获得的JDBC的Connection */ public static Connection getConnection() throws Exception &#123; //采用Properties载入输入流 InputStream is = JdbcUtil.class.getClassLoader().getResourceAsStream(&quot;db.properties&quot;); Properties properties = new Properties(); properties.load(is); String url = properties.getProperty(&quot;jdbc.url&quot;); String user = properties.getProperty(&quot;jdbc.user&quot;); String password = properties.getProperty(&quot;jdbc.password&quot;); String driverClass = properties.getProperty(&quot;jdbc.driverClass&quot;); Class.forName(driverClass); Connection connection = DriverManager.getConnection(url, user, password); return connection; &#125; /** * 释放DB相关资源 * @param resultSet * @param statement * @param connection */ public static void release(ResultSet resultSet, Statement statement,Connection connection)&#123; if (resultSet !=null) &#123; try &#123; resultSet.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (statement !=null) &#123; try &#123; statement.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (connection !=null) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 3.测试类 1234567public class JdbcTest &#123; @Test public void testGetconnection() throws Exception &#123; Connection connection = JdbcUtil.getConnection(); Assert.assertNotNull(connection); &#125;&#125; Dao层开发1.创建一个接口类JDBCDAO,只提供一个查询方法 12345678910111213 List&lt;Student&gt; query();``` 2.写出它的实现类JDBCDAOImpl```androiddatabinding 1.获取数据库的连接 2.由数据库的连接获得一个PreparedStatement对象 3.PreparedStatement执行SQL语句,返回结果集ResultSet 4.判断结果集ResultSet是否有下一个节点 5.生成一个Student对象把所查询到的结果.添到Student对象里面去 6.返回对象集合.list.add(student) Code: 1234567891011121314151617181920212223242526272829303132333435public class StudentDAOImpl implements StudentDAO &#123; @Override public List&lt;Student&gt; query() throws SQLException &#123; List&lt;Student&gt; list = new ArrayList&lt;&gt;(); Connection connection = null; PreparedStatement preparedStatement=null; ResultSet resultSet=null; String sql = &quot;select id,name,age from student&quot;; try &#123; connection = JdbcUtil.getConnection(); preparedStatement = connection.prepareStatement(sql); resultSet = preparedStatement.executeQuery(); Student student = null; while (resultSet.next())&#123; int id = resultSet.getInt(&quot;id&quot;); int age = resultSet.getInt(&quot;age&quot;); String name = resultSet.getString(&quot;name&quot;); student = new Student(); student.setId(id); student.setAge(age); student.setName(name); list.add(student); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; JdbcUtil.release(resultSet,preparedStatement,connection); &#125; return list; &#125;&#125; Code Test 12345678@Test public void testStudentQuery() throws SQLException &#123; StudentDAOImpl studentDAO = new StudentDAOImpl(); List&lt;Student&gt; query = studentDAO.query(); for (Student student : query) &#123; System.out.println(&quot;ID:&quot;+student.getId()+&quot; &quot;+&quot;AGE:&quot;+student.getAge()+&quot; &quot;+&quot;NAME:&quot;+student.getName()); &#125; &#125; Spring 提供的JdbcTemplate 导入Spring JDBC的依赖 1234567891011&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-jdbc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; 导入bean的xml配置的表头 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt;&lt;/beans&gt; 3.xml的配置 12345678910111213141516解释:DriverManagerDataSource 继承自AbstractDataSourceAbstractDataSource内置了下面这些成员变量 1. private String url; 2. private String username; 3. private String password; 4. private String catalog; 5. private String schema; 6. private Properties connectionProperties;所以我们需要配置与其相关的东西 下面是详细配置: 12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;bean id=&quot;dataSource&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://192.168.25.131:3306/spring_data&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;/bean&gt; &lt;!--Spring JDBC Template信息--&gt; &lt;bean id=&quot;jdbcTemplate&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt;``` #### 关于xml配置的单元测试模板```androiddatabinding@Before创建方法@Test测试方法@After销毁方法三者的执行顺序是从前往后的.]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>springdata</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring事务]]></title>
    <url>%2F2017%2F11%2F09%2FSpring%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[事务的概念事务值得是逻辑上的一组操作,这组操作要么全部成功,要么全部失败. 具体实例场景-银行转账 1234如果A给B转账期间,银行系统发生故障,就要保证A,B两者的财产不能出现任何损失.所以转账的操作就要添加到事务中进行,必须一起成功,或者一起失败.具体点就是,要么A给B成功转账,A少了3000元,B多了3000元,要么A没有给B转账成功,A没少一分钱,B没多一分钱. 事务的特性总的来讲分为4类特性1234原子性一致性隔离性持久性 原子性原子性是指事务是一个不可分割的工作单位,事务中的操作要么都发生,要么都不发生. 具体就是上面的例子. 一致性一致性指事务前后数据的完整性必须保持一致. 实例:就是说A和B转账操作完成之前和之后,A,B两者的存款之和,没有任何变化. 隔离性隔离性指的是指多个用户并发访问数据库时,一个用户的事务不能被其他用户的事务所干扰.多个并发的事务之间的数据要相互隔离. 实例: A正在被一个事务进行更新操作,另外一个事务也进行对A对象的更新操作,这样就导致第一个事务对A的修改,被第二个事务对A的修改给覆盖,修改记录被覆盖掉了,为了避免这种情况,所以事务执行期间,必须要有隔离性. 持久性持久性是指一个事务一旦被提交,他对数据库中的修改就是永久性的,即使数据库发生故障也不对其出现任何影响. Spring中的事务管理Spring事务管理主要有三个接口1231. platfromTransactionManager2. TransactionDefinition3. TransactionStatus platfromTransactionManagerSpring为不同的持久化框架提供了不同的PlatfromTransactionManager接口实现 TransactionDefinition事务定义信息(隔离级别,传播,超时,只读) 可预见的安全性问题包括:脏读,幻读,不可重复读 123456789101.脏读一个事务读取了另外一个事务改写但没有提交的数据,如果这些数据被回滚,则读到的数据是无效的.2.不可重复读在同一事务中,多次读取同一数据返回的结果有所不同.3.幻读一个事物读取了几行记录之后,另一个事务插入一些记录,幻读就会产生.再后来的查询中,第一个事务就会发现有些原来没有的记录, 隔离级别:读未提交,读已提交,可重复读,可串行化. 隔离级别的划分(安全等级升序) 事务的传播行为主要用来解决服务器端的SERVICE&amp;&amp;DAO的一些问题. 图示:]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>Transaction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot初识]]></title>
    <url>%2F2017%2F11%2F09%2Fspringboot%2F</url>
    <content type="text"><![CDATA[1.springboot的简述java开发很笨重,配置繁杂.低下的开发效率,复杂的部署流程,第三方技术集成难度大. SpringBoot :习惯优于配置.无需手动进行配置. 使用SpringBoot很容易创建一个独立运行的jar,内嵌Servlet容器(就是里面内嵌了一个tomcat),准生产级别的基于Spring框架的项目,使用SpringBoot仅仅需要很少的Spring配置. 2.SpringBoot的优缺点优点12345671. 快速构建项目2. 对主流开发框架的**无配置集成**3. 项目可独立运行,无需外部的依赖Servlet容器4. 提供运行时的应用监控.5. 极大地提高了开发,部署效率.6. 与云计算的天然集成.7. 微服务,把子系统,全部拆成一个一个的jar,去运行. 缺点121.书籍很少2.不熟悉Spring java注解配置的经验.会吃力的. 3.springboot的配置pom.xml中需要引入的东西 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--设置springboot的parent--&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!--SpringBoot中的项目必须将parent设置为SpringBoot的Parent,该parent包含了大量默认的配置,大大简化了我们的开发--&gt; &lt;groupId&gt;com.luoyupiaoshang&lt;/groupId&gt; &lt;artifactId&gt;springbootTest&lt;/artifactId&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;name&gt;springbootTest Maven Webapp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;4.3.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 连接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.jolbox&lt;/groupId&gt; &lt;artifactId&gt;bonecp-spring&lt;/artifactId&gt; &lt;version&gt;0.8.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--引入springboot的web支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;springbootTest&lt;/finalName&gt; &lt;plugins&gt; &lt;!-- 资源文件拷贝插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!-- java编译插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.1&lt;/version&gt; &lt;configuration&gt; &lt;showWarnings&gt;true&lt;/showWarnings&gt; &lt;showDeprecation&gt;true&lt;/showDeprecation&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--springboot的插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 配置Tomcat插件 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.3-SNAPSHOT&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt; 4.第一个springboot项目123456789101112131415@RestController@SpringBootApplication@Configurationpublic class HelloApplication &#123; @RequestMapping(value = &quot;/hello&quot;) public String hello()&#123; return &quot;hello world!&quot;; &#125; //访问 http://localhost:8080/hello就能看到结果了 public static void main(String[] args) &#123; SpringApplication.run(HelloApplication.class,args); &#125;&#125; 下面对上面注解进行说明: 123456@RestController =@Controller + @RequestBody@SpringBootApplication SpringBoot的核心注解,主要目的是开启自动配置.@Configuration声明这是一个Spring的配置类@Controller 表明这是SpringMVC的一个Controller控制器@RequestBody 把相应的数据绑定到要返回的对象上 我们启动可以看到信息 12345672018-01-18 21:46:13.142 INFO 7120 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http)2018-01-18 21:46:13.258 INFO 7120 --- [ main] o.apache.catalina.core.StandardService : Starting service Tomcat2018-01-18 21:46:13.266 INFO 7120 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.5.112018-01-18 21:46:13.829 INFO 7120 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext2018-01-18 21:46:13.830 INFO 7120 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 10376 ms它内置的就是tomcat,以及访问端口 5.SpringBoot的核心1.入口类和SpringBootApplicationSpringBoot的项目一般会有*Application的入口类, 入口类中会有main方法,这是一个标准的java应用程序的入口方法. @SpringBootApplication注解是SpringBoot的核心注解,它其实是一个组合注解. 这个注解主要包含了一下注解: ####1.@SpringBootConfiguration:这是SpringBoot项目的配置注解,同时它是一个组合注解. 在SpringBoot项目中推荐使用@SpringBootConfiguration替代@Configuration ####2.@EnableAutoConfiguration:启动自动配置,该注解是用SpringBoot根据项目中依赖的jar包自动配置项目的项目项. 1. 我们添加了Spring-boot-starter-web的依赖,项目中也就会引入SpringMVC的依赖,SpringBoot就会自动配置tomcat和SpringMVC 我们可以看一下依赖关系: 4.@ComponentScan 这个注解就是默认扫描@SpringBootApplication所在类的同级目录下以及它的子目录. 2.关闭自动配置通过上述,我们可以得知,SpringBoot会根据项目中的jar包依赖,自动做出配置,SpringBoot支持的自动配置如下: 可以看到非常之多,我们不需要SpringBoot的某一项配置,需要进行下列操作. 3.自定义Banner就是修改一下SpringBoot启动时的图案. 网站链接 在Resource下建立一个baner.txt,将你生成那些字符图案,搞到里面去,重新运行,就可以了. 如果想屏蔽Banner效果.如下: 1234567public static void main(String[] args) &#123; //SpringApplication.run(HelloApplication.class,args); SpringApplication application = new SpringApplication(HelloApplication.class); application.setBannerMode(Banner.Mode.OFF);//这样就关闭了Banner效果 application.run(args); &#125; 4.全局配置文件可以写成application.properties或者application.yml 我喜欢用用yml格式的,所以我们用application.yml演示: 但是很不幸:出现了一个bug 对比一下吧:application.properties 12server.port=8088server.servlet-path=*.html 与application.yml123server port:8088 servlet-path: *.html 中的写法 你会发现 application.properties可以顺利运行,但是application.yml不会顺利运行. 使用application.yml运行会出现无法启动tomcat的错误,我使用了@EnableAutoConfiguration(就是忽视SpringBoot的自动配置)这个注解也不能解决. 所以我灰溜溜的跑回了application.properties的队列. 下面是其他的配置,供参考使用: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914014114214314414514614714814915015115215315415515615715815916016116216316416516616716816917017117217317417517617717817918018118218318418518618718818919019119219319419519619719819920020120220320420520620720820921021121221321421521621721821922022122222322422522622722822923023123223323423523623723823924024124224324424524624724824925025125225325425525625725825926026126226326426526626726826927027127227327427527627727827928028128228328428528628728828929029129229329429529629729829930030130230330430530630730830931031131231331431531631731831932032132232332432532632732832933033133233333433533633733833934034134234334434534634734834935035135235335435535635735835936036136236336436536636736836937037137237337437537637737837938038138238338438538638738838939039139239339439539639739839940040140240340440540640740840941041141241341441541641741841942042142242342442542642742842943043143243343443543643743843944044144244344444544644744844945045145245345445545645745845946046146246346446546646746846947047147247347447547647747847948048148248348448548648748848949049149249349449549649749849950050150250350450550650750850951051151251351451551651751851952052152252352452552652752852953053153253353453553653753853954054154254354454554654754854955055155255355455555655755855956056156256356456556656756856957057157257357457557657757857958058158258358458558658758858959059159259359459559659759859960060160260360460560660760860961061161261361461561661761861962062162262362462562662762862963063163263363463563663763863964064164264364464564664764864965065165265365465565665765865966066166266366466566666766866967067167267367467567667767867968068168268368468568668768868969069169269369469569669769869970070170270370470570670770870971071171271371471571671771871972072172272372472572672772872973073173273373473573673773873974074174274374474574674774874975075175275375475575675775875976076176276376476576676776876977077177277377477577677777877978078178278378478578678778878979079179279379479579679779879980080180280380480580680780880981081181281381481581681781881982082182282382482582682782882983083183283383483583683783883984084184284384484584684784884985085185285385485585685785885986086186286386486586686786886987087187287387487587687787887988088188288388488588688788888989089189289389489589689789889990090190290390490590690790890991091191291391491591691791891992092192292392492592692792892993093193293393493593693793893994094194294394494594694794894995095195295395495595695795895996096196296396496596696796896997097197297397497597697797897998098198298398498598698798898999099199299399499599699799899910001001100210031004100510061007100810091010101110121013101410151016101710181019102010211022102310241025102610271028102910301031103210331034103510361037103810391040104110421043104410451046104710481049105010511052105310541055105610571058105910601061106210631064106510661067106810691070107110721073107410751076107710781079108010811082108310841085108610871088108910901091109210931094109510961097109810991100110111021103110411051106110711081109111011111112111311141115111611171118111911201121112211231124112511261127112811291130113111321133113411351136113711381139114011411142114311441145114611471148114911501151115211531154115511561157115811591160116111621163116411651166116711681169117011711172117311741175117611771178117911801181118211831184118511861187118811891190119111921193119411951196119711981199120012011202120312041205120612071208120912101211121212131214121512161217121812191220122112221223122412251226122712281229123012311232123312341235123612371238123912401241124212431244124512461247124812491250125112521253125412551256125712581259126012611262126312641265126612671268126912701271127212731274127512761277127812791280128112821283128412851286128712881289129012911292129312941295129612971298129913001301130213031304130513061307130813091310131113121313131413151316131713181319132013211322132313241325132613271328132913301331133213331334133513361337133813391340134113421343134413451346134713481349135013511352135313541355135613571358135913601361136213631364136513661367136813691370137113721373137413751376137713781379138013811382138313841385138613871388138913901391139213931394139513961397139813991400140114021403140414051406140714081409141014111412141314141415141614171418141914201421142214231424142514261427142814291430143114321433143414351436143714381439144014411442144314441445144614471448144914501451145214531454145514561457145814591460146114621463146414651466146714681469147014711472147314741475147614771478147914801481148214831484148514861487148814891490149114921493149414951496149714981499150015011502150315041505150615071508150915101511151215131514151515161517151815191520152115221523152415251526152715281529153015311532153315341535153615371538153915401541154215431544154515461547154815491550155115521553155415551556155715581559156015611562156315641565156615671568156915701571157215731574157515761577157815791580158115821583158415851586158715881589159015911592159315941595159615971598159916001601160216031604160516061607160816091610161116121613161416151616161716181619162016211622162316241625162616271628162916301631163216331634163516361637163816391640164116421643164416451646164716481649165016511652165316541655165616571658165916601661166216631664166516661667166816691670167116721673167416751676167716781679168016811682168316841685168616871688168916901691169216931694169516961697169816991700170117021703170417051706170717081709171017111712171317141715171617171718171917201721172217231724172517261727172817291730173117321733173417351736173717381739174017411742174317441745174617471748174917501751175217531754175517561757175817591760176117621763176417651766176717681769177017711772177317741775177617771778177917801781178217831784178517861787178817891790179117921793179417951796179717981799180018011802180318041805180618071808180918101811181218131814181518161817181818191820182118221823182418251826182718281829183018311832183318341835183618371838183918401841184218431844184518461847184818491850185118521853185418551856185718581859186018611862186318641865186618671868186918701871187218731874187518761877187818791880188118821883188418851886188718881889189018911892189318941895189618971898189919001901190219031904190519061907190819091910191119121913191419151916191719181919192019211922192319241925192619271928192919301931193219331934193519361937193819391940194119421943194419451946194719481949195019511952195319541955195619571958195919601961196219631964196519661967196819691970197119721973197419751976197719781979198019811982198319841985198619871988198919901991199219931994199519961997199819992000200120022003200420052006200720082009201020112012201320142015201620172018201920202021202220232024202520262027202820292030203120322033203420352036203720382039204020412042204320442045204620472048204920502051205220532054205520562057205820592060206120622063206420652066206720682069207020712072207320742075207620772078207920802081208220832084208520862087208820892090209120922093209420952096209720982099210021012102210321042105210621072108210921102111211221132114211521162117211821192120212121222123212421252126212721282129213021312132213321342135213621372138213921402141214221432144214521462147214821492150215121522153*# ===================================================================**# COMMON SPRING BOOT PROPERTIES**#**# This sample file is provided as a guideline. Do NOT copy it in its**# entirety to your own application. ^^^**# ===================================================================**# ----------------------------------------**# CORE PROPERTIES**# ----------------------------------------**# BANNER*banner.charset=UTF-8 *# Banner file encoding.*banner.location=classpath:banner.txt *# Banner file location.*banner.image.location=classpath:banner.gif *# Banner image file location (jpg/png can also be used).*banner.image.width= *# Width of the banner image in chars (default 76)*banner.image.height= *# Height of the banner image in chars (default based on image height)*banner.image.margin= *# Left hand image margin in chars (default 2)*banner.image.invert= *# If images should be inverted for dark terminal themes (default false)**# LOGGING*logging.config= *# Location of the logging configuration file. For instance `classpath:logback.xml` for Logback*logging.exception-conversion-word=%wEx *# Conversion word used when logging exceptions.*logging.file= *# Log file name. For instance `myapp.log`*logging.level.*= *# Log levels severity mapping. For instance `logging.level.org.springframework=DEBUG`*logging.path= *# Location of the log file. For instance `/var/log`*logging.pattern.console= *# Appender pattern for output to the console. Only supported with the default logback setup.*logging.pattern.file= *# Appender pattern for output to the file. Only supported with the default logback setup.*logging.pattern.level= *# Appender pattern for log level (default %5p). Only supported with the default logback setup.*logging.register-shutdown-hook=false *# Register a shutdown hook for the logging system when it is initialized.**# AOP*spring.aop.auto=true *# Add @EnableAspectJAutoProxy.*spring.aop.proxy-target-class=false *# Whether subclass-based (CGLIB) proxies are to be created (true) as opposed to standard Java interface-based proxies (false).**# IDENTITY (*[&lt;u&gt;ContextIdApplicationContextInitializer&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot/src/main/java/org/springframework/boot/context/ContextIdApplicationContextInitializer.java))spring.application.index= *# Application index.*spring.application.name= *# Application name.**# ADMIN (*[&lt;u&gt;SpringApplicationAdminJmxAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/admin/SpringApplicationAdminJmxAutoConfiguration.java))spring.application.admin.enabled=false *# Enable admin features for the application.*spring.application.admin.jmx-name=org.springframework.boot:type=Admin,name=SpringApplication *# JMX name of the application admin MBean.**# AUTO-CONFIGURATION*spring.autoconfigure.exclude= *# Auto-configuration classes to exclude.**# SPRING CORE*spring.beaninfo.ignore=true *# Skip search of BeanInfo classes.**# SPRING CACHE (*[&lt;u&gt;CacheProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/cache/CacheProperties.java))spring.cache.cache-names= *# Comma-separated list of cache names to create if supported by the underlying cache manager.*spring.cache.caffeine.spec= *# The spec to use to create caches. Check CaffeineSpec for more details on the spec format.*spring.cache.couchbase.expiration=0 *# Entry expiration in milliseconds. By default the entries never expire.*spring.cache.ehcache.config= *# The location of the configuration file to use to initialize EhCache.*spring.cache.guava.spec= *# The spec to use to create caches. Check CacheBuilderSpec for more details on the spec format.*spring.cache.infinispan.config= *# The location of the configuration file to use to initialize Infinispan.*spring.cache.jcache.config= *# The location of the configuration file to use to initialize the cache manager.*spring.cache.jcache.provider= *# Fully qualified name of the CachingProvider implementation to use to retrieve the JSR-107 compliant cache manager. Only needed if more than one JSR-107 implementation is available on the classpath.*spring.cache.type= *# Cache type, auto-detected according to the environment by default.**# SPRING CONFIG - using environment property only (*[&lt;u&gt;ConfigFileApplicationListener&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot/src/main/java/org/springframework/boot/context/config/ConfigFileApplicationListener.java))spring.config.location= *# Config file locations.*spring.config.name=application *# Config file name.**# HAZELCAST (*[&lt;u&gt;HazelcastProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/hazelcast/HazelcastProperties.java))spring.hazelcast.config= *# The location of the configuration file to use to initialize Hazelcast.**# PROJECT INFORMATION (*[&lt;u&gt;ProjectInfoProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/info/ProjectInfoProperties.java))spring.info.build.location=classpath:META-INF/build-info.properties *# Location of the generated build-info.properties file.*spring.info.git.location=classpath:git.properties *# Location of the generated git.properties file.**# JMX*spring.jmx.default-domain= *# JMX domain name.*spring.jmx.enabled=true *# Expose management beans to the JMX domain.*spring.jmx.server=mbeanServer *# MBeanServer bean name.**# Email (*[&lt;u&gt;MailProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mail/MailProperties.java))spring.mail.default-encoding=UTF-8 *# Default MimeMessage encoding.*spring.mail.host= *# SMTP server host. For instance `smtp.example.com`*spring.mail.jndi-name= *# Session JNDI name. When set, takes precedence to others mail settings.*spring.mail.password= *# Login password of the SMTP server.*spring.mail.port= *# SMTP server port.*spring.mail.properties.*= *# Additional JavaMail session properties.*spring.mail.protocol=smtp *# Protocol used by the SMTP server.*spring.mail.test-connection=false *# Test that the mail server is available on startup.*spring.mail.username= *# Login user of the SMTP server.**# APPLICATION SETTINGS (*[&lt;u&gt;SpringApplication&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot/src/main/java/org/springframework/boot/SpringApplication.java))spring.main.banner-mode=console *# Mode used to display the banner when the application runs.*spring.main.sources= *# Sources (class name, package name or XML resource location) to include in the ApplicationContext.*spring.main.web-environment= *# Run the application in a web environment (auto-detected by default).**# FILE ENCODING (*[&lt;u&gt;FileEncodingApplicationListener&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot/src/main/java/org/springframework/boot/context/FileEncodingApplicationListener.java))spring.mandatory-file-encoding= *# Expected character encoding the application must use.**# INTERNATIONALIZATION (*[&lt;u&gt;MessageSourceAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/context/MessageSourceAutoConfiguration.java))spring.messages.always-use-message-format=false *# Set whether to always apply the MessageFormat rules, parsing even messages without arguments.*spring.messages.basename=messages *# Comma-separated list of basenames, each following the ResourceBundle convention.*spring.messages.cache-seconds=-1 *# Loaded resource bundle files cache expiration, in seconds. When set to -1, bundles are cached forever.*spring.messages.encoding=UTF-8 *# Message bundles encoding.*spring.messages.fallback-to-system-locale=true *# Set whether to fall back to the system Locale if no files for a specific Locale have been found.**# OUTPUT*spring.output.ansi.enabled=detect *# Configure the ANSI output.**# PID FILE (*[&lt;u&gt;ApplicationPidFileWriter&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot/src/main/java/org/springframework/boot/system/ApplicationPidFileWriter.java))spring.pid.fail-on-write-error= *# Fail if ApplicationPidFileWriter is used but it cannot write the PID file.*spring.pid.file= *# Location of the PID file to write (if ApplicationPidFileWriter is used).**# PROFILES*spring.profiles.active= *# Comma-separated list (or list if using YAML) of* [&lt;u&gt;active profiles&lt;/u&gt;](#howto-set-active-spring-profiles &quot;72.6 Set the active Spring profiles&quot;).spring.profiles.include= *# Unconditionally activate the specified comma separated profiles (or list of profiles if using YAML).**# SENDGRID (*[&lt;u&gt;SendGridAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/sendgrid/SendGridAutoConfiguration.java))spring.sendgrid.api-key= *# SendGrid api key (alternative to username/password)*spring.sendgrid.username= *# SendGrid account username*spring.sendgrid.password= *# SendGrid account password*spring.sendgrid.proxy.host= *# SendGrid proxy host*spring.sendgrid.proxy.port= *# SendGrid proxy port**# ----------------------------------------**# WEB PROPERTIES**# ----------------------------------------**# EMBEDDED SERVER CONFIGURATION (*[&lt;u&gt;ServerProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/ServerProperties.java))server.address= *# Network address to which the server should bind to.*server.compression.enabled=false *# If response compression is enabled.*server.compression.excluded-user-agents= *# List of user-agents to exclude from compression.*server.compression.mime-types= *# Comma-separated list of MIME types that should be compressed. For instance `text/html,text/css,application/json`*server.compression.min-response-size= *# Minimum response size that is required for compression to be performed. For instance 2048*server.connection-timeout= *# Time in milliseconds that connectors will wait for another HTTP request before closing the connection. When not set, the connector&apos;s container-specific default will be used. Use a value of -1 to indicate no (i.e. infinite) timeout.*server.context-parameters.*= *# Servlet context init parameters. For instance `server.context-parameters.a=alpha`*server.context-path= *# Context path of the application.*server.display-name=application *# Display name of the application.*server.max-http-header-size=0 *# Maximum size in bytes of the HTTP message header.*server.error.include-stacktrace=never *# When to include a &quot;stacktrace&quot; attribute.*server.error.path=/error *# Path of the error controller.*server.error.whitelabel.enabled=true *# Enable the default error page displayed in browsers in case of a server error.*server.jetty.acceptors= *# Number of acceptor threads to use.*server.jetty.max-http-post-size=0 *# Maximum size in bytes of the HTTP post or put content.*server.jetty.selectors= *# Number of selector threads to use.*server.jsp-servlet.class-name=org.apache.jasper.servlet.JspServlet *# The class name of the JSP servlet.*server.jsp-servlet.init-parameters.*= *# Init parameters used to configure the JSP servlet*server.jsp-servlet.registered=true *# Whether or not the JSP servlet is registered*server.port=8080 *# Server HTTP port.*server.server-header= *# Value to use for the Server response header (no header is sent if empty)*server.servlet-path=/ *# Path of the main dispatcher servlet.*server.use-forward-headers= *# If X-Forwarded-* headers should be applied to the HttpRequest.*server.session.cookie.comment= *# Comment for the session cookie.*server.session.cookie.domain= *# Domain for the session cookie.*server.session.cookie.http-only= *# &quot;HttpOnly&quot; flag for the session cookie.*server.session.cookie.max-age= *# Maximum age of the session cookie in seconds.*server.session.cookie.name= *# Session cookie name.*server.session.cookie.path= *# Path of the session cookie.*server.session.cookie.secure= *# &quot;Secure&quot; flag for the session cookie.*server.session.persistent=false *# Persist session data between restarts.*server.session.store-dir= *# Directory used to store session data.*server.session.timeout= *# Session timeout in seconds.*server.session.tracking-modes= *# Session tracking modes (one or more of the following: &quot;cookie&quot;, &quot;url&quot;, &quot;ssl&quot;).*server.ssl.ciphers= *# Supported SSL ciphers.*server.ssl.client-auth= *# Whether client authentication is wanted (&quot;want&quot;) or needed (&quot;need&quot;). Requires a trust store.*server.ssl.enabled= *# Enable SSL support.*server.ssl.enabled-protocols= *# Enabled SSL protocols.*server.ssl.key-alias= *# Alias that identifies the key in the key store.*server.ssl.key-password= *# Password used to access the key in the key store.*server.ssl.key-store= *# Path to the key store that holds the SSL certificate (typically a jks file).*server.ssl.key-store-password= *# Password used to access the key store.*server.ssl.key-store-provider= *# Provider for the key store.*server.ssl.key-store-type= *# Type of the key store.*server.ssl.protocol=TLS *# SSL protocol to use.*server.ssl.trust-store= *# Trust store that holds SSL certificates.*server.ssl.trust-store-password= *# Password used to access the trust store.*server.ssl.trust-store-provider= *# Provider for the trust store.*server.ssl.trust-store-type= *# Type of the trust store.*server.tomcat.accept-count= *# Maximum queue length for incoming connection requests when all possible request processing threads are in use.*server.tomcat.accesslog.buffered=true *# Buffer output such that it is only flushed periodically.*server.tomcat.accesslog.directory=logs *# Directory in which log files are created. Can be relative to the tomcat base dir or absolute.*server.tomcat.accesslog.enabled=false *# Enable access log.*server.tomcat.accesslog.pattern=common *# Format pattern for access logs.*server.tomcat.accesslog.prefix=access_log *# Log file name prefix.*server.tomcat.accesslog.rename-on-rotate=false *# Defer inclusion of the date stamp in the file name until rotate time.*server.tomcat.accesslog.request-attributes-enabled=false *# Set request attributes for IP address, Hostname, protocol and port used for the request.*server.tomcat.accesslog.rotate=true *# Enable access log rotation.*server.tomcat.accesslog.suffix=.log *# Log file name suffix.*server.tomcat.additional-tld-skip-patterns= *# Comma-separated list of additional patterns that match jars to ignore for TLD scanning.*server.tomcat.background-processor-delay=30 *# Delay in seconds between the invocation of backgroundProcess methods.*server.tomcat.basedir= *# Tomcat base directory. If not specified a temporary directory will be used.*server.tomcat.internal-proxies=10\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 192\\.168\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 169\\.254\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 127\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.1[6-9]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\ 172\\.2[0-9]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125;|\\172\\.3[0-1]&#123;1&#125;\\.\\d&#123;1,3&#125;\\.\\d&#123;1,3&#125; *# regular expression matching trusted IP addresses.*server.tomcat.max-connections= *# Maximum number of connections that the server will accept and process at any given time.*server.tomcat.max-http-post-size=0 *# Maximum size in bytes of the HTTP post content.*server.tomcat.max-threads=0 *# Maximum amount of worker threads.*server.tomcat.min-spare-threads=0 *# Minimum amount of worker threads.*server.tomcat.port-header=X-Forwarded-Port *# Name of the HTTP header used to override the original port value.*server.tomcat.protocol-header= *# Header that holds the incoming protocol, usually named &quot;X-Forwarded-Proto&quot;.*server.tomcat.protocol-header-https-value=https *# Value of the protocol header that indicates that the incoming request uses SSL.*server.tomcat.redirect-context-root= *# Whether requests to the context root should be redirected by appending a / to the path.*server.tomcat.remote-ip-header= *# Name of the http header from which the remote ip is extracted. For instance `X-FORWARDED-FOR`*server.tomcat.uri-encoding=UTF-8 *# Character encoding to use to decode the URI.*server.undertow.accesslog.dir= *# Undertow access log directory.*server.undertow.accesslog.enabled=false *# Enable access log.*server.undertow.accesslog.pattern=common *# Format pattern for access logs.*server.undertow.accesslog.prefix=access_log. *# Log file name prefix.*server.undertow.accesslog.rotate=true *# Enable access log rotation.*server.undertow.accesslog.suffix=log *# Log file name suffix.*server.undertow.buffer-size= *# Size of each buffer in bytes.*server.undertow.buffers-per-region= *# Number of buffer per region.*server.undertow.direct-buffers= *# Allocate buffers outside the Java heap.*server.undertow.io-threads= *# Number of I/O threads to create for the worker.*server.undertow.max-http-post-size=0 *# Maximum size in bytes of the HTTP post content.*server.undertow.worker-threads= *# Number of worker threads.**# FREEMARKER (*[&lt;u&gt;FreeMarkerAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/freemarker/FreeMarkerAutoConfiguration.java))spring.freemarker.allow-request-override=false *# Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.*spring.freemarker.allow-session-override=false *# Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.*spring.freemarker.cache=false *# Enable template caching.*spring.freemarker.charset=UTF-8 *# Template encoding.*spring.freemarker.check-template-location=true *# Check that the templates location exists.*spring.freemarker.content-type=text/html *# Content-Type value.*spring.freemarker.enabled=true *# Enable MVC view resolution for this technology.*spring.freemarker.expose-request-attributes=false *# Set whether all request attributes should be added to the model prior to merging with the template.*spring.freemarker.expose-session-attributes=false *# Set whether all HttpSession attributes should be added to the model prior to merging with the template.*spring.freemarker.expose-spring-macro-helpers=true *# Set whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.*spring.freemarker.prefer-file-system-access=true *# Prefer file system access for template loading. File system access enables hot detection of template changes.*spring.freemarker.prefix= *# Prefix that gets prepended to view names when building a URL.*spring.freemarker.request-context-attribute= *# Name of the RequestContext attribute for all views.*spring.freemarker.settings.*= *# Well-known FreeMarker keys which will be passed to FreeMarker&apos;s Configuration.*spring.freemarker.suffix= *# Suffix that gets appended to view names when building a URL.*spring.freemarker.template-loader-path=classpath:/templates/ *# Comma-separated list of template paths.*spring.freemarker.view-names= *# White list of view names that can be resolved.**# GROOVY TEMPLATES (*[&lt;u&gt;GroovyTemplateAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/groovy/template/GroovyTemplateAutoConfiguration.java))spring.groovy.template.allow-request-override=false *# Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.*spring.groovy.template.allow-session-override=false *# Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.*spring.groovy.template.cache= *# Enable template caching.*spring.groovy.template.charset=UTF-8 *# Template encoding.*spring.groovy.template.check-template-location=true *# Check that the templates location exists.*spring.groovy.template.configuration.*= *# See GroovyMarkupConfigurer*spring.groovy.template.content-type=test/html *# Content-Type value.*spring.groovy.template.enabled=true *# Enable MVC view resolution for this technology.*spring.groovy.template.expose-request-attributes=false *# Set whether all request attributes should be added to the model prior to merging with the template.*spring.groovy.template.expose-session-attributes=false *# Set whether all HttpSession attributes should be added to the model prior to merging with the template.*spring.groovy.template.expose-spring-macro-helpers=true *# Set whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.*spring.groovy.template.prefix= *# Prefix that gets prepended to view names when building a URL.*spring.groovy.template.request-context-attribute= *# Name of the RequestContext attribute for all views.*spring.groovy.template.resource-loader-path=classpath:/templates/ *# Template path.*spring.groovy.template.suffix=.tpl *# Suffix that gets appended to view names when building a URL.*spring.groovy.template.view-names= *# White list of view names that can be resolved.**# SPRING HATEOAS (*[&lt;u&gt;HateoasProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/hateoas/HateoasProperties.java))spring.hateoas.use-hal-as-default-json-media-type=true *# Specify if application/hal+json responses should be sent to requests that accept application/json.**# HTTP message conversion*spring.http.converters.preferred-json-mapper=jackson *# Preferred JSON mapper to use for HTTP message conversion. Set to &quot;gson&quot; to force the use of Gson when both it and Jackson are on the classpath.**# HTTP encoding (*[&lt;u&gt;HttpEncodingProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/HttpEncodingProperties.java))spring.http.encoding.charset=UTF-8 *# Charset of HTTP requests and responses. Added to the &quot;Content-Type&quot; header if not set explicitly.*spring.http.encoding.enabled=true *# Enable http encoding support.*spring.http.encoding.force= *# Force the encoding to the configured charset on HTTP requests and responses.*spring.http.encoding.force-request= *# Force the encoding to the configured charset on HTTP requests. Defaults to true when &quot;force&quot; has not been specified.*spring.http.encoding.force-response= *# Force the encoding to the configured charset on HTTP responses.*spring.http.encoding.mapping= *# Locale to Encoding mapping.**# MULTIPART (*[&lt;u&gt;MultipartProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/MultipartProperties.java))spring.http.multipart.enabled=true *# Enable support of multi-part uploads.*spring.http.multipart.file-size-threshold=0 *# Threshold after which files will be written to disk. Values can use the suffixed &quot;MB&quot; or &quot;KB&quot; to indicate a Megabyte or Kilobyte size.*spring.http.multipart.location= *# Intermediate location of uploaded files.*spring.http.multipart.max-file-size=1MB *# Max file size. Values can use the suffixed &quot;MB&quot; or &quot;KB&quot; to indicate a Megabyte or Kilobyte size.*spring.http.multipart.max-request-size=10MB *# Max request size. Values can use the suffixed &quot;MB&quot; or &quot;KB&quot; to indicate a Megabyte or Kilobyte size.*spring.http.multipart.resolve-lazily=false *# Whether to resolve the multipart request lazily at the time of file or parameter access.**# JACKSON (*[&lt;u&gt;JacksonProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jackson/JacksonProperties.java))spring.jackson.date-format= *# Date format string or a fully-qualified date format class name. For instance `yyyy-MM-dd HH:mm:ss`.*spring.jackson.default-property-inclusion= *# Controls the inclusion of properties during serialization.*spring.jackson.deserialization.*= *# Jackson on/off features that affect the way Java objects are deserialized.*spring.jackson.generator.*= *# Jackson on/off features for generators.*spring.jackson.joda-date-time-format= *# Joda date time format string. If not configured, &quot;date-format&quot; will be used as a fallback if it is configured with a format string.*spring.jackson.locale= *# Locale used for formatting.*spring.jackson.mapper.*= *# Jackson general purpose on/off features.*spring.jackson.parser.*= *# Jackson on/off features for parsers.*spring.jackson.property-naming-strategy= *# One of the constants on Jackson&apos;s PropertyNamingStrategy. Can also be a fully-qualified class name of a PropertyNamingStrategy subclass.*spring.jackson.serialization.*= *# Jackson on/off features that affect the way Java objects are serialized.*spring.jackson.time-zone= *# Time zone used when formatting dates. For instance `America/Los_Angeles`**# JERSEY (*[&lt;u&gt;JerseyProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jersey/JerseyProperties.java))spring.jersey.application-path= *# Path that serves as the base URI for the application. Overrides the value of &quot;@ApplicationPath&quot; if specified.*spring.jersey.filter.order=0 *# Jersey filter chain order.*spring.jersey.init.*= *# Init parameters to pass to Jersey via the servlet or filter.*spring.jersey.servlet.load-on-startup=-1 *# Load on startup priority of the Jersey servlet.*spring.jersey.type=servlet *# Jersey integration type.**# SPRING LDAP (*[&lt;u&gt;LdapProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/ldap/LdapProperties.java))spring.ldap.urls= *# LDAP URLs of the server.*spring.ldap.base= *# Base suffix from which all operations should originate.*spring.ldap.username= *# Login user of the server.*spring.ldap.password= *# Login password of the server.*spring.ldap.base-environment.*= *# LDAP specification settings.**# EMBEDDED LDAP (*[&lt;u&gt;EmbeddedLdapProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/ldap/embedded/EmbeddedLdapProperties.java))spring.ldap.embedded.base-dn= *# The base DN*spring.ldap.embedded.credential.username= *# Embedded LDAP username.*spring.ldap.embedded.credential.password= *# Embedded LDAP password.*spring.ldap.embedded.ldif=classpath:schema.ldif *# Schema (LDIF) script resource reference.*spring.ldap.embedded.port= *# Embedded LDAP port.*spring.ldap.embedded.validation.enabled=true *# Enable LDAP schema validation.*spring.ldap.embedded.validation.schema= *# Path to the custom schema.**# SPRING MOBILE DEVICE VIEWS (*[&lt;u&gt;DeviceDelegatingViewResolverAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mobile/DeviceDelegatingViewResolverAutoConfiguration.java))spring.mobile.devicedelegatingviewresolver.enable-fallback=false *# Enable support for fallback resolution.*spring.mobile.devicedelegatingviewresolver.enabled=false *# Enable device view resolver.*spring.mobile.devicedelegatingviewresolver.mobile-prefix=mobile/ *# Prefix that gets prepended to view names for mobile devices.*spring.mobile.devicedelegatingviewresolver.mobile-suffix= *# Suffix that gets appended to view names for mobile devices.*spring.mobile.devicedelegatingviewresolver.normal-prefix= *# Prefix that gets prepended to view names for normal devices.*spring.mobile.devicedelegatingviewresolver.normal-suffix= *# Suffix that gets appended to view names for normal devices.*spring.mobile.devicedelegatingviewresolver.tablet-prefix=tablet/ *# Prefix that gets prepended to view names for tablet devices.*spring.mobile.devicedelegatingviewresolver.tablet-suffix= *# Suffix that gets appended to view names for tablet devices.**# SPRING MOBILE SITE PREFERENCE (*[&lt;u&gt;SitePreferenceAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mobile/SitePreferenceAutoConfiguration.java))spring.mobile.sitepreference.enabled=true *# Enable SitePreferenceHandler.**# MUSTACHE TEMPLATES (*[&lt;u&gt;MustacheAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mustache/MustacheAutoConfiguration.java))spring.mustache.allow-request-override= *# Set whether HttpServletRequest attributes are allowed to override (hide) controller generated model attributes of the same name.*spring.mustache.allow-session-override= *# Set whether HttpSession attributes are allowed to override (hide) controller generated model attributes of the same name.*spring.mustache.cache= *# Enable template caching.*spring.mustache.charset= *# Template encoding.*spring.mustache.check-template-location= *# Check that the templates location exists.*spring.mustache.content-type= *# Content-Type value.*spring.mustache.enabled= *# Enable MVC view resolution for this technology.*spring.mustache.expose-request-attributes= *# Set whether all request attributes should be added to the model prior to merging with the template.*spring.mustache.expose-session-attributes= *# Set whether all HttpSession attributes should be added to the model prior to merging with the template.*spring.mustache.expose-spring-macro-helpers= *# Set whether to expose a RequestContext for use by Spring&apos;s macro library, under the name &quot;springMacroRequestContext&quot;.*spring.mustache.prefix=classpath:/templates/ *# Prefix to apply to template names.*spring.mustache.request-context-attribute= *# Name of the RequestContext attribute for all views.*spring.mustache.suffix=.html *# Suffix to apply to template names.*spring.mustache.view-names= *# White list of view names that can be resolved.**# SPRING MVC (*[&lt;u&gt;WebMvcProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/WebMvcProperties.java))spring.mvc.async.request-timeout= *# Amount of time (in milliseconds) before asynchronous request handling times out.*spring.mvc.date-format= *# Date format to use. For instance `dd/MM/yyyy`.*spring.mvc.dispatch-trace-request=false *# Dispatch TRACE requests to the FrameworkServlet doService method.*spring.mvc.dispatch-options-request=true *# Dispatch OPTIONS requests to the FrameworkServlet doService method.*spring.mvc.favicon.enabled=true *# Enable resolution of favicon.ico.*spring.mvc.formcontent.putfilter.enabled=true *# Enable Spring&apos;s HttpPutFormContentFilter.*spring.mvc.ignore-default-model-on-redirect=true *# If the content of the &quot;default&quot; model should be ignored during redirect scenarios.*spring.mvc.locale= *# Locale to use. By default, this locale is overridden by the &quot;Accept-Language&quot; header.*spring.mvc.locale-resolver=accept-header *# Define how the locale should be resolved.*spring.mvc.log-resolved-exception=false *# Enable warn logging of exceptions resolved by a &quot;HandlerExceptionResolver&quot;.*spring.mvc.media-types.*= *# Maps file extensions to media types for content negotiation.*spring.mvc.message-codes-resolver-format= *# Formatting strategy for message codes. For instance `PREFIX_ERROR_CODE`.*spring.mvc.servlet.load-on-startup=-1 *# Load on startup priority of the Spring Web Services servlet.*spring.mvc.static-path-pattern=/** *# Path pattern used for static resources.*spring.mvc.throw-exception-if-no-handler-found=false *# If a &quot;NoHandlerFoundException&quot; should be thrown if no Handler was found to process a request.*spring.mvc.view.prefix= *# Spring MVC view prefix.*spring.mvc.view.suffix= *# Spring MVC view suffix.**# SPRING RESOURCES HANDLING (*[&lt;u&gt;ResourceProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/web/ResourceProperties.java))spring.resources.add-mappings=true *# Enable default resource handling.*spring.resources.cache-period= *# Cache period for the resources served by the resource handler, in seconds.*spring.resources.chain.cache=true *# Enable caching in the Resource chain.*spring.resources.chain.enabled= *# Enable the Spring Resource Handling chain. Disabled by default unless at least one strategy has been enabled.*spring.resources.chain.gzipped=false *# Enable resolution of already gzipped resources.*spring.resources.chain.html-application-cache=false *# Enable HTML5 application cache manifest rewriting.*spring.resources.chain.strategy.content.enabled=false *# Enable the content Version Strategy.*spring.resources.chain.strategy.content.paths=/** *# Comma-separated list of patterns to apply to the Version Strategy.*spring.resources.chain.strategy.fixed.enabled=false *# Enable the fixed Version Strategy.*spring.resources.chain.strategy.fixed.paths=/** *# Comma-separated list of patterns to apply to the Version Strategy.*spring.resources.chain.strategy.fixed.version= *# Version string to use for the Version Strategy.*spring.resources.static-locations=classpath:/META-INF/resources/,classpath:/resources/,classpath:/static/,classpath:/public/ *# Locations of static resources.**# SPRING SESSION (*[&lt;u&gt;SessionProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/session/SessionProperties.java))spring.session.hazelcast.flush-mode=on-save *# Sessions flush mode.*spring.session.hazelcast.map-name=spring:session:sessions *# Name of the map used to store sessions.*spring.session.jdbc.initializer.enabled= *# Create the required session tables on startup if necessary. Enabled automatically if the default table name is set or a custom schema is configured.*spring.session.jdbc.schema=classpath:org/springframework/session/jdbc/schema-@@platform@@.sql *# Path to the SQL file to use to initialize the database schema.*spring.session.jdbc.table-name=SPRING_SESSION *# Name of database table used to store sessions.*spring.session.mongo.collection-name=sessions *# Collection name used to store sessions.*spring.session.redis.flush-mode=on-save *# Sessions flush mode.*spring.session.redis.namespace= *# Namespace for keys used to store sessions.*spring.session.store-type= *# Session store type.**# SPRING SOCIAL (*[&lt;u&gt;SocialWebAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/social/SocialWebAutoConfiguration.java))spring.social.auto-connection-views=false *# Enable the connection status view for supported providers.**# SPRING SOCIAL FACEBOOK (*[&lt;u&gt;FacebookAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/social/FacebookAutoConfiguration.java))spring.social.facebook.app-id= *# your application&apos;s Facebook App ID*spring.social.facebook.app-secret= *# your application&apos;s Facebook App Secret**# SPRING SOCIAL LINKEDIN (*[&lt;u&gt;LinkedInAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/social/LinkedInAutoConfiguration.java))spring.social.linkedin.app-id= *# your application&apos;s LinkedIn App ID*spring.social.linkedin.app-secret= *# your application&apos;s LinkedIn App Secret**# SPRING SOCIAL TWITTER (*[&lt;u&gt;TwitterAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/social/TwitterAutoConfiguration.java))spring.social.twitter.app-id= *# your application&apos;s Twitter App ID*spring.social.twitter.app-secret= *# your application&apos;s Twitter App Secret**# THYMELEAF (*[&lt;u&gt;ThymeleafAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/thymeleaf/ThymeleafAutoConfiguration.java))spring.thymeleaf.cache=true *# Enable template caching.*spring.thymeleaf.check-template=true *# Check that the template exists before rendering it.*spring.thymeleaf.check-template-location=true *# Check that the templates location exists.*spring.thymeleaf.content-type=text/html *# Content-Type value.*spring.thymeleaf.enabled=true *# Enable MVC Thymeleaf view resolution.*spring.thymeleaf.encoding=UTF-8 *# Template encoding.*spring.thymeleaf.excluded-view-names= *# Comma-separated list of view names that should be excluded from resolution.*spring.thymeleaf.mode=HTML5 *# Template mode to be applied to templates. See also StandardTemplateModeHandlers.*spring.thymeleaf.prefix=classpath:/templates/ *# Prefix that gets prepended to view names when building a URL.*spring.thymeleaf.suffix=.html *# Suffix that gets appended to view names when building a URL.*spring.thymeleaf.template-resolver-order= *# Order of the template resolver in the chain.*spring.thymeleaf.view-names= *# Comma-separated list of view names that can be resolved.**# SPRING WEB SERVICES (*[&lt;u&gt;WebServicesProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/webservices/WebServicesProperties.java))spring.webservices.path=/services *# Path that serves as the base URI for the services.*spring.webservices.servlet.init= *# Servlet init parameters to pass to Spring Web Services.*spring.webservices.servlet.load-on-startup=-1 *# Load on startup priority of the Spring Web Services servlet.**# ----------------------------------------**# SECURITY PROPERTIES**# ----------------------------------------**# SECURITY (*[&lt;u&gt;SecurityProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/security/SecurityProperties.java))security.basic.authorize-mode=role *# Security authorize mode to apply.*security.basic.enabled=true *# Enable basic authentication.*security.basic.path=/** *# Comma-separated list of paths to secure.*security.basic.realm=Spring *# HTTP basic realm name.*security.enable-csrf=false *# Enable Cross Site Request Forgery support.*security.filter-order=0 *# Security filter chain order.*security.filter-dispatcher-types=ASYNC, FORWARD, INCLUDE, REQUEST *# Security filter chain dispatcher types.*security.headers.cache=true *# Enable cache control HTTP headers.*security.headers.content-security-policy= *# Value for content security policy header.*security.headers.content-security-policy-mode=default *# Content security policy mode.*security.headers.content-type=true *# Enable &quot;X-Content-Type-Options&quot; header.*security.headers.frame=true *# Enable &quot;X-Frame-Options&quot; header.*security.headers.hsts=all *# HTTP Strict Transport Security (HSTS) mode (none, domain, all).*security.headers.xss=true *# Enable cross site scripting (XSS) protection.*security.ignored= *# Comma-separated list of paths to exclude from the default secured paths.*security.require-ssl=false *# Enable secure channel for all requests.*security.sessions=stateless *# Session creation policy (always, never, if_required, stateless).*security.user.name=user *# Default user name.*security.user.password= *# Password for the default user name. A random password is logged on startup by default.*security.user.role=USER *# Granted roles for the default user name.**# SECURITY OAUTH2 CLIENT (*[&lt;u&gt;OAuth2ClientProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/security/oauth2/OAuth2ClientProperties.java))security.oauth2.client.client-id= *# OAuth2 client id.*security.oauth2.client.client-secret= *# OAuth2 client secret. A random secret is generated by default**# SECURITY OAUTH2 RESOURCES (*[&lt;u&gt;ResourceServerProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/security/oauth2/resource/ResourceServerProperties.java))security.oauth2.resource.filter-order= *# The order of the filter chain used to authenticate tokens.*security.oauth2.resource.id= *# Identifier of the resource.*security.oauth2.resource.jwt.key-uri= *# The URI of the JWT token. Can be set if the value is not available and the key is public.*security.oauth2.resource.jwt.key-value= *# The verification key of the JWT token. Can either be a symmetric secret or PEM-encoded RSA public key.*security.oauth2.resource.prefer-token-info=true *# Use the token info, can be set to false to use the user info.*security.oauth2.resource.service-id=resource *#*security.oauth2.resource.token-info-uri= *# URI of the token decoding endpoint.*security.oauth2.resource.token-type= *# The token type to send when using the userInfoUri.*security.oauth2.resource.user-info-uri= *# URI of the user endpoint.**# SECURITY OAUTH2 SSO (*[&lt;u&gt;OAuth2SsoProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/security/oauth2/client/OAuth2SsoProperties.java))security.oauth2.sso.filter-order= *# Filter order to apply if not providing an explicit WebSecurityConfigurerAdapter*security.oauth2.sso.login-path=/login *# Path to the login page, i.e. the one that triggers the redirect to the OAuth2 Authorization Server**# ----------------------------------------**# DATA PROPERTIES**# ----------------------------------------**# FLYWAY (*[&lt;u&gt;FlywayProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/flyway/FlywayProperties.java))flyway.baseline-description= *#*flyway.baseline-version=1 *# version to start migration*flyway.baseline-on-migrate= *#*flyway.check-location=false *# Check that migration scripts location exists.*flyway.clean-on-validation-error= *#*flyway.enabled=true *# Enable flyway.*flyway.encoding= *#*flyway.ignore-failed-future-migration= *#*flyway.init-sqls= *# SQL statements to execute to initialize a connection immediately after obtaining it.*flyway.locations=classpath:db/migration *# locations of migrations scripts*flyway.out-of-order= *#*flyway.password= *# JDBC password if you want Flyway to create its own DataSource*flyway.placeholder-prefix= *#*flyway.placeholder-replacement= *#*flyway.placeholder-suffix= *#*flyway.placeholders.*= *#*flyway.schemas= *# schemas to update*flyway.sql-migration-prefix=V *#*flyway.sql-migration-separator= *#*flyway.sql-migration-suffix=.sql *#*flyway.table= *#*flyway.url= *# JDBC url of the database to migrate. If not set, the primary configured data source is used.*flyway.user= *# Login user of the database to migrate.*flyway.validate-on-migrate= *#**# LIQUIBASE (*[&lt;u&gt;LiquibaseProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/liquibase/LiquibaseProperties.java))liquibase.change-log=classpath:/db/changelog/db.changelog-master.yaml *# Change log configuration path.*liquibase.check-change-log-location=true *# Check the change log location exists.*liquibase.contexts= *# Comma-separated list of runtime contexts to use.*liquibase.default-schema= *# Default database schema.*liquibase.drop-first=false *# Drop the database schema first.*liquibase.enabled=true *# Enable liquibase support.*liquibase.labels= *# Comma-separated list of runtime labels to use.*liquibase.parameters.*= *# Change log parameters.*liquibase.password= *# Login password of the database to migrate.*liquibase.rollback-file= *# File to which rollback SQL will be written when an update is performed.*liquibase.url= *# JDBC url of the database to migrate. If not set, the primary configured data source is used.*liquibase.user= *# Login user of the database to migrate.**# COUCHBASE (*[&lt;u&gt;CouchbaseProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/couchbase/CouchbaseProperties.java))spring.couchbase.bootstrap-hosts= *# Couchbase nodes (host or IP address) to bootstrap from.*spring.couchbase.bucket.name=default *# Name of the bucket to connect to.*spring.couchbase.bucket.password= *# Password of the bucket.*spring.couchbase.env.endpoints.key-value=1 *# Number of sockets per node against the Key/value service.*spring.couchbase.env.endpoints.query=1 *# Number of sockets per node against the Query (N1QL) service.*spring.couchbase.env.endpoints.view=1 *# Number of sockets per node against the view service.*spring.couchbase.env.ssl.enabled= *# Enable SSL support. Enabled automatically if a &quot;keyStore&quot; is provided unless specified otherwise.*spring.couchbase.env.ssl.key-store= *# Path to the JVM key store that holds the certificates.*spring.couchbase.env.ssl.key-store-password= *# Password used to access the key store.*spring.couchbase.env.timeouts.connect=5000 *# Bucket connections timeout in milliseconds.*spring.couchbase.env.timeouts.key-value=2500 *# Blocking operations performed on a specific key timeout in milliseconds.*spring.couchbase.env.timeouts.query=7500 *# N1QL query operations timeout in milliseconds.*spring.couchbase.env.timeouts.socket-connect=1000 *# Socket connect connections timeout in milliseconds.*spring.couchbase.env.timeouts.view=7500 *# Regular and geospatial view operations timeout in milliseconds.**# DAO (*[&lt;u&gt;PersistenceExceptionTranslationAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/dao/PersistenceExceptionTranslationAutoConfiguration.java))spring.dao.exceptiontranslation.enabled=true *# Enable the PersistenceExceptionTranslationPostProcessor.**# CASSANDRA (*[&lt;u&gt;CassandraProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/cassandra/CassandraProperties.java))spring.data.cassandra.cluster-name= *# Name of the Cassandra cluster.*spring.data.cassandra.compression=none *# Compression supported by the Cassandra binary protocol.*spring.data.cassandra.connect-timeout-millis= *# Socket option: connection time out.*spring.data.cassandra.consistency-level= *# Queries consistency level.*spring.data.cassandra.contact-points=localhost *# Comma-separated list of cluster node addresses.*spring.data.cassandra.fetch-size= *# Queries default fetch size.*spring.data.cassandra.keyspace-name= *# Keyspace name to use.*spring.data.cassandra.load-balancing-policy= *# Class name of the load balancing policy.*spring.data.cassandra.port= *# Port of the Cassandra server.*spring.data.cassandra.password= *# Login password of the server.*spring.data.cassandra.read-timeout-millis= *# Socket option: read time out.*spring.data.cassandra.reconnection-policy= *# Reconnection policy class.*spring.data.cassandra.retry-policy= *# Class name of the retry policy.*spring.data.cassandra.serial-consistency-level= *# Queries serial consistency level.*spring.data.cassandra.schema-action=none *# Schema action to take at startup.*spring.data.cassandra.ssl=false *# Enable SSL support.*spring.data.cassandra.username= *# Login user of the server.**# DATA COUCHBASE (*[&lt;u&gt;CouchbaseDataProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/data/couchbase/CouchbaseDataProperties.java))spring.data.couchbase.auto-index=false *# Automatically create views and indexes.*spring.data.couchbase.consistency=read-your-own-writes *# Consistency to apply by default on generated queries.*spring.data.couchbase.repositories.enabled=true *# Enable Couchbase repositories.**# ELASTICSEARCH (*[&lt;u&gt;ElasticsearchProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/data/elasticsearch/ElasticsearchProperties.java))spring.data.elasticsearch.cluster-name=elasticsearch *# Elasticsearch cluster name.*spring.data.elasticsearch.cluster-nodes= *# Comma-separated list of cluster node addresses. If not specified, starts a client node.*spring.data.elasticsearch.properties.*= *# Additional properties used to configure the client.*spring.data.elasticsearch.repositories.enabled=true *# Enable Elasticsearch repositories.**# DATA LDAP*spring.data.ldap.repositories.enabled=true *# Enable LDAP repositories.**# MONGODB (*[&lt;u&gt;MongoProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mongo/MongoProperties.java))spring.data.mongodb.authentication-database= *# Authentication database name.*spring.data.mongodb.database=test *# Database name.*spring.data.mongodb.field-naming-strategy= *# Fully qualified name of the FieldNamingStrategy to use.*spring.data.mongodb.grid-fs-database= *# GridFS database name.*spring.data.mongodb.host=localhost *# Mongo server host. Cannot be set with uri.*spring.data.mongodb.password= *# Login password of the mongo server. Cannot be set with uri.*spring.data.mongodb.port=27017 *# Mongo server port. Cannot be set with uri.*spring.data.mongodb.repositories.enabled=true *# Enable Mongo repositories.*spring.data.mongodb.uri=mongodb://localhost/test *# Mongo database URI. Cannot be set with host, port and credentials.*spring.data.mongodb.username= *# Login user of the mongo server. Cannot be set with uri.**# DATA REDIS*spring.data.redis.repositories.enabled=true *# Enable Redis repositories.**# NEO4J (*[&lt;u&gt;Neo4jProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/neo4j/Neo4jProperties.java))spring.data.neo4j.compiler= *# Compiler to use.*spring.data.neo4j.embedded.enabled=true *# Enable embedded mode if the embedded driver is available.*spring.data.neo4j.open-in-view=false *# Register OpenSessionInViewInterceptor. Binds a Neo4j Session to the thread for the entire processing of the request.*spring.data.neo4j.password= *# Login password of the server.*spring.data.neo4j.repositories.enabled=true *# Enable Neo4j repositories.*spring.data.neo4j.uri= *# URI used by the driver. Auto-detected by default.*spring.data.neo4j.username= *# Login user of the server.**# DATA REST (*[&lt;u&gt;RepositoryRestProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/data/rest/RepositoryRestProperties.java))spring.data.rest.base-path= *# Base path to be used by Spring Data REST to expose repository resources.*spring.data.rest.default-page-size= *# Default size of pages.*spring.data.rest.detection-strategy=default *# Strategy to use to determine which repositories get exposed.*spring.data.rest.enable-enum-translation= *# Enable enum value translation via the Spring Data REST default resource bundle.*spring.data.rest.limit-param-name= *# Name of the URL query string parameter that indicates how many results to return at once.*spring.data.rest.max-page-size= *# Maximum size of pages.*spring.data.rest.page-param-name= *# Name of the URL query string parameter that indicates what page to return.*spring.data.rest.return-body-on-create= *# Return a response body after creating an entity.*spring.data.rest.return-body-on-update= *# Return a response body after updating an entity.*spring.data.rest.sort-param-name= *# Name of the URL query string parameter that indicates what direction to sort results.**# SOLR (*[&lt;u&gt;SolrProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/solr/SolrProperties.java))spring.data.solr.host=http://127.0.0.1:8983/solr *# Solr host. Ignored if &quot;zk-host&quot; is set.*spring.data.solr.repositories.enabled=true *# Enable Solr repositories.*spring.data.solr.zk-host= *# ZooKeeper host address in the form HOST:PORT.**# DATASOURCE (*[&lt;u&gt;DataSourceAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/DataSourceAutoConfiguration.java)&amp; [&lt;u&gt;DataSourceProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jdbc/DataSourceProperties.java))spring.datasource.continue-on-error=false *# Do not stop if an error occurs while initializing the database.*spring.datasource.data= *# Data (DML) script resource references.*spring.datasource.data-username= *# User of the database to execute DML scripts (if different).*spring.datasource.data-password= *# Password of the database to execute DML scripts (if different).*spring.datasource.dbcp2.*= *# Commons DBCP2 specific settings*spring.datasource.driver-class-name= *# Fully qualified name of the JDBC driver. Auto-detected based on the URL by default.*spring.datasource.generate-unique-name=false *# Generate a random datasource name.*spring.datasource.hikari.*= *# Hikari specific settings*spring.datasource.initialize=true *# Populate the database using &apos;data.sql&apos;.*spring.datasource.jmx-enabled=false *# Enable JMX support (if provided by the underlying pool).*spring.datasource.jndi-name= *# JNDI location of the datasource. Class, url, username &amp; password are ignored when set.*spring.datasource.name=testdb *# Name of the datasource.*spring.datasource.password= *# Login password of the database.*spring.datasource.platform=all *# Platform to use in the schema resource (schema-$&#123;platform&#125;.sql).*spring.datasource.schema= *# Schema (DDL) script resource references.*spring.datasource.schema-username= *# User of the database to execute DDL scripts (if different).*spring.datasource.schema-password= *# Password of the database to execute DDL scripts (if different).*spring.datasource.separator=; *# Statement separator in SQL initialization scripts.*spring.datasource.sql-script-encoding= *# SQL scripts encoding.*spring.datasource.tomcat.*= *# Tomcat datasource specific settings*spring.datasource.type= *# Fully qualified name of the connection pool implementation to use. By default, it is auto-detected from the classpath.*spring.datasource.url= *# JDBC url of the database.*spring.datasource.username=*# JEST (Elasticsearch HTTP client) (*[&lt;u&gt;JestProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jest/JestProperties.java))spring.elasticsearch.jest.connection-timeout=3000 *# Connection timeout in milliseconds.*spring.elasticsearch.jest.multi-threaded=true *# Enable connection requests from multiple execution threads.*spring.elasticsearch.jest.password= *# Login password.*spring.elasticsearch.jest.proxy.host= *# Proxy host the HTTP client should use.*spring.elasticsearch.jest.proxy.port= *# Proxy port the HTTP client should use.*spring.elasticsearch.jest.read-timeout=3000 *# Read timeout in milliseconds.*spring.elasticsearch.jest.uris=http://localhost:9200 *# Comma-separated list of the Elasticsearch instances to use.*spring.elasticsearch.jest.username= *# Login user.**# H2 Web Console (*[&lt;u&gt;H2ConsoleProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/h2/H2ConsoleProperties.java))spring.h2.console.enabled=false *# Enable the console.*spring.h2.console.path=/h2-console *# Path at which the console will be available.*spring.h2.console.settings.trace=false *# Enable trace output.*spring.h2.console.settings.web-allow-others=false *# Enable remote access.**# JOOQ (*[&lt;u&gt;JooqAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jooq/JooqAutoConfiguration.java))spring.jooq.sql-dialect= *# SQLDialect JOOQ used when communicating with the configured datasource. For instance `POSTGRES`**# JPA (*[&lt;u&gt;JpaBaseConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/orm/jpa/JpaBaseConfiguration.java), [&lt;u&gt;HibernateJpaAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaAutoConfiguration.java))spring.data.jpa.repositories.enabled=true *# Enable JPA repositories.*spring.jpa.database= *# Target database to operate on, auto-detected by default. Can be alternatively set using the &quot;databasePlatform&quot; property.*spring.jpa.database-platform= *# Name of the target database to operate on, auto-detected by default. Can be alternatively set using the &quot;Database&quot; enum.*spring.jpa.generate-ddl=false *# Initialize the schema on startup.*spring.jpa.hibernate.ddl-auto= *# DDL mode. This is actually a shortcut for the &quot;hibernate.hbm2ddl.auto&quot; property. Default to &quot;create-drop&quot; when using an embedded database, &quot;none&quot; otherwise.*spring.jpa.hibernate.naming.implicit-strategy= *# Hibernate 5 implicit naming strategy fully qualified name.*spring.jpa.hibernate.naming.physical-strategy= *# Hibernate 5 physical naming strategy fully qualified name.*spring.jpa.hibernate.naming.strategy= *# Hibernate 4 naming strategy fully qualified name. Not supported with Hibernate 5.*spring.jpa.hibernate.use-new-id-generator-mappings= *# Use Hibernate&apos;s newer IdentifierGenerator for AUTO, TABLE and SEQUENCE.*spring.jpa.open-in-view=true *# Register OpenEntityManagerInViewInterceptor. Binds a JPA EntityManager to the thread for the entire processing of the request.*spring.jpa.properties.*= *# Additional native properties to set on the JPA provider.*spring.jpa.show-sql=false *# Enable logging of SQL statements.**# JTA (*[&lt;u&gt;JtaAutoConfiguration&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/transaction/jta/JtaAutoConfiguration.java))spring.jta.enabled=true *# Enable JTA support.*spring.jta.log-dir= *# Transaction logs directory.*spring.jta.transaction-manager-id= *# Transaction manager unique identifier.**# ATOMIKOS (*[&lt;u&gt;AtomikosProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot/src/main/java/org/springframework/boot/jta/atomikos/AtomikosProperties.java))spring.jta.atomikos.connectionfactory.borrow-connection-timeout=30 *# Timeout, in seconds, for borrowing connections from the pool.*spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag=true *# Whether or not to ignore the transacted flag when creating session.*spring.jta.atomikos.connectionfactory.local-transaction-mode=false *# Whether or not local transactions are desired.*spring.jta.atomikos.connectionfactory.maintenance-interval=60 *# The time, in seconds, between runs of the pool&apos;s maintenance thread.*spring.jta.atomikos.connectionfactory.max-idle-time=60 *# The time, in seconds, after which connections are cleaned up from the pool.*spring.jta.atomikos.connectionfactory.max-lifetime=0 *# The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.*spring.jta.atomikos.connectionfactory.max-pool-size=1 *# The maximum size of the pool.*spring.jta.atomikos.connectionfactory.min-pool-size=1 *# The minimum size of the pool.*spring.jta.atomikos.connectionfactory.reap-timeout=0 *# The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.*spring.jta.atomikos.connectionfactory.unique-resource-name=jmsConnectionFactory *# The unique name used to identify the resource during recovery.*spring.jta.atomikos.datasource.borrow-connection-timeout=30 *# Timeout, in seconds, for borrowing connections from the pool.*spring.jta.atomikos.datasource.default-isolation-level= *# Default isolation level of connections provided by the pool.*spring.jta.atomikos.datasource.login-timeout= *# Timeout, in seconds, for establishing a database connection.*spring.jta.atomikos.datasource.maintenance-interval=60 *# The time, in seconds, between runs of the pool&apos;s maintenance thread.*spring.jta.atomikos.datasource.max-idle-time=60 *# The time, in seconds, after which connections are cleaned up from the pool.*spring.jta.atomikos.datasource.max-lifetime=0 *# The time, in seconds, that a connection can be pooled for before being destroyed. 0 denotes no limit.*spring.jta.atomikos.datasource.max-pool-size=1 *# The maximum size of the pool.*spring.jta.atomikos.datasource.min-pool-size=1 *# The minimum size of the pool.*spring.jta.atomikos.datasource.reap-timeout=0 *# The reap timeout, in seconds, for borrowed connections. 0 denotes no limit.*spring.jta.atomikos.datasource.test-query= *# SQL query or statement used to validate a connection before returning it.*spring.jta.atomikos.datasource.unique-resource-name=dataSource *# The unique name used to identify the resource during recovery.*spring.jta.atomikos.properties.checkpoint-interval=500 *# Interval between checkpoints.*spring.jta.atomikos.properties.console-file-count=1 *# Number of debug logs files that can be created.*spring.jta.atomikos.properties.console-file-limit=-1 *# How many bytes can be stored at most in debug logs files.*spring.jta.atomikos.properties.console-file-name=tm.out *# Debug logs file name.*spring.jta.atomikos.properties.console-log-level=warn *# Console log level.*spring.jta.atomikos.properties.default-jta-timeout=10000 *# Default timeout for JTA transactions.*spring.jta.atomikos.properties.enable-logging=true *# Enable disk logging.*spring.jta.atomikos.properties.force-shutdown-on-vm-exit=false *# Specify if a VM shutdown should trigger forced shutdown of the transaction core.*spring.jta.atomikos.properties.log-base-dir= *# Directory in which the log files should be stored.*spring.jta.atomikos.properties.log-base-name=tmlog *# Transactions log file base name.*spring.jta.atomikos.properties.max-actives=50 *# Maximum number of active transactions.*spring.jta.atomikos.properties.max-timeout=300000 *# Maximum timeout (in milliseconds) that can be allowed for transactions.*spring.jta.atomikos.properties.output-dir= *# Directory in which to store the debug log files.*spring.jta.atomikos.properties.serial-jta-transactions=true *# Specify if sub-transactions should be joined when possible.*spring.jta.atomikos.properties.service= *# Transaction manager implementation that should be started.*spring.jta.atomikos.properties.threaded-two-phase-commit=true *# Use different (and concurrent) threads for two-phase commit on the participating resources.*spring.jta.atomikos.properties.transaction-manager-unique-name= *# Transaction manager&apos;s unique name.**# BITRONIX*spring.jta.bitronix.connectionfactory.acquire-increment=1 *# Number of connections to create when growing the pool.*spring.jta.bitronix.connectionfactory.acquisition-interval=1 *# Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.*spring.jta.bitronix.connectionfactory.acquisition-timeout=30 *# Timeout, in seconds, for acquiring connections from the pool.*spring.jta.bitronix.connectionfactory.allow-local-transactions=true *# Whether or not the transaction manager should allow mixing XA and non-XA transactions.*spring.jta.bitronix.connectionfactory.apply-transaction-timeout=false *# Whether or not the transaction timeout should be set on the XAResource when it is enlisted.*spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled=true *# Whether or not resources should be enlisted and delisted automatically.*spring.jta.bitronix.connectionfactory.cache-producers-consumers=true *# Whether or not produces and consumers should be cached.*spring.jta.bitronix.connectionfactory.defer-connection-release=true *# Whether or not the provider can run many transactions on the same connection and supports transaction interleaving.*spring.jta.bitronix.connectionfactory.ignore-recovery-failures=false *# Whether or not recovery failures should be ignored.*spring.jta.bitronix.connectionfactory.max-idle-time=60 *# The time, in seconds, after which connections are cleaned up from the pool.*spring.jta.bitronix.connectionfactory.max-pool-size=10 *# The maximum size of the pool. 0 denotes no limit.*spring.jta.bitronix.connectionfactory.min-pool-size=0 *# The minimum size of the pool.*spring.jta.bitronix.connectionfactory.password= *# The password to use to connect to the JMS provider.*spring.jta.bitronix.connectionfactory.share-transaction-connections=false *# Whether or not connections in the ACCESSIBLE state can be shared within the context of a transaction.*spring.jta.bitronix.connectionfactory.test-connections=true *# Whether or not connections should be tested when acquired from the pool.*spring.jta.bitronix.connectionfactory.two-pc-ordering-position=1 *# The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE).*spring.jta.bitronix.connectionfactory.unique-name=jmsConnectionFactory *# The unique name used to identify the resource during recovery.*spring.jta.bitronix.connectionfactory.use-tm-join=true Whether or not TMJOIN should be used when starting XAResources.spring.jta.bitronix.connectionfactory.user= *# The user to use to connect to the JMS provider.*spring.jta.bitronix.datasource.acquire-increment=1 *# Number of connections to create when growing the pool.*spring.jta.bitronix.datasource.acquisition-interval=1 *# Time, in seconds, to wait before trying to acquire a connection again after an invalid connection was acquired.*spring.jta.bitronix.datasource.acquisition-timeout=30 *# Timeout, in seconds, for acquiring connections from the pool.*spring.jta.bitronix.datasource.allow-local-transactions=true *# Whether or not the transaction manager should allow mixing XA and non-XA transactions.*spring.jta.bitronix.datasource.apply-transaction-timeout=false *# Whether or not the transaction timeout should be set on the XAResource when it is enlisted.*spring.jta.bitronix.datasource.automatic-enlisting-enabled=true *# Whether or not resources should be enlisted and delisted automatically.*spring.jta.bitronix.datasource.cursor-holdability= *# The default cursor holdability for connections.*spring.jta.bitronix.datasource.defer-connection-release=true *# Whether or not the database can run many transactions on the same connection and supports transaction interleaving.*spring.jta.bitronix.datasource.enable-jdbc4-connection-test= *# Whether or not Connection.isValid() is called when acquiring a connection from the pool.*spring.jta.bitronix.datasource.ignore-recovery-failures=false *# Whether or not recovery failures should be ignored.*spring.jta.bitronix.datasource.isolation-level= *# The default isolation level for connections.*spring.jta.bitronix.datasource.local-auto-commit= *# The default auto-commit mode for local transactions.*spring.jta.bitronix.datasource.login-timeout= *# Timeout, in seconds, for establishing a database connection.*spring.jta.bitronix.datasource.max-idle-time=60 *# The time, in seconds, after which connections are cleaned up from the pool.*spring.jta.bitronix.datasource.max-pool-size=10 *# The maximum size of the pool. 0 denotes no limit.*spring.jta.bitronix.datasource.min-pool-size=0 *# The minimum size of the pool.*spring.jta.bitronix.datasource.prepared-statement-cache-size=0 *# The target size of the prepared statement cache. 0 disables the cache.*spring.jta.bitronix.datasource.share-transaction-connections=false *# Whether or not connections in the ACCESSIBLE state can be shared within the context of a transaction.*spring.jta.bitronix.datasource.test-query= *# SQL query or statement used to validate a connection before returning it.*spring.jta.bitronix.datasource.two-pc-ordering-position=1 *# The position that this resource should take during two-phase commit (always first is Integer.MIN_VALUE, always last is Integer.MAX_VALUE).*spring.jta.bitronix.datasource.unique-name=dataSource *# The unique name used to identify the resource during recovery.*spring.jta.bitronix.datasource.use-tm-join=true Whether or not TMJOIN should be used when starting XAResources.spring.jta.bitronix.properties.allow-multiple-lrc=false *# Allow multiple LRC resources to be enlisted into the same transaction.*spring.jta.bitronix.properties.asynchronous2-pc=false *# Enable asynchronously execution of two phase commit.*spring.jta.bitronix.properties.background-recovery-interval-seconds=60 *# Interval in seconds at which to run the recovery process in the background.*spring.jta.bitronix.properties.current-node-only-recovery=true *# Recover only the current node.*spring.jta.bitronix.properties.debug-zero-resource-transaction=false *# Log the creation and commit call stacks of transactions executed without a single enlisted resource.*spring.jta.bitronix.properties.default-transaction-timeout=60 *# Default transaction timeout in seconds.*spring.jta.bitronix.properties.disable-jmx=false *# Enable JMX support.*spring.jta.bitronix.properties.exception-analyzer= *# Set the fully qualified name of the exception analyzer implementation to use.*spring.jta.bitronix.properties.filter-log-status=false *# Enable filtering of logs so that only mandatory logs are written.*spring.jta.bitronix.properties.force-batching-enabled=true *# Set if disk forces are batched.*spring.jta.bitronix.properties.forced-write-enabled=true *# Set if logs are forced to disk.*spring.jta.bitronix.properties.graceful-shutdown-interval=60 *# Maximum amount of seconds the TM will wait for transactions to get done before aborting them at shutdown time.*spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name= *# JNDI name of the TransactionSynchronizationRegistry.*spring.jta.bitronix.properties.jndi-user-transaction-name= *# JNDI name of the UserTransaction.*spring.jta.bitronix.properties.journal=disk *# Name of the journal. Can be &apos;disk&apos;, &apos;null&apos; or a class name.*spring.jta.bitronix.properties.log-part1-filename=btm1.tlog *# Name of the first fragment of the journal.*spring.jta.bitronix.properties.log-part2-filename=btm2.tlog *# Name of the second fragment of the journal.*spring.jta.bitronix.properties.max-log-size-in-mb=2 *# Maximum size in megabytes of the journal fragments.*spring.jta.bitronix.properties.resource-configuration-filename= *# ResourceLoader configuration file name.*spring.jta.bitronix.properties.server-id= *# ASCII ID that must uniquely identify this TM instance. Default to the machine&apos;s IP address.*spring.jta.bitronix.properties.skip-corrupted-logs=false *# Skip corrupted transactions log entries.*spring.jta.bitronix.properties.warn-about-zero-resource-transaction=true *# Log a warning for transactions executed without a single enlisted resource.**# NARAYANA (*[&lt;u&gt;NarayanaProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot/src/main/java/org/springframework/boot/jta/narayana/NarayanaProperties.java))spring.jta.narayana.default-timeout=60 *# Transaction timeout in seconds.*spring.jta.narayana.expiry-scanners=com.arjuna.ats.internal.arjuna.recovery.ExpiredTransactionStatusManagerScanner *# Comma-separated list of expiry scanners.*spring.jta.narayana.log-dir= *# Transaction object store directory.*spring.jta.narayana.one-phase-commit=true *# Enable one phase commit optimisation.*spring.jta.narayana.periodic-recovery-period=120 *# Interval in which periodic recovery scans are performed in seconds.*spring.jta.narayana.recovery-backoff-period=10 *# Back off period between first and second phases of the recovery scan in seconds.*spring.jta.narayana.recovery-db-pass= *# Database password to be used by recovery manager.*spring.jta.narayana.recovery-db-user= *# Database username to be used by recovery manager.*spring.jta.narayana.recovery-jms-pass= *# JMS password to be used by recovery manager.*spring.jta.narayana.recovery-jms-user= *# JMS username to be used by recovery manager.*spring.jta.narayana.recovery-modules= *# Comma-separated list of recovery modules.*spring.jta.narayana.transaction-manager-id=1 *# Unique transaction manager id.*spring.jta.narayana.xa-resource-orphan-filters= *# Comma-separated list of orphan filters.**# EMBEDDED MONGODB (*[&lt;u&gt;EmbeddedMongoProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/mongo/embedded/EmbeddedMongoProperties.java))spring.mongodb.embedded.features=SYNC_DELAY *# Comma-separated list of features to enable.*spring.mongodb.embedded.storage.database-dir= *# Directory used for data storage.*spring.mongodb.embedded.storage.oplog-size= *# Maximum size of the oplog in megabytes.*spring.mongodb.embedded.storage.repl-set-name= *# Name of the replica set.*spring.mongodb.embedded.version=2.6.10 *# Version of Mongo to use.**# REDIS (*[&lt;u&gt;RedisProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/data/redis/RedisProperties.java))spring.redis.cluster.max-redirects= *# Maximum number of redirects to follow when executing commands across the cluster.*spring.redis.cluster.nodes= *# Comma-separated list of &quot;host:port&quot; pairs to bootstrap from.*spring.redis.database=0 *# Database index used by the connection factory.*spring.redis.url= *# Connection URL, will override host, port and password (user will be ignored), e.g. redis://user:password@example.com:6379*spring.redis.host=localhost *# Redis server host.*spring.redis.password= *# Login password of the redis server.*spring.redis.ssl=false *# Enable SSL support.*spring.redis.pool.max-active=8 *# Max number of connections that can be allocated by the pool at a given time. Use a negative value for no limit.*spring.redis.pool.max-idle=8 *# Max number of &quot;idle&quot; connections in the pool. Use a negative value to indicate an unlimited number of idle connections.*spring.redis.pool.max-wait=-1 *# Maximum amount of time (in milliseconds) a connection allocation should block before throwing an exception when the pool is exhausted. Use a negative value to block indefinitely.*spring.redis.pool.min-idle=0 *# Target for the minimum number of idle connections to maintain in the pool. This setting only has an effect if it is positive.*spring.redis.port=6379 *# Redis server port.*spring.redis.sentinel.master= *# Name of Redis server.*spring.redis.sentinel.nodes= *# Comma-separated list of host:port pairs.*spring.redis.timeout=0 *# Connection timeout in milliseconds.**# TRANSACTION (*[&lt;u&gt;TransactionProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/transaction/TransactionProperties.java))spring.transaction.default-timeout= *# Default transaction timeout in seconds.*spring.transaction.rollback-on-commit-failure= *# Perform the rollback on commit failures.**# ----------------------------------------**# INTEGRATION PROPERTIES**# ----------------------------------------**# ACTIVEMQ (*[&lt;u&gt;ActiveMQProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jms/activemq/ActiveMQProperties.java))spring.activemq.broker-url= *# URL of the ActiveMQ broker. Auto-generated by default. For instance `tcp://localhost:61616`*spring.activemq.in-memory=true *# Specify if the default broker URL should be in memory. Ignored if an explicit broker has been specified.*spring.activemq.password= *# Login password of the broker.*spring.activemq.user= *# Login user of the broker.*spring.activemq.packages.trust-all=false *# Trust all packages.*spring.activemq.packages.trusted= *# Comma-separated list of specific packages to trust (when not trusting all packages).*spring.activemq.pool.configuration.*= *# See PooledConnectionFactory.*spring.activemq.pool.enabled=false *# Whether a PooledConnectionFactory should be created instead of a regular ConnectionFactory.*spring.activemq.pool.expiry-timeout=0 *# Connection expiration timeout in milliseconds.*spring.activemq.pool.idle-timeout=30000 *# Connection idle timeout in milliseconds.*spring.activemq.pool.max-connections=1 *# Maximum number of pooled connections.**# ARTEMIS (*[&lt;u&gt;ArtemisProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jms/artemis/ArtemisProperties.java))spring.artemis.embedded.cluster-password= *# Cluster password. Randomly generated on startup by default.*spring.artemis.embedded.data-directory= *# Journal file directory. Not necessary if persistence is turned off.*spring.artemis.embedded.enabled=true *# Enable embedded mode if the Artemis server APIs are available.*spring.artemis.embedded.persistent=false *# Enable persistent store.*spring.artemis.embedded.queues= *# Comma-separated list of queues to create on startup.*spring.artemis.embedded.server-id= *# Server id. By default, an auto-incremented counter is used.*spring.artemis.embedded.topics= *# Comma-separated list of topics to create on startup.*spring.artemis.host=localhost *# Artemis broker host.*spring.artemis.mode= *# Artemis deployment mode, auto-detected by default.*spring.artemis.password= *# Login password of the broker.*spring.artemis.port=61616 *# Artemis broker port.*spring.artemis.user= *# Login user of the broker.**# SPRING BATCH (*[&lt;u&gt;BatchProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/batch/BatchProperties.java))spring.batch.initializer.enabled= *# Create the required batch tables on startup if necessary. Enabled automatically if no custom table prefix is set or if a custom schema is configured.*spring.batch.job.enabled=true *# Execute all Spring Batch jobs in the context on startup.*spring.batch.job.names= *# Comma-separated list of job names to execute on startup (For instance `job1,job2`). By default, all Jobs found in the context are executed.*spring.batch.schema=classpath:org/springframework/batch/core/schema-@@platform@@.sql *# Path to the SQL file to use to initialize the database schema.*spring.batch.table-prefix= *# Table prefix for all the batch meta-data tables.**# JMS (*[&lt;u&gt;JmsProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/jms/JmsProperties.java))spring.jms.jndi-name= *# Connection factory JNDI name. When set, takes precedence to others connection factory auto-configurations.*spring.jms.listener.acknowledge-mode= *# Acknowledge mode of the container. By default, the listener is transacted with automatic acknowledgment.*spring.jms.listener.auto-startup=true *# Start the container automatically on startup.*spring.jms.listener.concurrency= *# Minimum number of concurrent consumers.*spring.jms.listener.max-concurrency= *# Maximum number of concurrent consumers.*spring.jms.pub-sub-domain=false *# Specify if the default destination type is topic.*spring.jms.template.default-destination= *# Default destination to use on send/receive operations that do not have a destination parameter.*spring.jms.template.delivery-delay= *# Delivery delay to use for send calls in milliseconds.*spring.jms.template.delivery-mode= *# Delivery mode. Enable QoS when set.*spring.jms.template.priority= *# Priority of a message when sending. Enable QoS when set.*spring.jms.template.qos-enabled= *# Enable explicit QoS when sending a message.*spring.jms.template.receive-timeout= *# Timeout to use for receive calls in milliseconds.*spring.jms.template.time-to-live= *# Time-to-live of a message when sending in milliseconds. Enable QoS when set.**# APACHE KAFKA (*[&lt;u&gt;KafkaProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/kafka/KafkaProperties.java))spring.kafka.bootstrap-servers= *# Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.*spring.kafka.client-id= *# Id to pass to the server when making requests; used for server-side logging.*spring.kafka.consumer.auto-commit-interval= *# Frequency in milliseconds that the consumer offsets are auto-committed to Kafka if &apos;enable.auto.commit&apos; true.*spring.kafka.consumer.auto-offset-reset= *# What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server.*spring.kafka.consumer.bootstrap-servers= *# Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.*spring.kafka.consumer.client-id= *# Id to pass to the server when making requests; used for server-side logging.*spring.kafka.consumer.enable-auto-commit= *# If true the consumer&apos;s offset will be periodically committed in the background.*spring.kafka.consumer.fetch-max-wait= *# Maximum amount of time in milliseconds the server will block before answering the fetch request if there isn&apos;t sufficient data to immediately satisfy the requirement given by &quot;fetch.min.bytes&quot;.*spring.kafka.consumer.fetch-min-size= *# Minimum amount of data the server should return for a fetch request in bytes.*spring.kafka.consumer.group-id= *# Unique string that identifies the consumer group this consumer belongs to.*spring.kafka.consumer.heartbeat-interval= *# Expected time in milliseconds between heartbeats to the consumer coordinator.*spring.kafka.consumer.key-deserializer= *# Deserializer class for keys.*spring.kafka.consumer.max-poll-records= *# Maximum number of records returned in a single call to poll().*spring.kafka.consumer.value-deserializer= *# Deserializer class for values.*spring.kafka.listener.ack-count= *# Number of records between offset commits when ackMode is &quot;COUNT&quot; or &quot;COUNT_TIME&quot;.*spring.kafka.listener.ack-mode= *# Listener AckMode; see the spring-kafka documentation.*spring.kafka.listener.ack-time= *# Time in milliseconds between offset commits when ackMode is &quot;TIME&quot; or &quot;COUNT_TIME&quot;.*spring.kafka.listener.concurrency= *# Number of threads to run in the listener containers.*spring.kafka.listener.poll-timeout= *# Timeout in milliseconds to use when polling the consumer.*spring.kafka.producer.acks= *# Number of acknowledgments the producer requires the leader to have received before considering a request complete.*spring.kafka.producer.batch-size= *# Number of records to batch before sending.*spring.kafka.producer.bootstrap-servers= *# Comma-delimited list of host:port pairs to use for establishing the initial connection to the Kafka cluster.*spring.kafka.producer.buffer-memory= *# Total bytes of memory the producer can use to buffer records waiting to be sent to the server.*spring.kafka.producer.client-id= *# Id to pass to the server when making requests; used for server-side logging.*spring.kafka.producer.compression-type= *# Compression type for all data generated by the producer.*spring.kafka.producer.key-serializer= *# Serializer class for keys.*spring.kafka.producer.retries= *# When greater than zero, enables retrying of failed sends.*spring.kafka.producer.value-serializer= *# Serializer class for values.*spring.kafka.properties.*= *# Additional properties used to configure the client.*spring.kafka.ssl.key-password= *# Password of the private key in the key store file.*spring.kafka.ssl.keystore-location= *# Location of the key store file.*spring.kafka.ssl.keystore-password= *# Store password for the key store file.*spring.kafka.ssl.truststore-location= *# Location of the trust store file.*spring.kafka.ssl.truststore-password= *# Store password for the trust store file.*spring.kafka.template.default-topic= *# Default topic to which messages will be sent.**# RABBIT (*[&lt;u&gt;RabbitProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-autoconfigure/src/main/java/org/springframework/boot/autoconfigure/amqp/RabbitProperties.java))spring.rabbitmq.addresses= *# Comma-separated list of addresses to which the client should connect.*spring.rabbitmq.cache.channel.checkout-timeout= *# Number of milliseconds to wait to obtain a channel if the cache size has been reached.*spring.rabbitmq.cache.channel.size= *# Number of channels to retain in the cache.*spring.rabbitmq.cache.connection.mode=channel *# Connection factory cache mode.*spring.rabbitmq.cache.connection.size= *# Number of connections to cache.*spring.rabbitmq.connection-timeout= *# Connection timeout, in milliseconds; zero for infinite.*spring.rabbitmq.dynamic=true *# Create an AmqpAdmin bean.*spring.rabbitmq.host=localhost *# RabbitMQ host.*spring.rabbitmq.listener.acknowledge-mode= *# Acknowledge mode of container.*spring.rabbitmq.listener.auto-startup=true *# Start the container automatically on startup.*spring.rabbitmq.listener.concurrency= *# Minimum number of consumers.*spring.rabbitmq.listener.default-requeue-rejected= *# Whether or not to requeue delivery failures; default `true`.*spring.rabbitmq.listener.idle-event-interval= *# How often idle container events should be published in milliseconds.*spring.rabbitmq.listener.max-concurrency= *# Maximum number of consumers.*spring.rabbitmq.listener.prefetch= *# Number of messages to be handled in a single request. It should be greater than or equal to the transaction size (if used).*spring.rabbitmq.listener.retry.enabled=false *# Whether or not publishing retries are enabled.*spring.rabbitmq.listener.retry.initial-interval=1000 *# Interval between the first and second attempt to deliver a message.*spring.rabbitmq.listener.retry.max-attempts=3 *# Maximum number of attempts to deliver a message.*spring.rabbitmq.listener.retry.max-interval=10000 *# Maximum interval between attempts.*spring.rabbitmq.listener.retry.multiplier=1.0 *# A multiplier to apply to the previous delivery retry interval.*spring.rabbitmq.listener.retry.stateless=true *# Whether or not retry is stateless or stateful.*spring.rabbitmq.listener.transaction-size= *# Number of messages to be processed in a transaction. For best results it should be less than or equal to the prefetch count.*spring.rabbitmq.password= *# Login to authenticate against the broker.*spring.rabbitmq.port=5672 *# RabbitMQ port.*spring.rabbitmq.publisher-confirms=false *# Enable publisher confirms.*spring.rabbitmq.publisher-returns=false *# Enable publisher returns.*spring.rabbitmq.requested-heartbeat= *# Requested heartbeat timeout, in seconds; zero for none.*spring.rabbitmq.ssl.enabled=false *# Enable SSL support.*spring.rabbitmq.ssl.key-store= *# Path to the key store that holds the SSL certificate.*spring.rabbitmq.ssl.key-store-password= *# Password used to access the key store.*spring.rabbitmq.ssl.trust-store= *# Trust store that holds SSL certificates.*spring.rabbitmq.ssl.trust-store-password= *# Password used to access the trust store.*spring.rabbitmq.ssl.algorithm= *# SSL algorithm to use. By default configure by the rabbit client library.*spring.rabbitmq.template.mandatory=false *# Enable mandatory messages.*spring.rabbitmq.template.receive-timeout=0 *# Timeout for `receive()` methods.*spring.rabbitmq.template.reply-timeout=5000 *# Timeout for `sendAndReceive()` methods.*spring.rabbitmq.template.retry.enabled=false *# Set to true to enable retries in the `RabbitTemplate`.*spring.rabbitmq.template.retry.initial-interval=1000 *# Interval between the first and second attempt to publish a message.*spring.rabbitmq.template.retry.max-attempts=3 *# Maximum number of attempts to publish a message.*spring.rabbitmq.template.retry.max-interval=10000 *# Maximum number of attempts to publish a message.*spring.rabbitmq.template.retry.multiplier=1.0 *# A multiplier to apply to the previous publishing retry interval.*spring.rabbitmq.username= *# Login user to authenticate to the broker.*spring.rabbitmq.virtual-host= *# Virtual host to use when connecting to the broker.**# ----------------------------------------**# ACTUATOR PROPERTIES**# ----------------------------------------**# ENDPOINTS (*[&lt;u&gt;AbstractEndpoint&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/endpoint/AbstractEndpoint.java) subclasses)endpoints.enabled=true *# Enable endpoints.*endpoints.sensitive= *# Default endpoint sensitive setting.*endpoints.actuator.enabled=true *# Enable the endpoint.*endpoints.actuator.path= *# Endpoint URL path.*endpoints.actuator.sensitive=false *# Enable security on the endpoint.*endpoints.auditevents.enabled= *# Enable the endpoint.*endpoints.auditevents.path= *# Endpoint path.*endpoints.auditevents.sensitive=false *# Enable security on the endpoint.*endpoints.autoconfig.enabled= *# Enable the endpoint.*endpoints.autoconfig.id= *# Endpoint identifier.*endpoints.autoconfig.path= *# Endpoint path.*endpoints.autoconfig.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.beans.enabled= *# Enable the endpoint.*endpoints.beans.id= *# Endpoint identifier.*endpoints.beans.path= *# Endpoint path.*endpoints.beans.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.configprops.enabled= *# Enable the endpoint.*endpoints.configprops.id= *# Endpoint identifier.*endpoints.configprops.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services *# Keys that should be sanitized. Keys can be simple strings that the property ends with or regex expressions.*endpoints.configprops.path= *# Endpoint path.*endpoints.configprops.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.docs.curies.enabled=false *# Enable the curie generation.*endpoints.docs.enabled=true *# Enable actuator docs endpoint.*endpoints.docs.path=/docs *#*endpoints.docs.sensitive=false *#*endpoints.dump.enabled= *# Enable the endpoint.*endpoints.dump.id= *# Endpoint identifier.*endpoints.dump.path= *# Endpoint path.*endpoints.dump.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.env.enabled= *# Enable the endpoint.*endpoints.env.id= *# Endpoint identifier.*endpoints.env.keys-to-sanitize=password,secret,key,token,.*credentials.*,vcap_services *# Keys that should be sanitized. Keys can be simple strings that the property ends with or regex expressions.*endpoints.env.path= *# Endpoint path.*endpoints.env.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.flyway.enabled= *# Enable the endpoint.*endpoints.flyway.id= *# Endpoint identifier.*endpoints.flyway.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.health.enabled= *# Enable the endpoint.*endpoints.health.id= *# Endpoint identifier.*endpoints.health.mapping.*= *# Mapping of health statuses to HttpStatus codes. By default, registered health statuses map to sensible defaults (i.e. UP maps to 200).*endpoints.health.path= *# Endpoint path.*endpoints.health.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.health.time-to-live=1000 *# Time to live for cached result, in milliseconds.*endpoints.heapdump.enabled= *# Enable the endpoint.*endpoints.heapdump.path= *# Endpoint path.*endpoints.heapdump.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.hypermedia.enabled=false *# Enable hypermedia support for endpoints.*endpoints.info.enabled= *# Enable the endpoint.*endpoints.info.id= *# Endpoint identifier.*endpoints.info.path= *# Endpoint path.*endpoints.info.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.jolokia.enabled=true *# Enable Jolokia endpoint.*endpoints.jolokia.path=/jolokia *# Endpoint URL path.*endpoints.jolokia.sensitive=true *# Enable security on the endpoint.*endpoints.liquibase.enabled= *# Enable the endpoint.*endpoints.liquibase.id= *# Endpoint identifier.*endpoints.liquibase.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.logfile.enabled=true *# Enable the endpoint.*endpoints.logfile.external-file= *# External Logfile to be accessed.*endpoints.logfile.path=/logfile *# Endpoint URL path.*endpoints.logfile.sensitive=true *# Enable security on the endpoint.*endpoints.loggers.enabled=true *# Enable the endpoint.*endpoints.loggers.id= *# Endpoint identifier.*endpoints.loggers.path=/logfile *# Endpoint path.*endpoints.loggers.sensitive=true *# Mark if the endpoint exposes sensitive information.*endpoints.mappings.enabled= *# Enable the endpoint.*endpoints.mappings.id= *# Endpoint identifier.*endpoints.mappings.path= *# Endpoint path.*endpoints.mappings.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.metrics.enabled= *# Enable the endpoint.*endpoints.metrics.filter.enabled=true *# Enable the metrics servlet filter.*endpoints.metrics.filter.gauge-submissions=merged *# Http filter gauge submissions (merged, per-http-method)*endpoints.metrics.filter.counter-submissions=merged *# Http filter counter submissions (merged, per-http-method)*endpoints.metrics.id= *# Endpoint identifier.*endpoints.metrics.path= *# Endpoint path.*endpoints.metrics.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.shutdown.enabled= *# Enable the endpoint.*endpoints.shutdown.id= *# Endpoint identifier.*endpoints.shutdown.path= *# Endpoint path.*endpoints.shutdown.sensitive= *# Mark if the endpoint exposes sensitive information.*endpoints.trace.enabled= *# Enable the endpoint.*endpoints.trace.id= *# Endpoint identifier.*endpoints.trace.path= *# Endpoint path.*endpoints.trace.sensitive= *# Mark if the endpoint exposes sensitive information.**# ENDPOINTS CORS CONFIGURATION (*[&lt;u&gt;EndpointCorsProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/EndpointCorsProperties.java))endpoints.cors.allow-credentials= *# Set whether credentials are supported. When not set, credentials are not supported.*endpoints.cors.allowed-headers= *# Comma-separated list of headers to allow in a request. &apos;*&apos; allows all headers.*endpoints.cors.allowed-methods=GET *# Comma-separated list of methods to allow. &apos;*&apos; allows all methods.*endpoints.cors.allowed-origins= *# Comma-separated list of origins to allow. &apos;*&apos; allows all origins. When not set, CORS support is disabled.*endpoints.cors.exposed-headers= *# Comma-separated list of headers to include in a response.*endpoints.cors.max-age=1800 *# How long, in seconds, the response from a pre-flight request can be cached by clients.**# JMX ENDPOINT (*[&lt;u&gt;EndpointMBeanExportProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/EndpointMBeanExportProperties.java))endpoints.jmx.domain= *# JMX domain name. Initialized with the value of &apos;spring.jmx.default-domain&apos; if set.*endpoints.jmx.enabled=true *# Enable JMX export of all endpoints.*endpoints.jmx.static-names= *# Additional static properties to append to all ObjectNames of MBeans representing Endpoints.*endpoints.jmx.unique-names=false *# Ensure that ObjectNames are modified in case of conflict.**# JOLOKIA (*[&lt;u&gt;JolokiaProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/JolokiaProperties.java))jolokia.config.*= *# See Jolokia manual**# MANAGEMENT HTTP SERVER (*[&lt;u&gt;ManagementServerProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/ManagementServerProperties.java))management.add-application-context-header=true *# Add the &quot;X-Application-Context&quot; HTTP header in each response.*management.address= *# Network address that the management endpoints should bind to.*management.context-path= *# Management endpoint context-path. For instance `/actuator`*management.cloudfoundry.enabled= *# Enable extended Cloud Foundry actuator endpoints*management.cloudfoundry.skip-ssl-validation= *# Skip SSL verification for Cloud Foundry actuator endpoint security calls*management.port= *# Management endpoint HTTP port. Uses the same port as the application by default. Configure a different port to use management-specific SSL.*management.security.enabled=true *# Enable security.*management.security.roles=ACTUATOR *# Comma-separated list of roles that can access the management endpoint.*management.security.sessions=stateless *# Session creating policy to use (always, never, if_required, stateless).*management.ssl.ciphers= *# Supported SSL ciphers. Requires a custom management.port.*management.ssl.client-auth= *# Whether client authentication is wanted (&quot;want&quot;) or needed (&quot;need&quot;). Requires a trust store. Requires a custom management.port.*management.ssl.enabled= *# Enable SSL support. Requires a custom management.port.*management.ssl.enabled-protocols= *# Enabled SSL protocols. Requires a custom management.port.*management.ssl.key-alias= *# Alias that identifies the key in the key store. Requires a custom management.port.*management.ssl.key-password= *# Password used to access the key in the key store. Requires a custom management.port.*management.ssl.key-store= *# Path to the key store that holds the SSL certificate (typically a jks file). Requires a custom management.port.*management.ssl.key-store-password= *# Password used to access the key store. Requires a custom management.port.*management.ssl.key-store-provider= *# Provider for the key store. Requires a custom management.port.*management.ssl.key-store-type= *# Type of the key store. Requires a custom management.port.*management.ssl.protocol=TLS *# SSL protocol to use. Requires a custom management.port.*management.ssl.trust-store= *# Trust store that holds SSL certificates. Requires a custom management.port.*management.ssl.trust-store-password= *# Password used to access the trust store. Requires a custom management.port.*management.ssl.trust-store-provider= *# Provider for the trust store. Requires a custom management.port.*management.ssl.trust-store-type= *# Type of the trust store. Requires a custom management.port.**# HEALTH INDICATORS*management.health.db.enabled=true *# Enable database health check.*management.health.cassandra.enabled=true *# Enable cassandra health check.*management.health.couchbase.enabled=true *# Enable couchbase health check.*management.health.defaults.enabled=true *# Enable default health indicators.*management.health.diskspace.enabled=true *# Enable disk space health check.*management.health.diskspace.path= *# Path used to compute the available disk space.*management.health.diskspace.threshold=0 *# Minimum disk space that should be available, in bytes.*management.health.elasticsearch.enabled=true *# Enable elasticsearch health check.*management.health.elasticsearch.indices= *# Comma-separated index names.*management.health.elasticsearch.response-timeout=100 *# The time, in milliseconds, to wait for a response from the cluster.*management.health.jms.enabled=true *# Enable JMS health check.*management.health.ldap.enabled=true *# Enable LDAP health check.*management.health.mail.enabled=true *# Enable Mail health check.*management.health.mongo.enabled=true *# Enable MongoDB health check.*management.health.rabbit.enabled=true *# Enable RabbitMQ health check.*management.health.redis.enabled=true *# Enable Redis health check.*management.health.solr.enabled=true *# Enable Solr health check.*management.health.status.order=DOWN, OUT_OF_SERVICE, UP, UNKNOWN *# Comma-separated list of health statuses in order of severity.**# INFO CONTRIBUTORS (*[&lt;u&gt;InfoContributorProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/InfoContributorProperties.java))management.info.build.enabled=true *# Enable build info.*management.info.defaults.enabled=true *# Enable default info contributors.*management.info.env.enabled=true *# Enable environment info.*management.info.git.enabled=true *# Enable git info.*management.info.git.mode=simple *# Mode to use to expose git information.**# REMOTE SHELL (*[&lt;u&gt;ShellProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/ShellProperties.java))management.shell.auth.type=simple *# Authentication type. Auto-detected according to the environment.*management.shell.auth.jaas.domain=my-domain *# JAAS domain.*management.shell.auth.key.path= *# Path to the authentication key. This should point to a valid &quot;.pem&quot; file.*management.shell.auth.simple.user.name=user *# Login user.*management.shell.auth.simple.user.password= *# Login password.*management.shell.auth.spring.roles=ACTUATOR *# Comma-separated list of required roles to login to the CRaSH console.*management.shell.command-path-patterns=classpath*:/commands/**,classpath*:/crash/commands/** *# Patterns to use to look for commands.*management.shell.command-refresh-interval=-1 *# Scan for changes and update the command if necessary (in seconds).*management.shell.config-path-patterns=classpath*:/crash/* *# Patterns to use to look for configurations.*management.shell.disabled-commands=jpa*,jdbc*,jndi* *# Comma-separated list of commands to disable.*management.shell.disabled-plugins= *# Comma-separated list of plugins to disable. Certain plugins are disabled by default based on the environment.*management.shell.ssh.auth-timeout = *# Number of milliseconds after user will be prompted to login again.*management.shell.ssh.enabled=true *# Enable CRaSH SSH support.*management.shell.ssh.idle-timeout = *# Number of milliseconds after which unused connections are closed.*management.shell.ssh.key-path= *# Path to the SSH server key.*management.shell.ssh.port=2000 *# SSH port.*management.shell.telnet.enabled=false *# Enable CRaSH telnet support. Enabled by default if the TelnetPlugin is available.*management.shell.telnet.port=5000 *# Telnet port.**# TRACING (*[&lt;u&gt;TraceProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/trace/TraceProperties.java))management.trace.include=request-headers,response-headers,cookies,errors *# Items to be included in the trace.**# METRICS EXPORT (*[&lt;u&gt;MetricExportProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/metrics/export/MetricExportProperties.java))spring.metrics.export.aggregate.key-pattern= *# Pattern that tells the aggregator what to do with the keys from the source repository.*spring.metrics.export.aggregate.prefix= *# Prefix for global repository if active.*spring.metrics.export.delay-millis=5000 *# Delay in milliseconds between export ticks. Metrics are exported to external sources on a schedule with this delay.*spring.metrics.export.enabled=true *# Flag to enable metric export (assuming a MetricWriter is available).*spring.metrics.export.excludes= *# List of patterns for metric names to exclude. Applied after the includes.*spring.metrics.export.includes= *# List of patterns for metric names to include.*spring.metrics.export.redis.key=keys.spring.metrics *# Key for redis repository export (if active).*spring.metrics.export.redis.prefix=spring.metrics *# Prefix for redis repository if active.*spring.metrics.export.send-latest= *# Flag to switch off any available optimizations based on not exporting unchanged metric values.*spring.metrics.export.statsd.host= *# Host of a statsd server to receive exported metrics.*spring.metrics.export.statsd.port=8125 *# Port of a statsd server to receive exported metrics.*spring.metrics.export.statsd.prefix= *# Prefix for statsd exported metrics.*spring.metrics.export.triggers.*= *# Specific trigger properties per MetricWriter bean name.**# ----------------------------------------**# DEVTOOLS PROPERTIES**# ----------------------------------------**# DEVTOOLS (*[&lt;u&gt;DevToolsProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-devtools/src/main/java/org/springframework/boot/devtools/autoconfigure/DevToolsProperties.java))spring.devtools.livereload.enabled=true *# Enable a livereload.com compatible server.*spring.devtools.livereload.port=35729 *# Server port.*spring.devtools.restart.additional-exclude= *# Additional patterns that should be excluded from triggering a full restart.*spring.devtools.restart.additional-paths= *# Additional paths to watch for changes.*spring.devtools.restart.enabled=true *# Enable automatic restart.*spring.devtools.restart.exclude=META-INF/maven/**,META-INF/resources/**,resources/**,static/**,public/**,templates/**,**/*Test.class,**/*Tests.class,git.properties *# Patterns that should be excluded from triggering a full restart.*spring.devtools.restart.poll-interval=1000 *# Amount of time (in milliseconds) to wait between polling for classpath changes.*spring.devtools.restart.quiet-period=400 *# Amount of quiet time (in milliseconds) required without any classpath changes before a restart is triggered.*spring.devtools.restart.trigger-file= *# Name of a specific file that when changed will trigger the restart check. If not specified any classpath file change will trigger the restart.**# REMOTE DEVTOOLS (*[&lt;u&gt;RemoteDevToolsProperties&lt;/u&gt;](https://github.com/spring-projects/spring-boot/tree/v1.5.2.RELEASE/spring-boot-devtools/src/main/java/org/springframework/boot/devtools/autoconfigure/RemoteDevToolsProperties.java))spring.devtools.remote.context-path=/.~~spring-boot!~ *# Context path used to handle the remote connection.*spring.devtools.remote.debug.enabled=true *# Enable remote debug support.*spring.devtools.remote.debug.local-port=8000 *# Local remote debug server port.*spring.devtools.remote.proxy.host= *# The host of the proxy to use to connect to the remote application.*spring.devtools.remote.proxy.port= *# The port of the proxy to use to connect to the remote application.*spring.devtools.remote.restart.enabled=true *# Enable remote restart.*spring.devtools.remote.secret= *# A shared secret required to establish a connection (required to enable remote support).*spring.devtools.remote.secret-header-name=X-AUTH-TOKEN *# HTTP header used to transfer the shared secret.**# ----------------------------------------**# TESTING PROPERTIES**# ----------------------------------------*spring.test.database.replace=any *# Type of existing DataSource to replace.*spring.test.mockmvc.print=default *# MVC Print option.*]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>SpringBoot</tag>
      </tags>
  </entry>
</search>
